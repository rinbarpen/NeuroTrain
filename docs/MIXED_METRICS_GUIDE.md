# æ··åˆæŒ‡æ ‡æ–¹å‘ä½¿ç”¨æŒ‡å—

## ğŸ“‹ åŠŸèƒ½è¯´æ˜

`data_to_latex.py` å·¥å…·æ”¯æŒä¸ºä¸åŒçš„æŒ‡æ ‡åˆ—è®¾ç½®ä¸åŒçš„ä¼˜åŒ–æ–¹å‘ï¼Œè¿™åœ¨å­¦æœ¯è®ºæ–‡ä¸­éå¸¸å¸¸è§ï¼š

- **è¶Šé«˜è¶Šå¥½** (True): accuracy, precision, recall, f1_score, AUCç­‰
- **è¶Šä½è¶Šå¥½** (False): loss, error_rate, inference_time, memory_usageç­‰

## ğŸ¯ æ ¸å¿ƒå‚æ•°

### --metric-columns
æŒ‡å®šè¦è¿›è¡Œé«˜äº®çš„æŒ‡æ ‡åˆ—ååˆ—è¡¨

### --higher-is-better  
ä¸ºæ¯ä¸ªæŒ‡æ ‡åˆ—æŒ‡å®šä¼˜åŒ–æ–¹å‘ï¼ˆTrue/Falseï¼‰

**é‡è¦**: `--higher-is-better` çš„é¡ºåºå¿…é¡»ä¸ `--metric-columns` çš„é¡ºåºä¸€ä¸€å¯¹åº”ï¼

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1: æ ‡å‡†æœºå™¨å­¦ä¹ æŒ‡æ ‡

**åœºæ™¯**: è¯„ä¼°åˆ†ç±»æ¨¡å‹æ€§èƒ½

```bash
python tools/data_to_latex.py \
  -i results.csv \
  -t table --style booktabs \
  --highlight-best --highlight-second \
  --metric-columns accuracy precision recall f1_score \
  --higher-is-better True True True True \
  --our-model "OurModel"
```

**æ•°æ®ç¤ºä¾‹**:
```csv
model,accuracy,precision,recall,f1_score
ModelA,0.95,0.94,0.96,0.95
ModelB,0.93,0.92,0.94,0.93
OurModel,0.97,0.96,0.98,0.97
```

**è§£é‡Š**: æ‰€æœ‰æŒ‡æ ‡éƒ½æ˜¯è¶Šé«˜è¶Šå¥½

---

### ç¤ºä¾‹2: æ€§èƒ½ä¸æ•ˆç‡æƒè¡¡

**åœºæ™¯**: åœ¨ç²¾åº¦å’Œé€Ÿåº¦ä¹‹é—´æƒè¡¡

```bash
python tools/data_to_latex.py \
  -i results.csv \
  -t table --style booktabs \
  --highlight-best --highlight-second \
  --metric-columns accuracy inference_time memory_usage \
  --higher-is-better True False False \
  --our-model "OurModel"
```

**æ•°æ®ç¤ºä¾‹**:
```csv
model,accuracy,inference_time,memory_usage
SlowModel,0.97,200,1024
FastModel,0.91,45,256
OurModel,0.95,80,512
```

**è§£é‡Š**: 
- accuracyè¶Šé«˜è¶Šå¥½
- inference_timeè¶Šä½è¶Šå¥½ï¼ˆè¶Šå¿«ï¼‰
- memory_usageè¶Šä½è¶Šå¥½ï¼ˆå ç”¨æ›´å°‘ï¼‰

---

### ç¤ºä¾‹3: æŸå¤±å‡½æ•°ä¸æŒ‡æ ‡

**åœºæ™¯**: è®­ç»ƒè¿‡ç¨‹ä¸­çš„å¤šä¸ªæŒ‡æ ‡

```bash
python tools/data_to_latex.py \
  -i training_results.csv \
  -t table --style booktabs \
  --highlight-best --highlight-second \
  --metric-columns accuracy loss val_accuracy val_loss \
  --higher-is-better True False True False \
  --our-model "OurModel"
```

**æ•°æ®ç¤ºä¾‹**:
```csv
model,accuracy,loss,val_accuracy,val_loss
ModelA,0.95,0.12,0.93,0.15
ModelB,0.93,0.15,0.91,0.18
OurModel,0.97,0.08,0.96,0.10
```

**è§£é‡Š**: 
- accuracy/val_accuracy: è¶Šé«˜è¶Šå¥½
- loss/val_loss: è¶Šä½è¶Šå¥½

---

### ç¤ºä¾‹4: å®Œæ•´çš„æ¨¡å‹è¯„ä¼°

**åœºæ™¯**: å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½

```bash
python tools/data_to_latex.py \
  -i comprehensive_results.csv \
  -t table --style booktabs \
  --highlight-best --highlight-second \
  --metric-columns accuracy loss error_rate inference_time params \
  --higher-is-better True False False False False \
  --our-model "OurModel"
```

**æ•°æ®ç¤ºä¾‹**:
```csv
model,accuracy,loss,error_rate,inference_time,params
ResNet50,0.9523,0.125,0.0477,120.5,25.6M
VGG16,0.9234,0.156,0.0766,145.2,138.4M
OurModel,0.9678,0.089,0.0322,95.3,5.3M
MobileNet,0.9012,0.198,0.0988,78.4,4.2M
EfficientNet,0.9556,0.098,0.0444,85.6,7.8M
```

**è§£é‡Š**: 
- accuracy: è¶Šé«˜è¶Šå¥½ â†‘
- loss: è¶Šä½è¶Šå¥½ â†“
- error_rate: è¶Šä½è¶Šå¥½ â†“
- inference_time: è¶Šä½è¶Šå¥½ â†“ï¼ˆæ›´å¿«ï¼‰
- params: è¶Šä½è¶Šå¥½ â†“ï¼ˆæ›´è½»é‡ï¼‰

**è¾“å‡ºç»“æœ**:
```latex
\begin{tabular}{llllll}
\toprule
model & accuracy & loss & error_rate & inference_time & params \\
\midrule
ResNet50 & 0.9523 & 0.125 & 0.0477 & 120.5 & 25.6M \\
VGG16 & 0.9234 & 0.156 & 0.0766 & 145.2 & 138.4M \\
\underline{OurModel} & \textbf{0.9678} & \textbf{0.089} & \textbf{0.0322} & 95.3 & \textbf{5.3M} \\
MobileNet & 0.9012 & 0.198 & 0.0988 & \textbf{78.4} & \textit{4.2M} \\
EfficientNet & \textit{0.9556} & \textit{0.098} & \textit{0.0444} & \textit{85.6} & 7.8M \\
\bottomrule
\end{tabular}
```

**åˆ†æ**:
- OurModelåœ¨accuracy, loss, error_rate, paramsä¸Šéƒ½æ˜¯æœ€ä½³ â­
- MobileNetåœ¨inference_timeä¸Šæœ€å¿«
- EfficientNetåœ¨å¤šä¸ªæŒ‡æ ‡ä¸Šæ˜¯æ¬¡ä½³

---

### ç¤ºä¾‹5: å¤šä»»åŠ¡å­¦ä¹ 

**åœºæ™¯**: ä¸åŒä»»åŠ¡æœ‰ä¸åŒçš„æŒ‡æ ‡

```bash
python tools/data_to_latex.py \
  -i multitask_results.csv \
  -t table --style booktabs \
  --highlight-best --highlight-second \
  --metric-columns cls_acc det_map seg_iou total_loss \
  --higher-is-better True True True False \
  --our-model "MultiTaskModel" \
  --group-column task
```

---

## ğŸ”§ å¸¸è§æŒ‡æ ‡æ–¹å‘é€ŸæŸ¥è¡¨

### è¶Šé«˜è¶Šå¥½ (True)

| æŒ‡æ ‡ç±»åˆ« | æŒ‡æ ‡åç§° | è¯´æ˜ |
|---------|---------|------|
| **å‡†ç¡®ç‡** | accuracy, precision, recall | åˆ†ç±»å‡†ç¡®æ€§ |
| **Få€¼** | f1_score, f2_score | ç»¼åˆæŒ‡æ ‡ |
| **AUC** | auc, auc_roc, auc_pr | ROC/PRæ›²çº¿ä¸‹é¢ç§¯ |
| **IoU** | iou, dice_coefficient | åˆ†å‰²é‡å åº¦ |
| **mAP** | map, map50, map75 | æ£€æµ‹å¹³å‡ç²¾åº¦ |
| **ç›¸å…³æ€§** | correlation, r2_score | å›å½’ç›¸å…³æ€§ |
| **BLEU** | bleu_score | æœºå™¨ç¿»è¯‘è´¨é‡ |
| **å‡†ç¡®åŒ¹é…** | exact_match | é—®ç­”å‡†ç¡®åº¦ |

### è¶Šä½è¶Šå¥½ (False)

| æŒ‡æ ‡ç±»åˆ« | æŒ‡æ ‡åç§° | è¯´æ˜ |
|---------|---------|------|
| **æŸå¤±** | loss, cross_entropy, mse | æŸå¤±å‡½æ•°å€¼ |
| **é”™è¯¯ç‡** | error_rate, eer | é”™è¯¯ç™¾åˆ†æ¯” |
| **æ—¶é—´** | inference_time, training_time | æ‰§è¡Œæ—¶é—´ |
| **èµ„æº** | memory_usage, params, flops | èµ„æºå ç”¨ |
| **è·ç¦»** | distance, mae, rmse | è¯¯å·®è·ç¦» |
| **å›°æƒ‘åº¦** | perplexity | è¯­è¨€æ¨¡å‹è´¨é‡ |
| **WER** | word_error_rate | è¯­éŸ³è¯†åˆ«é”™è¯¯ç‡ |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. å‚æ•°é¡ºåºè¦åŒ¹é…

âŒ **é”™è¯¯ç¤ºä¾‹**:
```bash
# metric-columnsæœ‰4ä¸ªï¼Œä½†higher-is-betteråªæœ‰3ä¸ª
--metric-columns acc loss f1 time \
--higher-is-better True False True
```

âœ… **æ­£ç¡®ç¤ºä¾‹**:
```bash
# 4ä¸ªæŒ‡æ ‡ï¼Œ4ä¸ªTrue/False
--metric-columns acc loss f1 time \
--higher-is-better True False True False
```

### 2. True/FalseåŒºåˆ†å¤§å°å†™

âŒ **é”™è¯¯**:
```bash
--higher-is-better true false TRUE FALSE
```

âœ… **æ­£ç¡®**:
```bash
--higher-is-better True False True False
```

### 3. ç¡®ä¿åˆ—åå®Œå…¨åŒ¹é…

å…ˆç”¨ `--show-info` æŸ¥çœ‹åˆ—åï¼š
```bash
python tools/data_to_latex.py -i data.csv --show-info
```

ç„¶åä½¿ç”¨æ­£ç¡®çš„åˆ—åï¼š
```bash
--metric-columns accuracy f1_score inference_time
# ä¸æ˜¯: acc f1 time
```

---

## ğŸ’¡ å®ç”¨æŠ€å·§

### æŠ€å·§1: åªé«˜äº®å…³é”®æŒ‡æ ‡

ä¸å¿…é«˜äº®æ‰€æœ‰åˆ—ï¼Œåªé€‰æ‹©æœ€é‡è¦çš„ï¼š
```bash
# åªé«˜äº®accuracyå’Œlossï¼Œä¸é«˜äº®params
--metric-columns accuracy loss \
--higher-is-better True False
```

### æŠ€å·§2: ä¸åˆ†ç»„åŠŸèƒ½ç»“åˆ

åœ¨å¤šæ•°æ®é›†åœºæ™¯ä¸‹ï¼Œæ¯ç»„å†…åˆ†åˆ«è®¡ç®—æœ€ä½³/æ¬¡ä½³ï¼š
```bash
--metric-columns accuracy loss \
--higher-is-better True False \
--group-column dataset
```

### æŠ€å·§3: åªé«˜äº®æœ€ä½³å€¼

å¦‚æœä¸æƒ³æ˜¾ç¤ºæ¬¡ä½³ï¼Œå»æ‰ `--highlight-second`:
```bash
--highlight-best \
--metric-columns accuracy loss \
--higher-is-better True False
```

### æŠ€å·§4: æ•°å€¼åˆ—å³å¯¹é½

è®©è¡¨æ ¼æ›´ç¾è§‚ï¼š
```bash
--column-align "lrrrr"  # ç¬¬ä¸€åˆ—å·¦å¯¹é½ï¼Œæ•°å€¼åˆ—å³å¯¹é½
```

---

## ğŸ“ å®Œæ•´å‘½ä»¤æ¨¡æ¿

### æ¨¡æ¿1: æ ‡å‡†è¯„ä¼°
```bash
python tools/data_to_latex.py \
  -i results.csv \
  -t table \
  --style booktabs \
  --caption "Model Performance Comparison" \
  --label "tab:performance" \
  --highlight-best \
  --highlight-second \
  --metric-columns accuracy precision recall f1_score \
  --higher-is-better True True True True \
  --our-model "ProposedMethod" \
  -o paper/table1.tex
```

### æ¨¡æ¿2: æ•ˆç‡åˆ†æ
```bash
python tools/data_to_latex.py \
  -i efficiency.csv \
  -t table \
  --style booktabs \
  --caption "Efficiency Analysis" \
  --label "tab:efficiency" \
  --highlight-best \
  --highlight-second \
  --metric-columns accuracy inference_time memory_usage params \
  --higher-is-better True False False False \
  --our-model "EfficientModel" \
  --column-align "lrrrr" \
  -o paper/table2.tex
```

### æ¨¡æ¿3: è®­ç»ƒè¿‡ç¨‹
```bash
python tools/data_to_latex.py \
  -i training.csv \
  -t table \
  --style booktabs \
  --caption "Training Results" \
  --label "tab:training" \
  --highlight-best \
  --metric-columns train_acc train_loss val_acc val_loss \
  --higher-is-better True False True False \
  -c epoch train_acc train_loss val_acc val_loss \
  -o paper/table3.tex
```

---

## ğŸ“ å­¦æœ¯è®ºæ–‡ç¤ºä¾‹

### è®ºæ–‡è¡¨æ ¼æ ‡å‡†é…ç½®

```bash
conda run -n ntrain python tools/data_to_latex.py \
  -i paper_results.csv \
  -t table \
  --style booktabs \
  --caption "Comparison with State-of-the-Art Methods on Benchmark Datasets" \
  --label "tab:sota_comparison" \
  --highlight-best \
  --highlight-second \
  --metric-columns accuracy f1_score inference_time \
  --higher-is-better True True False \
  --our-model "Ours" \
  --column-align "lcccc" \
  -c method accuracy f1_score params inference_time \
  -o paper_tables/comparison.tex
```

**LaTeXæ–‡æ¡£ä¸­ä½¿ç”¨**:
```latex
\documentclass{article}
\usepackage{booktabs}

\begin{document}

\section{Experimental Results}

Table~\ref{tab:sota_comparison} shows the comparison with state-of-the-art methods.
Our method achieves the best accuracy and F1-score while maintaining competitive inference time.

\input{paper_tables/comparison.tex}

\end{document}
```

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- **é«˜çº§åŠŸèƒ½æŒ‡å—**: `tools/ADVANCED_FEATURES_GUIDE.md`
- **æ ·å¼æŒ‡å—**: `tools/TABLE_STYLES_GUIDE.md`
- **å¿«é€Ÿå‚è€ƒ**: `tools/data_to_latex_quickref.md`

---

## ğŸ“ é—®é¢˜æ’æŸ¥

### Q: ä¸ºä»€ä¹ˆé«˜äº®ç»“æœä¸å¯¹ï¼Ÿ
A: æ£€æŸ¥ `--higher-is-better` çš„é¡ºåºæ˜¯å¦ä¸ `--metric-columns` åŒ¹é…

### Q: å¯ä»¥ä¸æŒ‡å®š `--higher-is-better` å—ï¼Ÿ
A: å¯ä»¥ï¼Œé»˜è®¤æ‰€æœ‰æŒ‡æ ‡éƒ½æ˜¯è¶Šé«˜è¶Šå¥½ï¼ˆTrueï¼‰

### Q: å¦‚ä½•éªŒè¯è®¾ç½®æ˜¯å¦æ­£ç¡®ï¼Ÿ
A: ä½¿ç”¨ `--show-info` å…ˆæŸ¥çœ‹æ•°æ®ï¼Œç¡®è®¤åˆ—åå’Œæ•°å€¼

---

## ğŸ¯ æœ€ä½³å®è·µ

1. **æ¸…æ¥šæ ‡æ³¨æ–¹å‘**: åœ¨è®ºæ–‡ä¸­è¯´æ˜å“ªäº›æŒ‡æ ‡è¶Šé«˜è¶Šå¥½
2. **é€‰æ‹©å…³é”®æŒ‡æ ‡**: ä¸è¦é«˜äº®å¤ªå¤šåˆ—ï¼Œä¿æŒè¡¨æ ¼ç®€æ´
3. **ä¸€è‡´æ€§**: åŒç±»è®ºæ–‡ä¸­ä½¿ç”¨ç›¸åŒçš„æŒ‡æ ‡æ–¹å‘
4. **éªŒè¯ç»“æœ**: ç”Ÿæˆåæ£€æŸ¥æœ€ä½³/æ¬¡ä½³å€¼æ˜¯å¦æ­£ç¡®
5. **æ–‡æ¡£è¯´æ˜**: åœ¨captionæˆ–æ–‡ä¸­è¯´æ˜ "**Bold**: best, *Italic*: second best"

