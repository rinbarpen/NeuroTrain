# è‡ªåŠ¨ç¼“å­˜åŠŸèƒ½ä½¿ç”¨æŒ‡å—

## ğŸ¯ è®¾è®¡ç†å¿µ

ç¼“å­˜åŠŸèƒ½ç°åœ¨æ˜¯**å®Œå…¨è‡ªåŠ¨åŒ–**çš„ï¼š
- âœ… ç¬¬ä¸€æ¬¡åŠ è½½æ•°æ®é›†æ—¶ï¼Œè‡ªåŠ¨åˆ›å»ºç¼“å­˜
- âœ… ä¹‹åçš„åŠ è½½è‡ªåŠ¨ä»ç¼“å­˜è¯»å–
- âœ… å®Œå…¨é€æ˜ï¼Œæ— éœ€ä»»ä½•æ‰‹åŠ¨æ“ä½œ
- âœ… é»˜è®¤å¯ç”¨ï¼Œå¼€ç®±å³ç”¨

## ğŸš€ ä½¿ç”¨æ–¹æ³•

### åŸºæœ¬ä½¿ç”¨ï¼ˆæ¨èï¼‰

```python
from pathlib import Path
from src.dataset.mnist_dataset import MNISTDataset

# ç¬¬ä¸€æ¬¡è¿è¡Œ
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train'
)
# âœ“ è‡ªåŠ¨æ£€æµ‹ç¼“å­˜ä¸å­˜åœ¨
# âœ“ åŠ è½½æ•°æ®
# âœ“ è‡ªåŠ¨ä¿å­˜åˆ°ç¼“å­˜

# ç¬¬äºŒæ¬¡è¿è¡Œ
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train'
)
# âœ“ è‡ªåŠ¨æ£€æµ‹ç¼“å­˜å­˜åœ¨
# âœ“ ç›´æ¥ä»ç¼“å­˜åŠ è½½ï¼ˆå¿«é€Ÿï¼ï¼‰
```

**å°±è¿™ä¹ˆç®€å•ï¼** æ— éœ€è°ƒç”¨ä»»ä½•ç¼“å­˜æ–¹æ³•ã€‚

---

## ğŸ“– è¯¦ç»†è¯´æ˜

### å·¥ä½œæµç¨‹

```
åˆå§‹åŒ–æ•°æ®é›†
    â”‚
    â”œâ”€â†’ æ£€æŸ¥ç¼“å­˜æ˜¯å¦å­˜åœ¨
    â”‚       â”‚
    â”‚       â”œâ”€ å­˜åœ¨ â†’ ä»ç¼“å­˜åŠ è½½ â†’ å®Œæˆ âœ“
    â”‚       â”‚
    â”‚       â””â”€ ä¸å­˜åœ¨ â†“
    â”‚
    â”œâ”€â†’ æ­£å¸¸åŠ è½½æ•°æ®
    â”‚
    â””â”€â†’ è‡ªåŠ¨ä¿å­˜åˆ°ç¼“å­˜ â†’ å®Œæˆ âœ“
```

### é…ç½®é€‰é¡¹

#### 1. é»˜è®¤è¡Œä¸ºï¼ˆæ¨èï¼‰

```python
# ç¼“å­˜é»˜è®¤å¯ç”¨ï¼Œæ— éœ€ä»»ä½•é…ç½®
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train'
)
```

#### 2. ç¦ç”¨ç¼“å­˜

```python
# å¼€å‘è°ƒè¯•æ—¶å¯èƒ½éœ€è¦ç¦ç”¨
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train',
    enable_cache=False  # ç¦ç”¨ç¼“å­˜
)
```

#### 3. å¼ºåˆ¶é‡å»ºç¼“å­˜

```python
# æ•°æ®æ›´æ–°åéœ€è¦é‡å»ºç¼“å­˜
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train',
    force_rebuild_cache=True  # å¿½ç•¥ç°æœ‰ç¼“å­˜ï¼Œé‡æ–°æ„å»º
)
```

#### 4. ç‰ˆæœ¬ç®¡ç†

```python
# å®éªŒ1
dataset_exp1 = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train',
    cache_version='exp1'  # ä½¿ç”¨ç‹¬ç«‹çš„ç‰ˆæœ¬
)

# å®éªŒ2
dataset_exp2 = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train',
    cache_version='exp2'  # ä¸åŒç‰ˆæœ¬äº’ä¸å¹²æ‰°
)
```

#### 5. è‡ªå®šä¹‰ç¼“å­˜ç›®å½•

```python
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train',
    cache_root=Path("/path/to/custom/cache")
)
```

#### 6. æŒ‡å®šç¼“å­˜æ ¼å¼

```python
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train',
    cache_format='pt'  # å¯é€‰: 'pkl', 'pt', 'json'
)
```

---

## ğŸ“‚ ç¼“å­˜ç›®å½•ç»“æ„

```
cache/
â””â”€â”€ datasets/                # æ•°æ®é›†ç¼“å­˜æ ¹ç›®å½•
    â”œâ”€â”€ MNIST/               # æ•°æ®é›†åç§°ï¼ˆè‡ªåŠ¨åˆ›å»ºï¼‰
    â”‚   â”œâ”€â”€ v1/              # ç‰ˆæœ¬å·ï¼ˆé»˜è®¤v1ï¼‰
    â”‚   â”‚   â”œâ”€â”€ train_xxx.pkl         # è®­ç»ƒé›†ç¼“å­˜
    â”‚   â”‚   â”œâ”€â”€ train_xxx.meta.json   # å…ƒæ•°æ®
    â”‚   â”‚   â”œâ”€â”€ valid_xxx.pkl
    â”‚   â”‚   â”œâ”€â”€ valid_xxx.meta.json
    â”‚   â”‚   â”œâ”€â”€ test_xxx.pkl
    â”‚   â”‚   â””â”€â”€ test_xxx.meta.json
    â”‚   â””â”€â”€ v2/
    â”‚       â””â”€â”€ ...
    â””â”€â”€ {å…¶ä»–æ•°æ®é›†}/
```

---

## ğŸ“ é€‚ç”¨åœºæ™¯

### âœ… é€‚åˆä½¿ç”¨ç¼“å­˜

- éœ€è¦é¢„å¤„ç†çš„å¤§å‹æ•°æ®é›†
- ä»ç½‘ç»œæˆ–æ…¢é€Ÿå­˜å‚¨åŠ è½½çš„æ•°æ®
- å¤šæ¬¡è®­ç»ƒ/å®éªŒçš„åœºæ™¯
- å¤æ‚çš„æ•°æ®å¢å¼ºæµç¨‹

### âŒ å»ºè®®ç¦ç”¨ç¼“å­˜

- å¼€å‘è°ƒè¯•é˜¶æ®µï¼ˆæ•°æ®é›†ä»£ç åœ¨ä¿®æ”¹ï¼‰
- ç£ç›˜ç©ºé—´éå¸¸æœ‰é™
- æ•°æ®é¢‘ç¹æ›´æ–°
- å•æ¬¡è®­ç»ƒ

---

## ğŸ”§ åœ¨è‡ªå®šä¹‰æ•°æ®é›†ä¸­å®ç°

å¦‚æœä½ è¦åˆ›å»ºè‡ªå·±çš„æ•°æ®é›†ç±»ï¼ŒæŒ‰ä»¥ä¸‹æ¨¡å¼å®ç°ï¼š

```python
from pathlib import Path
from src.dataset.custom_dataset import CustomDataset

class MyDataset(CustomDataset):
    @staticmethod
    def name() -> str:
        return "my_dataset"
    
    def __init__(self, root_dir: Path, split: str, **kwargs):
        # 1. è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°ï¼ˆä¼šè‡ªåŠ¨å°è¯•ä»ç¼“å­˜åŠ è½½ï¼‰
        super().__init__(root_dir, split, **kwargs)
        
        # 2. å¦‚æœä»ç¼“å­˜åŠ è½½æˆåŠŸï¼Œç›´æ¥è¿”å›
        if self._cache_loaded:
            return
        
        # 3. ç¼“å­˜ä¸å­˜åœ¨ï¼Œæ­£å¸¸åŠ è½½æ•°æ®
        self._load_data()
        
        # 4. è‡ªåŠ¨ä¿å­˜åˆ°ç¼“å­˜
        self._save_to_cache_if_needed()
    
    def _load_data(self):
        """å®é™…çš„æ•°æ®åŠ è½½é€»è¾‘"""
        # åŠ è½½æ•°æ®...
        self.samples = [...]  # åŠ è½½æ ·æœ¬
        self.n = len(self.samples)
    
    def __getitem__(self, index):
        """è·å–æ•°æ®é¡¹"""
        # ä»ç¼“å­˜åŠ è½½çš„æƒ…å†µ
        if self._cache_loaded:
            return self.samples[index]
        # æ­£å¸¸åŠ è½½çš„æƒ…å†µ
        return self._process_sample(index)
    
    # å®ç°å¿…éœ€çš„é™æ€æ–¹æ³•
    @staticmethod
    def get_train_dataset(root_dir: Path, **kwargs):
        return MyDataset(root_dir, 'train', **kwargs)
    
    @staticmethod
    def get_valid_dataset(root_dir: Path, **kwargs):
        return MyDataset(root_dir, 'valid', **kwargs)
    
    @staticmethod
    def get_test_dataset(root_dir: Path, **kwargs):
        return MyDataset(root_dir, 'test', **kwargs)
```

### å®ç°è¦ç‚¹

1. **è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°**: `super().__init__(root_dir, split, **kwargs)` ä¼šè‡ªåŠ¨å¤„ç†ç¼“å­˜åŠ è½½
2. **æ£€æŸ¥ `_cache_loaded`**: å¦‚æœä¸ºTrueï¼Œè¯´æ˜æ•°æ®å·²ä»ç¼“å­˜åŠ è½½ï¼Œç›´æ¥è¿”å›
3. **åŠ è½½æ•°æ®**: æ­£å¸¸åŠ è½½æ•°æ®åˆ° `self.samples`
4. **è°ƒç”¨ `_save_to_cache_if_needed()`**: è‡ªåŠ¨ä¿å­˜åˆ°ç¼“å­˜

---

## ğŸ› ï¸ å‘½ä»¤è¡Œå·¥å…·

è™½ç„¶ç¼“å­˜æ˜¯è‡ªåŠ¨çš„ï¼Œä½†ä½ ä»å¯ä»¥ä½¿ç”¨å‘½ä»¤è¡Œå·¥å…·ç®¡ç†ï¼š

```bash
# æŸ¥çœ‹æ‰€æœ‰ç¼“å­˜
python tools/dataset_cache_tool.py list

# æŸ¥çœ‹ç‰¹å®šæ•°æ®é›†çš„ç¼“å­˜
python tools/dataset_cache_tool.py info MNIST

# æ¸…é™¤ç¼“å­˜
python tools/dataset_cache_tool.py clear MNIST --split train

# æ¸…é™¤æ‰€æœ‰ç¼“å­˜
python tools/dataset_cache_tool.py clear-all

# éªŒè¯ç¼“å­˜å®Œæ•´æ€§
python tools/dataset_cache_tool.py verify MNIST
```

---

## ğŸ“Š æ€§èƒ½æå‡

å…¸å‹çš„æ€§èƒ½æå‡ï¼š

| åœºæ™¯ | æ—¶é—´ | è¯´æ˜ |
|------|------|------|
| ç¬¬1æ¬¡åŠ è½½ï¼ˆåˆ›å»ºç¼“å­˜ï¼‰ | 2.5s | æ­£å¸¸åŠ è½½ + ä¿å­˜ç¼“å­˜ |
| ç¬¬2æ¬¡åŠ è½½ï¼ˆä»ç¼“å­˜ï¼‰   | 0.3s | ç›´æ¥ä»ç¼“å­˜è¯»å– |
| **åŠ é€Ÿæ¯”** | **8.3x** | æ˜¾è‘—æå‡ |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ•°æ®æ›´æ–°

å½“åŸå§‹æ•°æ®æ›´æ–°æ—¶ï¼Œè®°å¾—é‡å»ºç¼“å­˜ï¼š

```python
dataset = MyDataset(
    root_dir=path,
    split='train',
    force_rebuild_cache=True  # å¼ºåˆ¶é‡å»º
)
```

æˆ–ä½¿ç”¨å‘½ä»¤è¡Œæ¸…é™¤ç¼“å­˜ï¼š

```bash
python tools/dataset_cache_tool.py clear my_dataset
```

### 2. ç£ç›˜ç©ºé—´

ç¼“å­˜ä¼šå ç”¨é¢å¤–çš„ç£ç›˜ç©ºé—´ï¼Œå®šæœŸæ£€æŸ¥å’Œæ¸…ç†ï¼š

```bash
# æŸ¥çœ‹ç¼“å­˜å ç”¨
python tools/dataset_cache_tool.py list

# æ¸…é™¤ä¸éœ€è¦çš„ç¼“å­˜
python tools/dataset_cache_tool.py clear old_dataset
```

### 3. å¤šè¿›ç¨‹è®­ç»ƒ

- âœ… å…ˆåœ¨å•è¿›ç¨‹ä¸­åŠ è½½ä¸€æ¬¡æ•°æ®é›†ï¼ˆåˆ›å»ºç¼“å­˜ï¼‰
- âœ… ç„¶ååœ¨å¤šè¿›ç¨‹è®­ç»ƒä¸­ä½¿ç”¨ï¼ˆä»ç¼“å­˜åŠ è½½ï¼‰
- âŒ é¿å…å¤šä¸ªè¿›ç¨‹åŒæ—¶åˆ›å»ºåŒä¸€ä¸ªç¼“å­˜

### 4. é…ç½®ä¸€è‡´æ€§

ç¡®ä¿åŠ è½½æ—¶çš„é…ç½®ä¸ä¿å­˜æ—¶ä¸€è‡´ï¼Œå¦åˆ™ä¼šåˆ›å»ºæ–°çš„ç¼“å­˜ï¼š

```python
# ç¬¬ä¸€æ¬¡
dataset1 = MyDataset(root_dir=path, split='train', some_param=10)

# ç¬¬äºŒæ¬¡ - ä¼šä½¿ç”¨ç›¸åŒçš„ç¼“å­˜
dataset2 = MyDataset(root_dir=path, split='train', some_param=10)

# ç¬¬ä¸‰æ¬¡ - é…ç½®ä¸åŒï¼Œä¼šåˆ›å»ºæ–°çš„ç¼“å­˜
dataset3 = MyDataset(root_dir=path, split='train', some_param=20)
```

---

## ğŸ¯ æœ€ä½³å®è·µ

### å¼€å‘é˜¶æ®µ

```python
# ç¦ç”¨ç¼“å­˜ï¼Œä¾¿äºå¿«é€Ÿè¿­ä»£
dataset = MyDataset(
    root_dir=path,
    split='train',
    enable_cache=False
)
```

### è®­ç»ƒé˜¶æ®µ

```python
# ä½¿ç”¨é»˜è®¤é…ç½®ï¼Œè‡ªåŠ¨ç¼“å­˜
dataset = MyDataset(
    root_dir=path,
    split='train'
)
```

### å®éªŒç®¡ç†

```python
# ä¸ºä¸åŒå®éªŒä½¿ç”¨ä¸åŒç‰ˆæœ¬
dataset_baseline = MyDataset(
    root_dir=path,
    split='train',
    cache_version='baseline'
)

dataset_improved = MyDataset(
    root_dir=path,
    split='train',
    cache_version='improved'
)
```

---

## ğŸ“š ç¤ºä¾‹ç¨‹åº

è¿è¡Œè‡ªåŠ¨ç¼“å­˜æ¼”ç¤ºï¼š

```bash
conda run -n ntrain python examples/auto_cache_demo.py
```

è¯¥æ¼”ç¤ºåŒ…å«ï¼š
- âœ… è‡ªåŠ¨ç¼“å­˜åŸºæœ¬ç”¨æ³•
- âœ… æ€§èƒ½å¯¹æ¯”
- âœ… ç¦ç”¨ç¼“å­˜
- âœ… å¼ºåˆ¶é‡å»º
- âœ… å¤šåˆ’åˆ†ç¼“å­˜
- âœ… ç‰ˆæœ¬ç®¡ç†

---

## ğŸ†š ä¸æ—§ç‰ˆæœ¬çš„å¯¹æ¯”

### æ—§æ–¹å¼ï¼ˆæ‰‹åŠ¨ï¼‰

```python
dataset = MyDataset(root_dir=path, split='train', enable_cache=True)

# éœ€è¦æ‰‹åŠ¨è°ƒç”¨
if not dataset.load_from_cache():
    dataset.save_to_cache()
```

### æ–°æ–¹å¼ï¼ˆè‡ªåŠ¨ï¼‰âœ¨

```python
# å®Œå…¨è‡ªåŠ¨ï¼Œæ— éœ€ä»»ä½•æ“ä½œ
dataset = MyDataset(root_dir=path, split='train')
```

---

## ğŸ‰ æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

1. **å®Œå…¨è‡ªåŠ¨** - æ— éœ€ä»»ä½•æ‰‹åŠ¨æ“ä½œ
2. **é»˜è®¤å¯ç”¨** - å¼€ç®±å³ç”¨
3. **å®Œå…¨é€æ˜** - å¯¹ä½¿ç”¨è€…é€æ˜
4. **æ€§èƒ½æ˜¾è‘—** - 2-10å€åŠ é€Ÿ
5. **æ˜“äºé›†æˆ** - ç»§æ‰¿CustomDatasetå³å¯è·å¾—

### ä½¿ç”¨å»ºè®®

- âœ… è®­ç»ƒæ—¶ä½¿ç”¨é»˜è®¤é…ç½®ï¼ˆè‡ªåŠ¨ç¼“å­˜ï¼‰
- âœ… å¼€å‘æ—¶å¯ä»¥ç¦ç”¨ç¼“å­˜
- âœ… æ•°æ®æ›´æ–°åå¼ºåˆ¶é‡å»º
- âœ… ä½¿ç”¨ç‰ˆæœ¬å·ç®¡ç†ä¸åŒå®éªŒ
- âœ… å®šæœŸæ¸…ç†ä¸éœ€è¦çš„ç¼“å­˜

---

**ç‰ˆæœ¬**: 2.0.0 (è‡ªåŠ¨ç¼“å­˜)  
**æ›´æ–°æ—¥æœŸ**: 2025-10-29

