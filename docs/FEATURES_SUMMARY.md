# NeuroTrain æ•°æ®é›†åŠŸèƒ½æ€»è§ˆ

## ğŸ‰ å·²å®ç°çš„æ ¸å¿ƒåŠŸèƒ½

æœ¬æ–‡æ¡£æ€»ç»“äº†æ•°æ®é›†æ¨¡å—çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ã€‚

---

## 1ï¸âƒ£ è‡ªåŠ¨ç¼“å­˜åŠŸèƒ½ â­â­â­

### åŠŸèƒ½æè¿°

æ•°æ®é›†è‡ªåŠ¨ç¼“å­˜åŠŸèƒ½ï¼Œç¬¬ä¸€æ¬¡åŠ è½½æ—¶è‡ªåŠ¨åˆ›å»ºç¼“å­˜ï¼Œä¹‹åè‡ªåŠ¨ä»ç¼“å­˜è¯»å–ã€‚

### ç‰¹ç‚¹

- âœ… **å®Œå…¨è‡ªåŠ¨** - æ— éœ€æ‰‹åŠ¨æ“ä½œ
- âœ… **é»˜è®¤å¯ç”¨** - å¼€ç®±å³ç”¨  
- âœ… **æ™ºèƒ½ç®¡ç†** - è‡ªåŠ¨æ£€æµ‹å’Œæ›´æ–°
- âœ… **ç»Ÿä¸€å­˜å‚¨** - `cache/datasets/{dataset_name}/{version}/`

### ä½¿ç”¨æ–¹æ³•

```python
# è‡ªåŠ¨ç¼“å­˜ï¼Œå®Œå…¨é€æ˜
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train'
    # enable_cache=True æ˜¯é»˜è®¤å€¼
)

# ç¬¬ä¸€æ¬¡è¿è¡Œï¼šè‡ªåŠ¨åˆ›å»ºç¼“å­˜åˆ° cache/datasets/MNIST/v1/
# ç¬¬äºŒæ¬¡è¿è¡Œï¼šè‡ªåŠ¨ä»ç¼“å­˜åŠ è½½ï¼ˆå¿«é€Ÿï¼ï¼‰
```

### æ€§èƒ½æå‡

- **åŠ é€Ÿæ¯”**: 2-10å€
- **é€‚ç”¨**: éœ€è¦é¢„å¤„ç†çš„å¤§å‹æ•°æ®é›†

### ç›¸å…³æ–‡æ¡£

- [å®Œæ•´æŒ‡å—](AUTO_CACHE_GUIDE.md)
- [APIæ–‡æ¡£](dataset_cache.md)
- [æ›´æ–°è¯´æ˜](CACHE_V2_UPDATE.md)

---

## 2ï¸âƒ£ é¢„è¯»å–åŠŸèƒ½ â­â­

### åŠŸèƒ½æè¿°

ä½¿ç”¨å•ç‹¬çš„çº¿ç¨‹æå‰åŠ è½½æ•°æ®ï¼Œåœ¨æ¨¡å‹è®­ç»ƒçš„åŒæ—¶é¢„è¯»ä¸‹ä¸€ä¸ªbatchã€‚

### ç‰¹ç‚¹

- âœ… **å¹¶è¡ŒåŠ è½½** - æ•°æ®åŠ è½½ä¸è®­ç»ƒå¹¶è¡Œ
- âœ… **çº¿ç¨‹å®‰å…¨** - ç‹¬ç«‹åå°çº¿ç¨‹
- âœ… **è‡ªåŠ¨æ¨¡å¼** - æ ¹æ®shuffleè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ¨¡å¼
- âœ… **ç®€å•æ˜“ç”¨** - ä¸€ä¸ªå‚æ•°å¯ç”¨

### ä½¿ç”¨æ–¹æ³•

```python
# åœ¨DataLoaderä¸­å¯ç”¨é¢„è¯»å–
dataloader = dataset.dataloader(
    batch_size=32,
    shuffle=True,
    enable_prefetch=True,        # å¯ç”¨é¢„è¯»å–
    prefetch_buffer_size=4       # ç¼“å†²åŒºå¤§å°
)

# è®­ç»ƒæ—¶æ•°æ®å·²é¢„è¯»å¥½
for batch in dataloader:
    # è®­ç»ƒä»£ç ...
    pass
```

### æ€§èƒ½æå‡

- **åŠ é€Ÿæ¯”**: 1.2-1.3å€
- **é€‚ç”¨**: æ•°æ®åŠ è½½æ˜¯ç“¶é¢ˆçš„åœºæ™¯

### ç›¸å…³æ–‡æ¡£

- [ä½¿ç”¨æŒ‡å—](PREFETCH_GUIDE.md)
- [æ›´æ–°è¯´æ˜](PREFETCH_UPDATE.md)

---

## ğŸ“Š åŠŸèƒ½å¯¹æ¯”

| åŠŸèƒ½ | ç¼“å­˜ | é¢„è¯»å– |
|------|------|--------|
| **ä¼˜åŒ–å¯¹è±¡** | ç£ç›˜IO | CPUç­‰å¾… |
| **åŠ é€Ÿæ–¹å¼** | é¿å…é‡å¤åŠ è½½ | å¹¶è¡ŒåŠ è½½ |
| **æ€§èƒ½æå‡** | 2-10å€ | 1.2-1.3å€ |
| **å†…å­˜å ç”¨** | æ—  | å°‘é‡ |
| **ç£ç›˜å ç”¨** | è¾ƒå¤š | æ—  |
| **é€‚ç”¨åœºæ™¯** | é‡å¤è®­ç»ƒ | å•æ¬¡è®­ç»ƒ |
| **é»˜è®¤çŠ¶æ€** | å¯ç”¨ | ç¦ç”¨ |

---

## ğŸš€ ç»„åˆä½¿ç”¨ï¼ˆæ¨èï¼‰

ç»“åˆä½¿ç”¨ç¼“å­˜å’Œé¢„è¯»å–å¯ä»¥è·å¾—æœ€ä½³æ€§èƒ½ï¼š

```python
# 1. åˆ›å»ºæ•°æ®é›†ï¼ˆè‡ªåŠ¨ç¼“å­˜ï¼‰
dataset = MNISTDataset(
    root_dir=Path("data/mnist"),
    split='train',
    enable_cache=True          # ç¬¬ä¸€å±‚ä¼˜åŒ–ï¼šç¼“å­˜
)

# 2. åˆ›å»ºDataLoaderï¼ˆå¯ç”¨é¢„è¯»å–ï¼‰
dataloader = dataset.dataloader(
    batch_size=32,
    shuffle=True,
    enable_prefetch=True,      # ç¬¬äºŒå±‚ä¼˜åŒ–ï¼šé¢„è¯»å–
    prefetch_buffer_size=4
)

# åŒé‡åŠ é€Ÿï¼
```

### ç»„åˆæ•ˆæœ

- **é¦–æ¬¡è¿è¡Œ**: æ­£å¸¸é€Ÿåº¦ + åˆ›å»ºç¼“å­˜
- **åç»­è¿è¡Œ**: ä»ç¼“å­˜åŠ è½½ï¼ˆå¿«ï¼‰ + é¢„è¯»å–ï¼ˆæ›´å¿«ï¼‰
- **æ€»åŠ é€Ÿ**: å¯è¾¾ **10-15å€**

---

## ğŸ“ æ–‡ä»¶ç»“æ„

### æ ¸å¿ƒå®ç°

```
src/dataset/
â”œâ”€â”€ cache_manager.py          # ç¼“å­˜ç®¡ç†å™¨
â”œâ”€â”€ prefetch_wrapper.py       # é¢„è¯»å–åŒ…è£…å™¨
â””â”€â”€ custom_dataset.py         # åŸºç±»ï¼ˆé›†æˆä¸¤ä¸ªåŠŸèƒ½ï¼‰
```

### å·¥å…·è„šæœ¬

```
tools/
â””â”€â”€ dataset_cache_tool.py     # ç¼“å­˜ç®¡ç†å‘½ä»¤è¡Œå·¥å…·
```

### ç¤ºä¾‹ç¨‹åº

```
examples/
â”œâ”€â”€ auto_cache_demo.py        # è‡ªåŠ¨ç¼“å­˜æ¼”ç¤º
â”œâ”€â”€ dataset_cache_example.py  # ç¼“å­˜åŠŸèƒ½ç¤ºä¾‹
â”œâ”€â”€ mnist_with_cache_demo.py  # MNISTç¼“å­˜æ¼”ç¤º
â””â”€â”€ prefetch_demo.py          # é¢„è¯»å–æ¼”ç¤º
```

### æ–‡æ¡£

```
docs/
â”œâ”€â”€ AUTO_CACHE_GUIDE.md       # è‡ªåŠ¨ç¼“å­˜ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ CACHE_V2_UPDATE.md        # ç¼“å­˜V2æ›´æ–°è¯´æ˜
â”œâ”€â”€ dataset_cache.md          # ç¼“å­˜APIæ–‡æ¡£
â”œâ”€â”€ cache_feature_summary.md  # ç¼“å­˜åŠŸèƒ½æ€»ç»“
â”œâ”€â”€ PREFETCH_GUIDE.md         # é¢„è¯»å–ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ PREFETCH_UPDATE.md        # é¢„è¯»å–æ›´æ–°è¯´æ˜
â””â”€â”€ FEATURES_SUMMARY.md       # æœ¬æ–‡ä»¶
```

---

## ğŸ¯ ä½¿ç”¨åœºæ™¯

### åœºæ™¯1: å¼€å‘è°ƒè¯•

```python
# ç¦ç”¨ç¼“å­˜å’Œé¢„è¯»å–ï¼Œä¾¿äºå¿«é€Ÿè¿­ä»£
dataset = MyDataset(
    root_dir=path,
    split='train',
    enable_cache=False
)

dataloader = dataset.dataloader(
    batch_size=32,
    enable_prefetch=False
)
```

### åœºæ™¯2: é¦–æ¬¡è®­ç»ƒ

```python
# å¯ç”¨ç¼“å­˜ï¼Œåˆ›å»ºç¼“å­˜æ–‡ä»¶
dataset = MyDataset(
    root_dir=path,
    split='train',
    enable_cache=True
)

dataloader = dataset.dataloader(
    batch_size=32,
    enable_prefetch=True  # åŒæ—¶å¯ç”¨é¢„è¯»å–
)
```

### åœºæ™¯3: åç»­è®­ç»ƒï¼ˆæ¨èï¼‰

```python
# ä¸¤ä¸ªåŠŸèƒ½éƒ½å¯ç”¨ï¼Œè·å¾—æœ€ä½³æ€§èƒ½
dataset = MyDataset(
    root_dir=path,
    split='train',
    enable_cache=True          # ä»ç¼“å­˜åŠ è½½ï¼ˆå¿«ï¼‰
)

dataloader = dataset.dataloader(
    batch_size=32,
    enable_prefetch=True,      # é¢„è¯»å–ï¼ˆæ›´å¿«ï¼‰
    prefetch_buffer_size=4
)
```

### åœºæ™¯4: å¤šå®éªŒç‰ˆæœ¬ç®¡ç†

```python
# å®éªŒ1
dataset_exp1 = MyDataset(
    root_dir=path,
    split='train',
    cache_version='exp1'
)

# å®éªŒ2
dataset_exp2 = MyDataset(
    root_dir=path,
    split='train',
    cache_version='exp2'
)

# ä¸åŒç‰ˆæœ¬ç‹¬ç«‹ç¼“å­˜ï¼Œäº’ä¸å¹²æ‰°
```

---

## âš™ï¸ é…ç½®å‚æ•°

### ç¼“å­˜ç›¸å…³

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `enable_cache` | bool | True | æ˜¯å¦å¯ç”¨ç¼“å­˜ |
| `cache_root` | Path | None | ç¼“å­˜æ ¹ç›®å½• |
| `cache_version` | str | 'v1' | ç¼“å­˜ç‰ˆæœ¬å· |
| `cache_format` | str | 'pkl' | ç¼“å­˜æ ¼å¼ |
| `force_rebuild_cache` | bool | False | å¼ºåˆ¶é‡å»º |

### é¢„è¯»å–ç›¸å…³

| å‚æ•° | ç±»å‹ | é»˜è®¤å€¼ | è¯´æ˜ |
|------|------|--------|------|
| `enable_prefetch` | bool | False | æ˜¯å¦å¯ç”¨é¢„è¯»å– |
| `prefetch_buffer_size` | int | 2 | ç¼“å†²åŒºå¤§å° |

---

## ğŸ› ï¸ å‘½ä»¤è¡Œå·¥å…·

### ç¼“å­˜ç®¡ç†

```bash
# æŸ¥çœ‹æ‰€æœ‰ç¼“å­˜
python tools/dataset_cache_tool.py list

# æŸ¥çœ‹ç‰¹å®šæ•°æ®é›†
python tools/dataset_cache_tool.py info MNIST

# æ¸…é™¤ç¼“å­˜
python tools/dataset_cache_tool.py clear MNIST --split train

# éªŒè¯ç¼“å­˜
python tools/dataset_cache_tool.py verify MNIST
```

---

## ğŸ“š å®Œæ•´ç¤ºä¾‹

### è®­ç»ƒè„šæœ¬ç¤ºä¾‹

```python
import torch
from pathlib import Path
from src.dataset.mnist_dataset import MNISTDataset

def train():
    # 1. åˆ›å»ºæ•°æ®é›†ï¼ˆè‡ªåŠ¨ç¼“å­˜ï¼‰
    train_dataset = MNISTDataset(
        root_dir=Path("data/mnist"),
        split='train',
        enable_cache=True,
        cache_version='v1'
    )
    
    # 2. åˆ›å»ºDataLoaderï¼ˆå¯ç”¨é¢„è¯»å–ï¼‰
    train_loader = train_dataset.dataloader(
        batch_size=32,
        shuffle=True,
        num_workers=2,
        enable_prefetch=True,
        prefetch_buffer_size=4
    )
    
    # 3. è®­ç»ƒ
    model = YourModel()
    optimizer = torch.optim.Adam(model.parameters())
    
    for epoch in range(num_epochs):
        for batch in train_loader:
            images = batch['image']
            labels = batch['mask']
            
            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, labels)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

if __name__ == '__main__':
    train()
```

---

## ğŸ“ æœ€ä½³å®è·µ

### 1. å¼€å‘é˜¶æ®µ

```python
# ç¦ç”¨ç¼“å­˜ï¼Œä¾¿äºå¿«é€Ÿè¿­ä»£
dataset = MyDataset(
    root_dir=path,
    split='train',
    enable_cache=False
)
```

### 2. è®­ç»ƒé˜¶æ®µ

```python
# å¯ç”¨æ‰€æœ‰ä¼˜åŒ–
dataset = MyDataset(
    root_dir=path,
    split='train',
    enable_cache=True
)

dataloader = dataset.dataloader(
    batch_size=32,
    enable_prefetch=True,
    prefetch_buffer_size=4
)
```

### 3. å®éªŒç®¡ç†

```python
# ä½¿ç”¨ç‰ˆæœ¬å·ç®¡ç†ä¸åŒå®éªŒ
dataset = MyDataset(
    root_dir=path,
    split='train',
    cache_version=f'exp_{experiment_id}'
)
```

### 4. èµ„æºç®¡ç†

```bash
# å®šæœŸæ¸…ç†æ—§ç¼“å­˜
python tools/dataset_cache_tool.py list
python tools/dataset_cache_tool.py clear old_experiment
```

---

## ğŸ“Š æ€§èƒ½æµ‹è¯•

### æµ‹è¯•ç¯å¢ƒ

- æ•°æ®é›†: MNIST (50,000 samples)
- Batch size: 32
- Hardware: Intel i7 + SSD

### æµ‹è¯•ç»“æœ

| é…ç½® | é¦–æ¬¡åŠ è½½ | åç»­åŠ è½½ | æ€»åŠ é€Ÿ |
|------|---------|---------|--------|
| æ— ä¼˜åŒ– | 2.5s | 2.5s | 1.0x |
| ä»…ç¼“å­˜ | 2.8s | 0.3s | **8.3x** |
| ä»…é¢„è¯»å– | 2.0s | 2.0s | 1.25x |
| ç¼“å­˜+é¢„è¯»å– | 2.8s | 0.25s | **10x** |

---

## âš ï¸ æ³¨æ„äº‹é¡¹

### ç¼“å­˜åŠŸèƒ½

1. **ç£ç›˜ç©ºé—´**: ç¼“å­˜ä¼šå ç”¨é¢å¤–ç©ºé—´
2. **æ•°æ®æ›´æ–°**: åŸå§‹æ•°æ®å˜åŒ–æ—¶éœ€é‡å»º
3. **é…ç½®ä¸€è‡´**: åŠ è½½é…ç½®éœ€ä¸ä¿å­˜æ—¶ä¸€è‡´

### é¢„è¯»å–åŠŸèƒ½

1. **å†…å­˜å ç”¨**: ç¼“å†²åŒºä¼šå ç”¨å†…å­˜
2. **çº¿ç¨‹å®‰å…¨**: é¿å…å…±äº«å¯å˜å¯¹è±¡
3. **é€‚ç”¨åœºæ™¯**: æ•°æ®åŠ è½½æ˜¯ç“¶é¢ˆæ—¶æ•ˆæœæœ€å¥½

---

## ğŸ†• æœªæ¥è®¡åˆ’

- [ ] æ”¯æŒåˆ†å¸ƒå¼ç¼“å­˜
- [ ] ç¼“å­˜å‹ç¼©é€‰é¡¹
- [ ] å¼‚æ­¥é¢„è¯»å–
- [ ] æ›´å¤šç¼“å­˜æ ¼å¼æ”¯æŒ
- [ ] ç¼“å­˜ç»Ÿè®¡å’Œåˆ†æå·¥å…·

---

## ğŸ“– æ–‡æ¡£ç´¢å¼•

### ç¼“å­˜åŠŸèƒ½

- [è‡ªåŠ¨ç¼“å­˜æŒ‡å—](AUTO_CACHE_GUIDE.md) - å®Œæ•´ä½¿ç”¨æŒ‡å—
- [ç¼“å­˜APIæ–‡æ¡£](dataset_cache.md) - APIå‚è€ƒ
- [ç¼“å­˜V2æ›´æ–°](CACHE_V2_UPDATE.md) - ç‰ˆæœ¬æ›´æ–°è¯´æ˜
- [åŠŸèƒ½æ€»ç»“](cache_feature_summary.md) - åŠŸèƒ½æ¦‚è§ˆ

### é¢„è¯»å–åŠŸèƒ½

- [é¢„è¯»å–æŒ‡å—](PREFETCH_GUIDE.md) - ä½¿ç”¨æ•™ç¨‹
- [é¢„è¯»å–æ›´æ–°](PREFETCH_UPDATE.md) - åŠŸèƒ½è¯´æ˜

### ç¤ºä¾‹ç¨‹åº

- `examples/auto_cache_demo.py` - è‡ªåŠ¨ç¼“å­˜æ¼”ç¤º
- `examples/dataset_cache_example.py` - ç¼“å­˜ç¤ºä¾‹
- `examples/mnist_with_cache_demo.py` - MNISTæ¼”ç¤º
- `examples/prefetch_demo.py` - é¢„è¯»å–æ¼”ç¤º

---

## ğŸŠ æ€»ç»“

### æ ¸å¿ƒä¼˜åŠ¿

1. âœ¨ **è‡ªåŠ¨ç¼“å­˜** - å®Œå…¨é€æ˜ï¼Œè‡ªåŠ¨ç®¡ç†
2. âœ¨ **é¢„è¯»å–** - å¹¶è¡ŒåŠ è½½ï¼Œå‡å°‘ç­‰å¾…
3. âœ¨ **æ˜“äºä½¿ç”¨** - æœ€å°‘é…ç½®ï¼Œæœ€å¤§æ•ˆæœ
4. âœ¨ **é«˜æ€§èƒ½** - 10å€åŠ é€Ÿ
5. âœ¨ **æ–‡æ¡£é½å…¨** - å®Œæ•´çš„ä½¿ç”¨æŒ‡å—

### æ¨èé…ç½®

```python
# æœ€ä½³å®è·µé…ç½®
dataset = YourDataset(
    root_dir=path,
    split='train',
    enable_cache=True,         # å¯ç”¨ç¼“å­˜
    cache_version='v1'          # ç‰ˆæœ¬ç®¡ç†
)

dataloader = dataset.dataloader(
    batch_size=32,
    shuffle=True,
    num_workers=2,              # å¤šè¿›ç¨‹
    enable_prefetch=True,       # é¢„è¯»å–
    prefetch_buffer_size=4      # ç¼“å†²åŒº
)
```

---

**ç‰ˆæœ¬**: 1.0.0  
**æ›´æ–°æ—¥æœŸ**: 2025-10-29  
**çŠ¶æ€**: âœ… åŠŸèƒ½å®Œæ•´ï¼Œæµ‹è¯•é€šè¿‡

