# Dataset æ¨¡å—æ–‡æ¡£

## æ¦‚è¿°

Datasetæ¨¡å—æ˜¯NeuroTrainçš„æ ¸å¿ƒç»„ä»¶ä¹‹ä¸€ï¼Œè´Ÿè´£æ•°æ®çš„åŠ è½½ã€é¢„å¤„ç†å’Œå¢å¼ºã€‚è¯¥æ¨¡å—æä¾›äº†çµæ´»çš„æ•°æ®é›†ç®¡ç†ç³»ç»Ÿï¼Œæ”¯æŒå¤šç§åŒ»å­¦å›¾åƒæ•°æ®é›†ã€æ ‡å‡†è®¡ç®—æœºè§†è§‰æ•°æ®é›†ï¼Œä»¥åŠæ‰©æ•£æ¨¡å‹æ•°æ®é›†ã€‚

## ä¸»è¦ç‰¹æ€§

- ğŸ¯ **ç»Ÿä¸€çš„æ•°æ®é›†æ¥å£**: æ‰€æœ‰æ•°æ®é›†éƒ½éµå¾ªç»Ÿä¸€çš„æ¥å£è®¾è®¡
- ğŸ”„ **æ··åˆæ•°æ®é›†æ”¯æŒ**: å¯ä»¥æ··åˆä½¿ç”¨å¤šä¸ªæ•°æ®é›†è¿›è¡Œè®­ç»ƒ
- ğŸ² **æ™ºèƒ½é‡‡æ ·ç­–ç•¥**: æ”¯æŒæƒé‡é‡‡æ ·ã€å¹³è¡¡é‡‡æ ·ã€ä¼˜å…ˆçº§é‡‡æ ·
- ğŸ”§ **ä¸°å¯Œçš„æ•°æ®å¢å¼º**: é›†æˆå¤šç§æ•°æ®å¢å¼ºæ–¹æ³•
- ğŸ¤– **LLMé©±åŠ¨åˆ†æ**: ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹åˆ†æå’Œç­›é€‰æ•°æ®
- ğŸ“Š **æ•°æ®é›†æ³¨å†Œè¡¨**: è‡ªåŠ¨ç®¡ç†æ‰€æœ‰å¯ç”¨æ•°æ®é›†
- ğŸŒ **è‡ªåŠ¨ä¸‹è½½**: æ”¯æŒè‡ªåŠ¨ä¸‹è½½æ ‡å‡†æ•°æ®é›†

## æ•°æ®é›†æ³¨å†Œè¡¨

æ‰€æœ‰å¯ç”¨çš„æ•°æ®é›†éƒ½åœ¨ `DATASET_REGISTRY` ä¸­æ³¨å†Œï¼Œå¯ä»¥é€šè¿‡åç§°å¿«é€Ÿè®¿é—®ã€‚

### åŒ»å­¦å›¾åƒæ•°æ®é›†

#### è§†ç½‘è†œè¡€ç®¡åˆ†å‰²
- **drive**: DRIVEæ•°æ®é›†
- **medical/chasedb1**: CHASE-DB1æ•°æ®é›†
- **medical/stare**: STAREæ•°æ®é›†

#### çš®è‚¤ç—…å˜
- **medical/isic2016**: ISIC 2016 çš®è‚¤ç—…å˜åˆ†å‰²
- **medical/isic2017**: ISIC 2017 çš®è‚¤ç—…å˜åˆ†ç±»
- **medical/isic2018**: ISIC 2018 çš®è‚¤ç—…å˜åˆ†æ

#### 3DåŒ»å­¦å›¾åƒ
- **medical/btcv**: BTCVå¤šå™¨å®˜åˆ†å‰²
- **medical/brats2020**: BraTS 2020è„‘è‚¿ç˜¤åˆ†å‰²

#### ç»†èƒåˆ†å‰²
- **medical/bowl2018**: Data Science Bowl 2018æ ¸åˆ†å‰²

#### å¤šæ¨¡æ€åŒ»å­¦æ•°æ®
- **medical/vqarad**: VQA-RADåŒ»å­¦è§†è§‰é—®ç­”
- **medical/mri_brain_clip**: MRIè„‘éƒ¨CLIPæ•°æ®é›†

### æ ‡å‡†è®¡ç®—æœºè§†è§‰æ•°æ®é›†

#### å›¾åƒåˆ†ç±»
- **mnist**: MNISTæ‰‹å†™æ•°å­—
- **cifar10**: CIFAR-10å›¾åƒåˆ†ç±»
- **cifar100**: CIFAR-100å›¾åƒåˆ†ç±»
- **imagenet**: ImageNetå¤§è§„æ¨¡å›¾åƒåˆ†ç±»

#### ç›®æ ‡æ£€æµ‹å’Œåˆ†å‰²
- **coco**: COCOæ•°æ®é›†ï¼ˆæ£€æµ‹ã€åˆ†å‰²ã€å…³é”®ç‚¹ï¼‰
- **coco/detection**: COCOç›®æ ‡æ£€æµ‹
- **coco/segmentation**: COCOå®ä¾‹åˆ†å‰²
- **coco/keypoint**: COCOå…³é”®ç‚¹æ£€æµ‹
- **coco/caption**: COCOå›¾åƒæè¿°

### æ‰©æ•£æ¨¡å‹æ•°æ®é›†

- **diffusion**: é€šç”¨æ‰©æ•£æ¨¡å‹æ•°æ®é›†
- **unconditional_diffusion**: æ— æ¡ä»¶æ‰©æ•£æ¨¡å‹
- **conditional_diffusion**: æ¡ä»¶æ‰©æ•£æ¨¡å‹
- **text_to_image_diffusion**: æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£æ¨¡å‹

## æ ¸å¿ƒç±»å’Œå‡½æ•°

### 1. æ•°æ®é›†è·å–å‡½æ•°

```python
from src.dataset import (
    get_dataset,
    get_train_dataset,
    get_test_dataset,
    get_valid_dataset,
    get_train_valid_test_dataloader
)

# è·å–å®Œæ•´æ•°æ®é›†
dataset = get_dataset(config)

# è·å–è®­ç»ƒ/æµ‹è¯•/éªŒè¯æ•°æ®é›†
train_dataset = get_train_dataset(config)
test_dataset = get_test_dataset(config)
valid_dataset = get_valid_dataset(config)

# è·å–æ•°æ®åŠ è½½å™¨
train_loader, valid_loader, test_loader = get_train_valid_test_dataloader(config)
```

### 2. CustomDataset - è‡ªå®šä¹‰æ•°æ®é›†åŸºç±»

`CustomDataset` æ˜¯æ‰€æœ‰è‡ªå®šä¹‰æ•°æ®é›†çš„åŸºç±»ï¼Œæä¾›äº†æ ‡å‡†çš„æ•°æ®é›†æ¥å£ã€‚

```python
from src.dataset.custom_dataset import CustomDataset

class MyDataset(CustomDataset):
    def __init__(self, root_dir, transform=None):
        super().__init__()
        self.root_dir = root_dir
        self.transform = transform
        # åˆå§‹åŒ–æ•°æ®åˆ—è¡¨
        self._load_data()
    
    def _load_data(self):
        # åŠ è½½æ•°æ®è·¯å¾„ç­‰
        pass
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        # åŠ è½½å’Œå¤„ç†å•ä¸ªæ ·æœ¬
        image, mask = self._load_sample(idx)
        
        if self.transform:
            image, mask = self.transform(image, mask)
        
        return image, mask
```

### 3. HybridDataset - æ··åˆæ•°æ®é›†

`HybridDataset` å…è®¸æ··åˆä½¿ç”¨å¤šä¸ªæ•°æ®é›†è¿›è¡Œè®­ç»ƒï¼Œæ”¯æŒå¤šç§é‡‡æ ·ç­–ç•¥ã€‚

```python
from src.dataset.hybrid_dataset import HybridDataset, create_hybrid_dataset_from_config

# æ–¹æ³•1: ç›´æ¥åˆ›å»º
dataset1 = get_dataset(config1)
dataset2 = get_dataset(config2)

hybrid_dataset = HybridDataset(
    datasets=[dataset1, dataset2],
    sampling_strategy="weighted",  # é‡‡æ ·ç­–ç•¥
    weights=[0.7, 0.3],             # é‡‡æ ·æƒé‡
    ratios=[0.6, 0.4]               # æ•°æ®é›†æ¯”ä¾‹
)

# æ–¹æ³•2: ä»é…ç½®åˆ›å»º
hybrid_dataset = create_hybrid_dataset_from_config(config)
```

#### é‡‡æ ·ç­–ç•¥

1. **weighted (æƒé‡é‡‡æ ·)**
   - æ ¹æ®æŒ‡å®šæƒé‡ä»å„æ•°æ®é›†é‡‡æ ·
   - é€‚ç”¨äºæ•°æ®é›†è´¨é‡ä¸åŒçš„æƒ…å†µ

2. **balanced (å¹³è¡¡é‡‡æ ·)**
   - ç¡®ä¿å„æ•°æ®é›†çš„æ ·æœ¬æ•°é‡å¹³è¡¡
   - é€‚ç”¨äºæ•°æ®é›†å¤§å°å·®å¼‚å¤§çš„æƒ…å†µ

3. **priority (ä¼˜å…ˆçº§é‡‡æ ·)**
   - æŒ‰ä¼˜å…ˆçº§é¡ºåºé‡‡æ ·
   - é€‚ç”¨äºæœ‰ä¸»æ¬¡æ•°æ®é›†çš„æƒ…å†µ

4. **sequential (é¡ºåºé‡‡æ ·)**
   - æŒ‰é¡ºåºä¾æ¬¡é‡‡æ ·å„æ•°æ®é›†
   - é€‚ç”¨äºè¯¾ç¨‹å­¦ä¹ åœºæ™¯

### 4. DiffusionDataset - æ‰©æ•£æ¨¡å‹æ•°æ®é›†

ä¸“é—¨ä¸ºæ‰©æ•£æ¨¡å‹è®¾è®¡çš„æ•°æ®é›†ç±»ã€‚

```python
from src.dataset.diffusion_dataset import (
    DiffusionDataset,
    UnconditionalDiffusionDataset,
    ConditionalDiffusionDataset,
    TextToImageDiffusionDataset,
    get_mnist_diffusion_dataset,
    get_cifar10_diffusion_dataset
)

# æ— æ¡ä»¶æ‰©æ•£
unconditional_dataset = UnconditionalDiffusionDataset(
    image_dir="path/to/images",
    image_size=(64, 64)
)

# æ¡ä»¶æ‰©æ•£ï¼ˆç±»åˆ«æ¡ä»¶ï¼‰
conditional_dataset = ConditionalDiffusionDataset(
    image_dir="path/to/images",
    label_file="path/to/labels.json",
    image_size=(64, 64),
    num_classes=10
)

# æ–‡æœ¬åˆ°å›¾åƒæ‰©æ•£
text_to_image_dataset = TextToImageDiffusionDataset(
    image_dir="path/to/images",
    caption_file="path/to/captions.json",
    image_size=(256, 256)
)

# ä½¿ç”¨é¢„å®šä¹‰æ•°æ®é›†
mnist_diffusion = get_mnist_diffusion_dataset(
    root="./data",
    train=True,
    download=True
)
```

### 5. LLMæ•°æ®åˆ†æå™¨

ä½¿ç”¨å¤§è¯­è¨€æ¨¡å‹åˆ†æå’Œç­›é€‰æ•°æ®é›†ã€‚

```python
from src.dataset.llm_data_analyzer import LLMDataAnalyzer

analyzer = LLMDataAnalyzer(
    model_name="gpt-4",
    api_key="your_api_key"
)

# åˆ†ææ•°æ®é›†
analysis = analyzer.analyze_dataset(dataset)

# æ ¹æ®æ¡ä»¶ç­›é€‰æ•°æ®
filtered_indices = analyzer.filter_by_criteria(
    dataset,
    criteria="Find images with clear blood vessels"
)

# ç”Ÿæˆæ•°æ®é›†ç»Ÿè®¡æŠ¥å‘Š
report = analyzer.generate_report(dataset)
```

## é…ç½®ç¤ºä¾‹

### å•æ•°æ®é›†é…ç½®

```toml
[dataset]
name = "drive"
root_dir = "data/drive"
is_rgb = true
train_split = 0.8
image_size = [512, 512]

[dataset.augmentation]
random_flip = true
random_rotation = true
rotation_range = 15
brightness_range = [0.8, 1.2]
```

### æ··åˆæ•°æ®é›†é…ç½®

```toml
[dataset]
name = "enhanced_hybrid"
datasets = ["drive", "medical/chasedb1", "medical/stare"]
sampling_strategy = "weighted"
ratios = [0.5, 0.3, 0.2]
weights = [1.0, 1.2, 0.8]

[dataset.drive]
root_dir = "data/drive"
is_rgb = true

[dataset."medical/chasedb1"]
root_dir = "data/chasedb1"
is_rgb = true

[dataset."medical/stare"]
root_dir = "data/stare"
is_rgb = true

[dataset.augmentation]
random_flip = true
random_rotation = true
elastic_deformation = true
```

### æ‰©æ•£æ¨¡å‹æ•°æ®é›†é…ç½®

```toml
[dataset]
name = "conditional_diffusion"
image_dir = "data/images"
label_file = "data/labels.json"
image_size = [64, 64]
num_classes = 10

[dataset.augmentation]
random_flip = true
color_jitter = true
```

## æ•°æ®å¢å¼º

NeuroTrainæ”¯æŒå¤šç§æ•°æ®å¢å¼ºæ–¹æ³•ï¼Œå¯ä»¥é€šè¿‡é…ç½®æ–‡ä»¶çµæ´»æ§åˆ¶ã€‚

### å¸¸ç”¨å¢å¼ºæ–¹æ³•

```python
from src.utils.transform import get_transforms

# è·å–å¢å¼ºå˜æ¢
transforms = get_transforms(config['dataset']['augmentation'])

# å¸¸ç”¨å¢å¼ºåŒ…æ‹¬ï¼š
augmentation = {
    # å‡ ä½•å˜æ¢
    "random_flip": True,           # éšæœºç¿»è½¬
    "random_rotation": True,       # éšæœºæ—‹è½¬
    "rotation_range": 15,          # æ—‹è½¬è§’åº¦èŒƒå›´
    "random_crop": True,           # éšæœºè£å‰ª
    "crop_size": [256, 256],      # è£å‰ªå¤§å°
    
    # é¢œè‰²å˜æ¢
    "brightness_range": [0.8, 1.2],  # äº®åº¦è°ƒæ•´
    "contrast_range": [0.8, 1.2],    # å¯¹æ¯”åº¦è°ƒæ•´
    "saturation_range": [0.8, 1.2],  # é¥±å’Œåº¦è°ƒæ•´
    "hue_range": [-0.1, 0.1],        # è‰²è°ƒè°ƒæ•´
    "color_jitter": True,             # é¢œè‰²æŠ–åŠ¨
    
    # å½¢å˜
    "elastic_deformation": True,   # å¼¹æ€§å˜å½¢
    "grid_distortion": True,       # ç½‘æ ¼æ‰­æ›²
    
    # å™ªå£°
    "gaussian_noise": True,        # é«˜æ–¯å™ªå£°
    "gaussian_blur": True,         # é«˜æ–¯æ¨¡ç³Š
    
    # åŒ»å­¦å›¾åƒç‰¹å®š
    "normalize": True,             # æ ‡å‡†åŒ–
    "clahe": True,                 # CLAHEå¯¹æ¯”åº¦å¢å¼º
}
```

### è‡ªå®šä¹‰å¢å¼º

```python
import albumentations as A
from albumentations.pytorch import ToTensorV2

# è‡ªå®šä¹‰å¢å¼ºæµç¨‹
custom_transform = A.Compose([
    A.Resize(512, 512),
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.5),
    A.Rotate(limit=15, p=0.5),
    A.RandomBrightnessContrast(p=0.3),
    A.GaussianBlur(blur_limit=(3, 7), p=0.2),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2()
])

# åœ¨æ•°æ®é›†ä¸­ä½¿ç”¨
dataset = MyDataset(root_dir, transform=custom_transform)
```

## æ•°æ®é‡‡æ ·

### éšæœºé‡‡æ ·

```python
from src.dataset import random_sample

# ä»æ•°æ®é›†ä¸­éšæœºé‡‡æ ·nä¸ªæ ·æœ¬
subset = random_sample(dataset, n=100)
```

### åˆ†å±‚é‡‡æ ·

```python
from torch.utils.data import WeightedRandomSampler

# ä¸ºä¸å¹³è¡¡æ•°æ®é›†åˆ›å»ºé‡‡æ ·å™¨
class_counts = [1000, 500, 200]  # å„ç±»åˆ«æ ·æœ¬æ•°
weights = [1.0/c for c in class_counts]
sample_weights = [weights[label] for label in labels]

sampler = WeightedRandomSampler(
    weights=sample_weights,
    num_samples=len(sample_weights),
    replacement=True
)

# åœ¨DataLoaderä¸­ä½¿ç”¨
loader = DataLoader(dataset, batch_size=32, sampler=sampler)
```

## æ•°æ®é¢„å¤„ç†

### æ ‡å‡†åŒ–

```python
# è®¡ç®—æ•°æ®é›†çš„å‡å€¼å’Œæ ‡å‡†å·®
from src.dataset import compute_dataset_stats

mean, std = compute_dataset_stats(dataset)

# ä½¿ç”¨è®¡ç®—çš„ç»Ÿè®¡å€¼è¿›è¡Œæ ‡å‡†åŒ–
normalize = A.Normalize(mean=mean, std=std)
```

### è°ƒæ•´å¤§å°å’Œè£å‰ª

```python
import albumentations as A

# å›ºå®šå¤§å°
resize = A.Resize(height=512, width=512)

# ä¿æŒé•¿å®½æ¯”
resize_keep_ratio = A.LongestMaxSize(max_size=512)
pad = A.PadIfNeeded(min_height=512, min_width=512, border_mode=0)

# éšæœºè£å‰ª
random_crop = A.RandomCrop(height=256, width=256)

# ä¸­å¿ƒè£å‰ª
center_crop = A.CenterCrop(height=256, width=256)
```

## æ•°æ®åŠ è½½ä¼˜åŒ–

### DataLoaderé…ç½®

```python
from torch.utils.data import DataLoader

# ä¼˜åŒ–çš„DataLoaderé…ç½®
loader = DataLoader(
    dataset,
    batch_size=32,
    shuffle=True,
    num_workers=4,        # å¤šè¿›ç¨‹åŠ è½½
    pin_memory=True,      # å›ºå®šå†…å­˜ï¼ŒåŠ é€Ÿä¼ è¾“
    persistent_workers=True,  # ä¿æŒworkersæ´»è·ƒ
    prefetch_factor=2     # é¢„å–æ•°æ®
)
```

### æ•°æ®é¢„åŠ è½½

```python
from src.dataset import PrefetchDataLoader

# é¢„å–æ•°æ®åŠ è½½å™¨
prefetch_loader = PrefetchDataLoader(
    loader,
    device='cuda'
)

# ä½¿ç”¨
for batch in prefetch_loader:
    # æ•°æ®å·²ç»åœ¨GPUä¸Š
    images, labels = batch
    ...
```

## å¸¸ç”¨æ•°æ®é›†ä½¿ç”¨ç¤ºä¾‹

### DRIVEæ•°æ®é›†

```python
from src.dataset import get_dataset

config = {
    'dataset': {
        'name': 'drive',
        'root_dir': 'data/drive',
        'is_rgb': True,
        'train_split': 0.8,
        'image_size': [512, 512]
    }
}

train_dataset = get_train_dataset(config)
test_dataset = get_test_dataset(config)

print(f"Training samples: {len(train_dataset)}")
print(f"Test samples: {len(test_dataset)}")
```

### COCOæ•°æ®é›†

```python
config = {
    'dataset': {
        'name': 'coco/detection',
        'root_dir': 'data/coco',
        'annotation_file': 'data/coco/annotations/instances_train2017.json',
        'year': 2017
    }
}

dataset = get_dataset(config)

# è·å–ä¸€ä¸ªæ ·æœ¬
image, target = dataset[0]
print(f"Image shape: {image.shape}")
print(f"Bounding boxes: {target['boxes']}")
print(f"Labels: {target['labels']}")
```

### CIFAR-10æ•°æ®é›†

```python
config = {
    'dataset': {
        'name': 'cifar10',
        'root_dir': 'data/cifar10',
        'train': True,
        'download': True
    }
}

dataset = get_dataset(config)

# æŸ¥çœ‹æ•°æ®é›†ä¿¡æ¯
print(f"Classes: {dataset.classes}")
print(f"Number of samples: {len(dataset)}")
```

## é«˜çº§åŠŸèƒ½

### æ•°æ®é›†æ‹†åˆ†

```python
from torch.utils.data import random_split

# æŒ‰æ¯”ä¾‹æ‹†åˆ†æ•°æ®é›†
total_size = len(dataset)
train_size = int(0.8 * total_size)
val_size = int(0.1 * total_size)
test_size = total_size - train_size - val_size

train_dataset, val_dataset, test_dataset = random_split(
    dataset, 
    [train_size, val_size, test_size]
)
```

### æ•°æ®é›†åˆå¹¶

```python
from torch.utils.data import ConcatDataset

# åˆå¹¶å¤šä¸ªæ•°æ®é›†
combined_dataset = ConcatDataset([dataset1, dataset2, dataset3])
```

### æ•°æ®é›†å­é›†

```python
from torch.utils.data import Subset

# åˆ›å»ºæ•°æ®é›†å­é›†
indices = [0, 1, 2, 10, 11, 12]  # é€‰æ‹©çš„ç´¢å¼•
subset = Subset(dataset, indices)
```

### è‡ªå®šä¹‰Collateå‡½æ•°

```python
def custom_collate_fn(batch):
    """è‡ªå®šä¹‰batchå¤„ç†å‡½æ•°"""
    images = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    
    # å¤„ç†ä¸åŒå¤§å°çš„å›¾åƒ
    images = torch.stack([pad_image(img, target_size) for img in images])
    labels = torch.tensor(labels)
    
    return images, labels

# åœ¨DataLoaderä¸­ä½¿ç”¨
loader = DataLoader(dataset, batch_size=32, collate_fn=custom_collate_fn)
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **ä½¿ç”¨é€‚å½“çš„num_workers**
   - CPUæ ¸å¿ƒæ•°çš„2-4å€
   - å¤ªå°‘ï¼šæ•°æ®åŠ è½½æˆä¸ºç“¶é¢ˆ
   - å¤ªå¤šï¼šå†…å­˜å ç”¨è¿‡é«˜

2. **å¯ç”¨pin_memory**
   - ä½¿ç”¨GPUè®­ç»ƒæ—¶å¯ç”¨
   - åŠ é€ŸCPUåˆ°GPUçš„æ•°æ®ä¼ è¾“

3. **æ•°æ®é¢„å¤„ç†**
   - å°†è€—æ—¶çš„é¢„å¤„ç†æ“ä½œç¦»çº¿å®Œæˆ
   - ä¿å­˜å¤„ç†åçš„æ•°æ®åˆ°ç£ç›˜

4. **æ•°æ®ç¼“å­˜**
   - å°æ•°æ®é›†å¯ä»¥å®Œå…¨åŠ è½½åˆ°å†…å­˜
   - ä½¿ç”¨RAM diskåŠ é€ŸIO

5. **æ··åˆç²¾åº¦**
   - ä½¿ç”¨float16å‡å°‘å†…å­˜å ç”¨
   - åŠ é€Ÿæ•°æ®ä¼ è¾“

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **æ•°æ®åŠ è½½é€Ÿåº¦æ…¢**
   - å¢åŠ num_workers
   - ä½¿ç”¨SSDè€ŒéHDD
   - å‡å°‘æ•°æ®å¢å¼ºæ“ä½œ

2. **å†…å­˜ä¸è¶³**
   - å‡å°batch_size
   - å‡å°‘num_workers
   - ä½¿ç”¨æ•°æ®ç”Ÿæˆå™¨è€Œéé¢„åŠ è½½

3. **æ•°æ®ä¸å¹³è¡¡**
   - ä½¿ç”¨WeightedRandomSampler
   - ä½¿ç”¨è¿‡é‡‡æ ·/æ¬ é‡‡æ ·
   - è°ƒæ•´æŸå¤±å‡½æ•°æƒé‡

4. **æ•°æ®å¢å¼ºæ•ˆæœä¸å¥½**
   - æ£€æŸ¥å¢å¼ºå‚æ•°èŒƒå›´
   - å¯è§†åŒ–å¢å¼ºåçš„æ ·æœ¬
   - é€æ­¥å¢åŠ å¢å¼ºå¼ºåº¦

## æœ€ä½³å®è·µ

1. **æ•°æ®éªŒè¯**: åŠ è½½æ•°æ®åå…ˆå¯è§†åŒ–æ£€æŸ¥
2. **ç»Ÿè®¡åˆ†æ**: è®¡ç®—æ•°æ®é›†çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆå‡å€¼ã€æ ‡å‡†å·®ã€åˆ†å¸ƒç­‰ï¼‰
3. **ç‰ˆæœ¬æ§åˆ¶**: è®°å½•æ•°æ®é›†ç‰ˆæœ¬å’Œé¢„å¤„ç†æ­¥éª¤
4. **æ–‡æ¡£è®°å½•**: è®°å½•æ•°æ®é›†æ¥æºã€æ ¼å¼ã€ç‰¹ç‚¹
5. **å¢é‡å¼€å‘**: å…ˆåœ¨å°æ•°æ®é›†ä¸Šæµ‹è¯•ï¼Œå†ç”¨å®Œæ•´æ•°æ®é›†
6. **é”™è¯¯å¤„ç†**: æ·»åŠ å¼‚å¸¸å¤„ç†ï¼Œé¿å…ä¸ªåˆ«æŸåæ•°æ®å½±å“è®­ç»ƒ

## å‚è€ƒèµ„æ–™

- [PyTorch Datasetå’ŒDataLoaderæ–‡æ¡£](https://pytorch.org/docs/stable/data.html)
- [Albumentationsæ•°æ®å¢å¼ºåº“](https://albumentations.ai/)
- [MONAIåŒ»å­¦å›¾åƒå¤„ç†åº“](https://monai.io/)
- [TorchVisionæ•°æ®é›†](https://pytorch.org/vision/stable/datasets.html)

---

æ›´å¤šç¤ºä¾‹è¯·æŸ¥çœ‹ `examples/` ç›®å½•ä¸­çš„ä»£ç å’ŒJupyter Notebooksã€‚

