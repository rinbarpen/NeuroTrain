#!/usr/bin/env python3
"""
å®Œæ•´æµ‹è¯•å¥—ä»¶ - æµ‹è¯•æ‰€æœ‰åŠŸèƒ½
"""

import sys
import logging
import traceback
from pathlib import Path
from typing import Dict
import time

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

from src.config import set_config
from src.dataset import get_dataset, get_all_dataloader

class TestRunner:
    """æµ‹è¯•è¿è¡Œå™¨"""
    
    def __init__(self):
        self.results = {}
        self.start_time = time.time()
    
    def run_test(self, test_name: str, test_func, *args, **kwargs) -> bool:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        logger.info(f"\n{'='*80}")
        logger.info(f"è¿è¡Œæµ‹è¯•: {test_name}")
        logger.info(f"{'='*80}")
        
        try:
            result = test_func(*args, **kwargs)
            self.results[test_name] = result
            status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
            logger.info(f"\næµ‹è¯• {test_name}: {status}")
            return result
        except Exception as e:
            logger.error(f"\næµ‹è¯• {test_name} å¼‚å¸¸: {e}")
            logger.error(traceback.format_exc())
            self.results[test_name] = False
            return False
    
    def print_summary(self):
        """æ‰“å°æµ‹è¯•æ€»ç»“"""
        elapsed = time.time() - self.start_time
        logger.info(f"\n{'='*80}")
        logger.info("æµ‹è¯•ç»“æœæ€»ç»“")
        logger.info(f"{'='*80}")
        
        passed = sum(1 for v in self.results.values() if v)
        total = len(self.results)
        
        for test_name, result in self.results.items():
            status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
            logger.info(f"  {test_name:40s} {status}")
        
        logger.info(f"\næ€»è®¡: {passed}/{total} é€šè¿‡")
        logger.info(f"è€—æ—¶: {elapsed:.2f} ç§’")
        logger.info(f"{'='*80}")
        
        return passed == total

def test_basic_dataset_loading() -> bool:
    """æµ‹è¯•åŸºç¡€æ•°æ®é›†åŠ è½½"""
    config = {
        "task": "test",
        "run_id": "test_basic",
        "seed": 42,
        "device": "cpu",
        "dataset": {
            "name": "cifar10",
            "root_dir": "data/cifar10",
            "config": {"download": True, "valid_ratio": 0.1}
        },
        "train": {"batch_size": 32},
        "test": {"batch_size": 32},
        "dataloader": {"num_workers": 0, "shuffle": True}
    }
    
    try:
        set_config(config)
        
        for mode in ["train", "valid", "test"]:
            dataset = get_dataset(mode)
            if dataset is None:
                logger.warning(f"  {mode} æ•°æ®é›†è¿”å› None")
                return False
            
            dataset_len = len(dataset)
            logger.info(f"  {mode}: {type(dataset).__name__}, é•¿åº¦: {dataset_len}")
            
            if dataset_len == 0:
                logger.warning(f"  {mode} æ•°æ®é›†ä¸ºç©º")
                return False
            
            sample = dataset[0]
            logger.info(f"  æ ·æœ¬ç±»å‹: {type(sample)}")
        
        return True
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_dataloader_creation() -> bool:
    """æµ‹è¯•DataLoaderåˆ›å»º"""
    config = {
        "task": "test",
        "run_id": "test_dataloader",
        "seed": 42,
        "device": "cpu",
        "dataset": {
            "name": "cifar10",
            "root_dir": "data/cifar10",
            "config": {"download": True, "valid_ratio": 0.1}
        },
        "train": {"batch_size": 32},
        "test": {"batch_size": 32},
        "valid": {"batch_size": 32},
        "dataloader": {"num_workers": 0, "shuffle": True}
    }
    
    try:
        set_config(config)
        
        train_loader, valid_loader, test_loader = get_all_dataloader(use_valid=True)
        
        if train_loader is None:
            logger.error("è®­ç»ƒDataLoaderä¸ºNone")
            return False
        
        logger.info(f"  è®­ç»ƒDataLoader: {type(train_loader).__name__}")
        logger.info(f"  éªŒè¯DataLoader: {type(valid_loader).__name__ if valid_loader else None}")
        logger.info(f"  æµ‹è¯•DataLoader: {type(test_loader).__name__ if test_loader else None}")
        
        batch = next(iter(train_loader))
        logger.info(f"  æ‰¹æ¬¡ç±»å‹: {type(batch)}")
        if isinstance(batch, (list, tuple)) and len(batch) > 0:
            logger.info(f"  æ‰¹æ¬¡å¤§å°: {len(batch)}")
        
        return True
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_sample_ratio() -> bool:
    """æµ‹è¯•sample_ratioé…ç½®"""
    config = {
        "task": "test",
        "run_id": "test_sample_ratio",
        "seed": 42,
        "device": "cpu",
        "dataset": {
            "name": "cifar10",
            "root_dir": "data/cifar10",
            "config": {"download": True},
            "sample_ratio": {"train": 0.1, "test": 0.2}
        },
        "train": {"batch_size": 32},
        "test": {"batch_size": 32},
        "dataloader": {"num_workers": 0, "shuffle": True}
    }
    
    try:
        set_config(config)
        
        train_dataset = get_dataset("train")
        test_dataset = get_dataset("test")
        
        train_len = len(train_dataset) if train_dataset else 0
        test_len = len(test_dataset) if test_dataset else 0
        
        logger.info(f"  è®­ç»ƒé›†é•¿åº¦: {train_len} (æœŸæœ›çº¦4500ï¼Œ10%çš„45000)")
        logger.info(f"  æµ‹è¯•é›†é•¿åº¦: {test_len} (æœŸæœ›çº¦2000ï¼Œ20%çš„10000)")
        
        if train_len > 0 and test_len > 0:
            return True
        return False
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_max_samples() -> bool:
    """æµ‹è¯•max_samplesé…ç½®"""
    config = {
        "task": "test",
        "run_id": "test_max_samples",
        "seed": 42,
        "device": "cpu",
        "dataset": {
            "name": "cifar10",
            "root_dir": "data/cifar10",
            "config": {"download": True},
            "max_samples": {"train": 100, "test": 50}
        },
        "train": {"batch_size": 32},
        "test": {"batch_size": 32},
        "dataloader": {"num_workers": 0, "shuffle": True}
    }
    
    try:
        set_config(config)
        
        train_dataset = get_dataset("train")
        test_dataset = get_dataset("test")
        
        train_len = len(train_dataset) if train_dataset else 0
        test_len = len(test_dataset) if test_dataset else 0
        
        logger.info(f"  è®­ç»ƒé›†é•¿åº¦: {train_len} (æœŸæœ›<=100)")
        logger.info(f"  æµ‹è¯•é›†é•¿åº¦: {test_len} (æœŸæœ›<=50)")
        
        if train_len > 0 and test_len > 0:
            if train_len <= 100 and test_len <= 50:
                logger.info("  âœ“ é‡‡æ ·é…ç½®ç”Ÿæ•ˆ")
            else:
                logger.warning("  âš  é‡‡æ ·é…ç½®å¯èƒ½æœªç”Ÿæ•ˆï¼ˆæ•°æ®é›†å¯èƒ½ä¸æ”¯æŒmininalizeï¼‰")
            return True
        return False
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_custom_dataset_dataloader() -> bool:
    """æµ‹è¯•CustomDatasetçš„dataloaderæ–¹æ³•"""
    config = {
        "task": "test",
        "run_id": "test_custom_dataloader",
        "seed": 42,
        "device": "cpu",
        "dataset": {
            "name": "cifar10",
            "root_dir": "data/cifar10",
            "config": {"download": True}
        },
        "train": {"batch_size": 32},
        "test": {"batch_size": 32},
        "dataloader": {"num_workers": 0, "shuffle": True}
    }
    
    try:
        set_config(config)
        
        train_dataset = get_dataset("train")
        if train_dataset is None:
            return False
        
        if hasattr(train_dataset, 'dataloader'):
            loader = train_dataset.dataloader(
                batch_size=32,
                shuffle=True,
                num_workers=0
            )
            logger.info(f"  âœ“ ç›´æ¥è°ƒç”¨dataloaderæ–¹æ³•æˆåŠŸ: {type(loader).__name__}")
            
            batch = next(iter(loader))
            logger.info(f"  âœ“ æˆåŠŸè·å–æ‰¹æ¬¡: {type(batch)}")
            return True
        else:
            logger.warning("  âš  æ•°æ®é›†ä¸æ”¯æŒdataloaderæ–¹æ³•")
            return False
    except Exception as e:
        logger.error(f"æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_ddp_imports() -> bool:
    """æµ‹è¯•DDPç›¸å…³å¯¼å…¥å’Œé…ç½®"""
    try:
        from src.utils.ddp_utils import (
            init_ddp_distributed,
            is_main_process,
            cleanup_ddp
        )
        logger.info("  âœ“ DDPå·¥å…·æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        import torch.distributed as dist
        if dist.is_available():
            logger.info("  âœ“ torch.distributed å¯ç”¨")
        else:
            logger.warning("  âš  torch.distributed ä¸å¯ç”¨")
        
        return True
    except ImportError as e:
        logger.error(f"  âœ— DDPå¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"  âœ— DDPæµ‹è¯•å¤±è´¥: {e}")
        return False

def test_deepspeed_imports() -> bool:
    """æµ‹è¯•DeepSpeedç›¸å…³å¯¼å…¥å’Œé…ç½®"""
    try:
        from src.utils.deepspeed_utils import (
            is_deepspeed_available,
            init_deepspeed_distributed,
            load_deepspeed_config
        )
        logger.info("  âœ“ DeepSpeedå·¥å…·æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        if is_deepspeed_available():
            logger.info("  âœ“ DeepSpeed å¯ç”¨")
        else:
            logger.warning("  âš  DeepSpeed ä¸å¯ç”¨ï¼ˆéœ€è¦å®‰è£…: pip install deepspeedï¼‰")
        
        return True
    except ImportError as e:
        logger.error(f"  âœ— DeepSpeedå¯¼å…¥å¤±è´¥: {e}")
        return False
    except Exception as e:
        logger.error(f"  âœ— DeepSpeedæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    logger.info("=" * 80)
    logger.info("å¼€å§‹è¿è¡Œæ•°æ®é›†ã€DDPå’ŒDeepSpeedæµ‹è¯•")
    logger.info("=" * 80)
    
    runner = TestRunner()
    
    # åŸºç¡€åŠŸèƒ½æµ‹è¯•
    runner.run_test("åŸºç¡€æ•°æ®é›†åŠ è½½", test_basic_dataset_loading)
    runner.run_test("DataLoaderåˆ›å»º", test_dataloader_creation)
    runner.run_test("CustomDataset.dataloaderæ–¹æ³•", test_custom_dataset_dataloader)
    
    # é‡‡æ ·é…ç½®æµ‹è¯•
    runner.run_test("sample_ratioé…ç½®", test_sample_ratio)
    runner.run_test("max_samplesé…ç½®", test_max_samples)
    
    # DDPå’ŒDeepSpeedæµ‹è¯•
    runner.run_test("DDPå…¼å®¹æ€§", test_ddp_imports)
    runner.run_test("DeepSpeedå…¼å®¹æ€§", test_deepspeed_imports)
    
    # æ‰“å°æ€»ç»“
    all_passed = runner.print_summary()
    
    if all_passed:
        logger.info("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return 0
    else:
        logger.error("\nâŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ä¿¡æ¯")
        return 1

if __name__ == "__main__":
    sys.exit(main())

