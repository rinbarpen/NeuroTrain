#!/usr/bin/env python3
"""
PTQå’ŒQATé‡åŒ–ç¤ºä¾‹
å±•ç¤ºè®­ç»ƒåé‡åŒ–å’Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒçš„ä½¿ç”¨æ–¹æ³•
"""

import sys
import os
sys.path.insert(0, os.getcwd())

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

from src.quantization import QuantizationConfig, QuantizationManager, QuantizationTrainer, QuantizationAnalyzer


def create_sample_model():
    """åˆ›å»ºç¤ºä¾‹CNNæ¨¡å‹"""
    class SimpleCNN(nn.Module):
        def __init__(self, num_classes=10):
            super().__init__()
            self.features = nn.Sequential(
                nn.Conv2d(3, 32, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(32, 64, 3, padding=1),
                nn.ReLU(),
                nn.MaxPool2d(2),
                nn.Conv2d(64, 128, 3, padding=1),
                nn.ReLU(),
                nn.AdaptiveAvgPool2d((1, 1))
            )
            self.classifier = nn.Sequential(
                nn.Flatten(),
                nn.Linear(128, 64),
                nn.ReLU(),
                nn.Dropout(0.5),
                nn.Linear(64, num_classes)
            )
        
        def forward(self, x):
            x = self.features(x)
            x = self.classifier(x)
            return x
    
    return SimpleCNN()


def create_sample_data():
    """åˆ›å»ºç¤ºä¾‹æ•°æ®"""
    # åˆ›å»ºéšæœºæ•°æ®
    batch_size = 32
    num_samples = 1000
    
    X = torch.randn(num_samples, 3, 32, 32)
    y = torch.randint(0, 10, (num_samples,))
    
    # åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
    train_size = int(0.8 * num_samples)
    X_train, X_test = X[:train_size], X[train_size:]
    y_train, y_test = y[:train_size], y[train_size:]
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_dataset = TensorDataset(X_train, y_train)
    test_dataset = TensorDataset(X_test, y_test)
    
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
    
    return train_loader, test_loader


def example_ptq_dynamic():
    """ç¤ºä¾‹1: PTQåŠ¨æ€é‡åŒ–"""
    logger.info("=== PTQåŠ¨æ€é‡åŒ–ç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = create_sample_model()
    train_loader, test_loader = create_sample_data()
    
    # å…ˆè®­ç»ƒæ¨¡å‹ï¼ˆæ¨¡æ‹Ÿï¼‰
    model.train()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    
    # ç®€å•è®­ç»ƒå‡ ä¸ªepoch
    for epoch in range(3):
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
            if batch_idx % 10 == 0:
                logger.info(f"Epoch {epoch}, Batch {batch_idx}, Loss: {loss.item():.4f}")
    
    # è®­ç»ƒå®Œæˆåè¿›è¡ŒåŠ¨æ€é‡åŒ–
    logger.info("å¼€å§‹PTQåŠ¨æ€é‡åŒ–...")
    config = QuantizationConfig(method="dynamic", dtype="qint8")
    manager = QuantizationManager(config)
    quantized_model = manager.quantize_model(model)
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    size_info = manager.get_model_size_info(quantized_model)
    logger.info(f"PTQåŠ¨æ€é‡åŒ–å®Œæˆ!")
    logger.info(f"åŸå§‹æ¨¡å‹å¤§å°: {sum(p.numel() * p.element_size() for p in model.parameters()) / (1024*1024):.2f}MB")
    logger.info(f"é‡åŒ–æ¨¡å‹å¤§å°: {size_info['model_size_mb']:.2f}MB")
    
    return model, quantized_model


def example_ptq_static():
    """ç¤ºä¾‹2: PTQé™æ€é‡åŒ–"""
    logger.info("=== PTQé™æ€é‡åŒ–ç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = create_sample_model()
    train_loader, test_loader = create_sample_data()
    
    # å…ˆè®­ç»ƒæ¨¡å‹
    model.train()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    
    for epoch in range(2):
        for batch_idx, (data, target) in enumerate(train_loader):
            optimizer.zero_grad()
            output = model(data)
            loss = criterion(output, target)
            loss.backward()
            optimizer.step()
    
    # å‡†å¤‡æ ¡å‡†æ•°æ®
    calibration_data = []
    model.eval()
    with torch.no_grad():
        for i, (data, _) in enumerate(test_loader):
            if i >= 10:  # åªç”¨10ä¸ªbatchä½œä¸ºæ ¡å‡†æ•°æ®
                break
            calibration_data.append(data)
    
    # é™æ€é‡åŒ–
    logger.info("å¼€å§‹PTQé™æ€é‡åŒ–...")
    config = QuantizationConfig(
        method="static", 
        dtype="qint8",
        calibration_dataset=calibration_data,
        num_calibration_samples=len(calibration_data) * 32
    )
    manager = QuantizationManager(config)
    quantized_model = manager.quantize_model(model)
    
    # è·å–æ¨¡å‹ä¿¡æ¯
    size_info = manager.get_model_size_info(quantized_model)
    logger.info(f"PTQé™æ€é‡åŒ–å®Œæˆ!")
    logger.info(f"é‡åŒ–æ¨¡å‹å¤§å°: {size_info['model_size_mb']:.2f}MB")
    
    return model, quantized_model


def example_qat():
    """ç¤ºä¾‹3: QATé‡åŒ–æ„ŸçŸ¥è®­ç»ƒ"""
    logger.info("=== QATé‡åŒ–æ„ŸçŸ¥è®­ç»ƒç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ¨¡å‹å’Œæ•°æ®
    model = create_sample_model()
    train_loader, test_loader = create_sample_data()
    
    # åˆ›å»ºQATé…ç½®
    qat_config = QuantizationConfig(method="qat", dtype="qint8")
    
    # åˆ›å»ºé‡åŒ–è®­ç»ƒå™¨
    trainer = QuantizationTrainer(
        model=model,
        quantization_config=qat_config,
        output_dir="outputs/qat_example"
    )
    
    # è®¾ç½®é‡åŒ–
    quantized_model = trainer.setup_quantization()
    logger.info("QATæ¨¡å‹è®¾ç½®å®Œæˆ")
    
    # è®¾ç½®è®­ç»ƒç»„ä»¶
    optimizer = optim.Adam(quantized_model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss()
    
    # è¿›è¡Œé‡åŒ–æ„ŸçŸ¥è®­ç»ƒ
    logger.info("å¼€å§‹QATè®­ç»ƒ...")
    trainer.train_with_quantization(
        train_loader=train_loader,
        valid_loader=test_loader,
        num_epochs=3,
        optimizer=optimizer,
        criterion=criterion,
        save_best=True
    )
    
    return model, quantized_model


def example_quantization_analysis():
    """ç¤ºä¾‹4: é‡åŒ–æ•ˆæœåˆ†æ"""
    logger.info("=== é‡åŒ–æ•ˆæœåˆ†æç¤ºä¾‹ ===")
    
    # åˆ›å»ºæ¨¡å‹
    original_model = create_sample_model()
    train_loader, test_loader = create_sample_data()
    
    # é‡åŒ–æ¨¡å‹
    config = QuantizationConfig(method="dynamic")
    manager = QuantizationManager(config)
    quantized_model = manager.quantize_model(original_model)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = QuantizationAnalyzer(original_model, quantized_model)
    
    # æ¯”è¾ƒæ¨¡å‹å¤§å°
    size_comparison = analyzer.compare_model_sizes()
    logger.info("æ¨¡å‹å¤§å°æ¯”è¾ƒ:")
    logger.info(f"  åŸå§‹æ¨¡å‹: {size_comparison['original']['model_size_mb']:.2f}MB")
    logger.info(f"  é‡åŒ–æ¨¡å‹: {size_comparison['quantized']['model_size_mb']:.2f}MB")
    logger.info(f"  å‹ç¼©æ¯”: {size_comparison['compression_ratio']:.2f}x")
    logger.info(f"  å¤§å°å‡å°‘: {size_comparison['size_reduction_percent']:.1f}%")
    
    # æ¯”è¾ƒæ¨ç†é€Ÿåº¦
    test_input = torch.randn(1, 3, 32, 32)
    speed_comparison = analyzer.compare_inference_speed(test_input, num_runs=10)
    logger.info("æ¨ç†é€Ÿåº¦æ¯”è¾ƒ:")
    logger.info(f"  åŸå§‹æ¨¡å‹å¹³å‡æ—¶é—´: {speed_comparison['original_avg_time']:.4f}s")
    logger.info(f"  é‡åŒ–æ¨¡å‹å¹³å‡æ—¶é—´: {speed_comparison['quantized_avg_time']:.4f}s")
    logger.info(f"  åŠ é€Ÿæ¯”: {speed_comparison['speedup']:.2f}x")
    
    # æ¯”è¾ƒå‡†ç¡®ç‡
    accuracy_comparison = analyzer.compare_accuracy(test_loader)
    logger.info("å‡†ç¡®ç‡æ¯”è¾ƒ:")
    logger.info(f"  åŸå§‹æ¨¡å‹å‡†ç¡®ç‡: {accuracy_comparison['original_metrics']['accuracy']:.4f}")
    logger.info(f"  é‡åŒ–æ¨¡å‹å‡†ç¡®ç‡: {accuracy_comparison['quantized_metrics']['accuracy']:.4f}")
    logger.info(f"  å‡†ç¡®ç‡ä¸‹é™: {accuracy_comparison['accuracy_drop']:.4f}")
    
    return analyzer


def main():
    """è¿è¡Œæ‰€æœ‰PTQå’ŒQATç¤ºä¾‹"""
    logger.info("å¼€å§‹PTQå’ŒQATé‡åŒ–ç¤ºä¾‹...")
    
    try:
        # PTQåŠ¨æ€é‡åŒ–
        original_model1, quantized_model1 = example_ptq_dynamic()
        
        # PTQé™æ€é‡åŒ–
        original_model2, quantized_model2 = example_ptq_static()
        
        # QATé‡åŒ–æ„ŸçŸ¥è®­ç»ƒ
        original_model3, quantized_model3 = example_qat()
        
        # é‡åŒ–æ•ˆæœåˆ†æ
        analyzer = example_quantization_analysis()
        
        logger.info("ğŸ‰ æ‰€æœ‰PTQå’ŒQATç¤ºä¾‹è¿è¡Œå®Œæˆ!")
        
    except Exception as e:
        logger.error(f"ç¤ºä¾‹è¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
