#!/usr/bin/env python
"""
Vision Models with EntityMoE ä½¿ç”¨ç¤ºä¾‹

å±•ç¤ºå¦‚ä½•ä½¿ç”¨åŸºäº timm å’Œ transformers çš„ EntityMoE è§†è§‰æ¨¡å‹
"""

import sys
sys.path.insert(0, 'src')

import torch
import torch.nn as nn


def example_vit():
    """ViT with EntityMoE ç¤ºä¾‹"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 1: ViT with EntityMoE")
    print("="*70)
    
    from models.like.entity_moe.vit_entity_moe import vit_base_entity_moe, print_model_info
    
    # åˆ›å»ºæ¨¡å‹ï¼ˆä¸åŠ è½½é¢„è®­ç»ƒæƒé‡ä»¥åŠ å¿«æ¼”ç¤ºï¼‰
    print("\nåˆ›å»º ViT-Base æ¨¡å‹ï¼Œåœ¨æœ€åä¸€å±‚æ³¨å…¥ EntityMoE...")
    model = vit_base_entity_moe(
        pretrained=False,  # æ¼”ç¤ºæ—¶ä¸åŠ è½½é¢„è®­ç»ƒæƒé‡
        num_classes=1000,
        num_experts=4,
        num_experts_shared=2,
        expert_k=1,
        inject_layers='last'  # åªåœ¨æœ€åä¸€å±‚æ³¨å…¥
    )
    
    # æ‰“å°æ¨¡å‹é…ç½®
    print_model_info(model)
    
    # å‰å‘ä¼ æ’­
    print("\nè¿›è¡Œå‰å‘ä¼ æ’­...")
    x = torch.randn(2, 3, 224, 224)
    with torch.no_grad():
        output = model(x)
    
    print(f"âœ“ è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"âœ“ è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"âœ“ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")


def example_swin():
    """Swin Transformer with EntityMoE ç¤ºä¾‹"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 2: Swin Transformer with EntityMoE")
    print("="*70)
    
    from models.like.entity_moe.vit_entity_moe import swin_tiny_entity_moe, print_model_info
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»º Swin-Tiny æ¨¡å‹ï¼Œåœ¨æœ€åä¸€ä¸ª stage æ³¨å…¥ EntityMoE...")
    model = swin_tiny_entity_moe(
        pretrained=False,
        num_classes=1000,
        num_experts=4,
        num_experts_shared=2,
        expert_k=1,
        inject_layers='last_stage'
    )
    
    # æ‰“å°æ¨¡å‹é…ç½®
    print_model_info(model)
    
    # å‰å‘ä¼ æ’­
    print("\nè¿›è¡Œå‰å‘ä¼ æ’­...")
    x = torch.randn(2, 3, 224, 224)
    with torch.no_grad():
        output = model(x)
    
    print(f"âœ“ è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"âœ“ è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"âœ“ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")


def example_resnet():
    """ResNet with EntityMoE ç¤ºä¾‹"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 3: ResNet with EntityMoE")
    print("="*70)
    
    from models.like.entity_moe.vit_entity_moe import resnet50_entity_moe, print_model_info
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»º ResNet-50 æ¨¡å‹ï¼Œåœ¨ layer4 æ³¨å…¥ EntityMoE...")
    model = resnet50_entity_moe(
        pretrained=False,
        num_classes=1000,
        num_experts=4,
        num_experts_shared=2,
        expert_k=1,
        inject_layers='layer4'
    )
    
    # æ‰“å°æ¨¡å‹é…ç½®
    print_model_info(model)
    
    # å‰å‘ä¼ æ’­
    print("\nè¿›è¡Œå‰å‘ä¼ æ’­...")
    x = torch.randn(2, 3, 224, 224)
    with torch.no_grad():
        output = model(x)
    
    print(f"âœ“ è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"âœ“ è¾“å‡ºå½¢çŠ¶: {output.shape}")
    print(f"âœ“ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")


def example_sam():
    """SAM with EntityMoE ç¤ºä¾‹"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 4: SAM with EntityMoE")
    print("="*70)
    
    from models.like.entity_moe.vit_entity_moe import sam_vit_base_entity_moe, print_model_info
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»º SAM ViT-Base æ¨¡å‹ï¼Œåœ¨ååŠéƒ¨åˆ†å±‚æ³¨å…¥ EntityMoE...")
    model = sam_vit_base_entity_moe(
        pretrained=False,
        num_experts=4,
        num_experts_shared=2,
        expert_k=1,
        inject_layers='last_half'
    )
    
    # æ‰“å°æ¨¡å‹é…ç½®
    print_model_info(model)
    
    # å‰å‘ä¼ æ’­
    print("\nè¿›è¡Œå‰å‘ä¼ æ’­...")
    x = torch.randn(1, 3, 1024, 1024)
    with torch.no_grad():
        output = model(pixel_values=x)
    
    print(f"âœ“ è¾“å…¥å½¢çŠ¶: {x.shape}")
    print(f"âœ“ Vision features å½¢çŠ¶: {output.vision_outputs.last_hidden_state.shape}")
    print(f"âœ“ æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters())/1e6:.2f}M")


def example_custom_inject():
    """è‡ªå®šä¹‰æ³¨å…¥å±‚ç¤ºä¾‹"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 5: è‡ªå®šä¹‰æ³¨å…¥å±‚ä½ç½®")
    print("="*70)
    
    from models.like.entity_moe.vit_entity_moe import create_vit_entity_moe
    
    # åœ¨æŒ‡å®šçš„å±‚æ³¨å…¥ EntityMoE
    print("\nåˆ›å»º ViT æ¨¡å‹ï¼Œåœ¨ç¬¬ 9, 10, 11 å±‚æ³¨å…¥ EntityMoE...")
    model = create_vit_entity_moe(
        model_name='vit_base_patch16_224',
        pretrained=False,
        num_classes=1000,
        inject_layers=[9, 10, 11]  # æŒ‡å®šå±‚ç´¢å¼•
    )
    
    from models.like.entity_moe.vit_entity_moe import print_model_info
    print_model_info(model)
    
    # å‰å‘ä¼ æ’­
    x = torch.randn(2, 3, 224, 224)
    with torch.no_grad():
        output = model(x)
    
    print(f"\nâœ“ è¾“å‡ºå½¢çŠ¶: {output.shape}")


def example_training():
    """è®­ç»ƒç¤ºä¾‹"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 6: è®­ç»ƒç¤ºä¾‹ï¼ˆä¼ªä»£ç ï¼‰")
    print("="*70)
    
    from models.like.entity_moe.vit_entity_moe import vit_base_entity_moe
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = vit_base_entity_moe(
        pretrained=False,  # å®é™…è®­ç»ƒæ—¶è®¾ä¸º True
        num_classes=10,    # å‡è®¾æ˜¯ 10 åˆ†ç±»ä»»åŠ¡
        inject_layers='last'
    )
    
    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)
    
    print("âœ“ æ¨¡å‹åˆ›å»ºå®Œæˆ")
    print("âœ“ æŸå¤±å‡½æ•°: CrossEntropyLoss")
    print("âœ“ ä¼˜åŒ–å™¨: AdamW (lr=1e-4)")
    
    # æ¨¡æ‹Ÿä¸€ä¸ªè®­ç»ƒæ­¥éª¤
    print("\næ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤...")
    model.train()
    
    # æ¨¡æ‹Ÿæ•°æ®
    images = torch.randn(4, 3, 224, 224)
    labels = torch.randint(0, 10, (4,))
    
    # å‰å‘ä¼ æ’­
    outputs = model(images)
    loss = criterion(outputs, labels)
    
    # åå‘ä¼ æ’­
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    
    print(f"âœ“ è®­ç»ƒæ­¥éª¤å®Œæˆ")
    print(f"âœ“ Loss: {loss.item():.4f}")
    
    # è¯„ä¼°æ¨¡å¼
    model.eval()
    with torch.no_grad():
        outputs = model(images)
        predictions = outputs.argmax(dim=1)
    
    print(f"âœ“ æ¨ç†å®Œæˆ")
    print(f"âœ“ é¢„æµ‹ç»“æœ: {predictions}")


def example_fine_tuning():
    """å¾®è°ƒç¤ºä¾‹"""
    print("\n" + "="*70)
    print("ç¤ºä¾‹ 7: å¾®è°ƒæŠ€å·§")
    print("="*70)
    
    from models.like.entity_moe.vit_entity_moe import vit_base_entity_moe
    
    # åˆ›å»ºæ¨¡å‹
    print("\nåˆ›å»ºæ¨¡å‹...")
    model = vit_base_entity_moe(
        pretrained=False,
        num_classes=100,
        inject_layers='last'
    )
    
    # æ–¹æ³• 1: å†»ç»“é¢„è®­ç»ƒçš„ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒ EntityMoE å’Œåˆ†ç±»å¤´
    print("\næ–¹æ³• 1: å†»ç»“ä¸»å¹²ç½‘ç»œï¼Œåªè®­ç»ƒ EntityMoE éƒ¨åˆ†")
    frozen_params = 0
    trainable_params = 0
    
    for name, param in model.named_parameters():
        if 'entity_moe' not in name and 'head' not in name:
            param.requires_grad = False
            frozen_params += param.numel()
        else:
            trainable_params += param.numel()
    
    print(f"âœ“ å†»ç»“å‚æ•°: {frozen_params/1e6:.2f}M")
    print(f"âœ“ å¯è®­ç»ƒå‚æ•°: {trainable_params/1e6:.2f}M")
    
    # æ–¹æ³• 2: ä½¿ç”¨ä¸åŒçš„å­¦ä¹ ç‡
    print("\næ–¹æ³• 2: ä½¿ç”¨å·®å¼‚åŒ–å­¦ä¹ ç‡")
    backbone_params = []
    entitymoe_params = []
    head_params = []
    
    for name, param in model.named_parameters():
        if 'entity_moe' in name:
            entitymoe_params.append(param)
        elif 'head' in name:
            head_params.append(param)
        else:
            backbone_params.append(param)
    
    optimizer = torch.optim.AdamW([
        {'params': backbone_params, 'lr': 1e-5},      # ä¸»å¹²ç½‘ç»œç”¨å°å­¦ä¹ ç‡
        {'params': entitymoe_params, 'lr': 1e-4},     # EntityMoE ç”¨ä¸­ç­‰å­¦ä¹ ç‡
        {'params': head_params, 'lr': 1e-3},          # åˆ†ç±»å¤´ç”¨å¤§å­¦ä¹ ç‡
    ])
    
    print(f"âœ“ ä¸»å¹²ç½‘ç»œå­¦ä¹ ç‡: 1e-5")
    print(f"âœ“ EntityMoE å­¦ä¹ ç‡: 1e-4")
    print(f"âœ“ åˆ†ç±»å¤´å­¦ä¹ ç‡: 1e-3")


def main():
    print("\n" + "="*70)
    print("Vision Models with EntityMoE - ä½¿ç”¨ç¤ºä¾‹")
    print("="*70)
    
    try:
        # è¿è¡Œå„ä¸ªç¤ºä¾‹
        example_vit()
        example_swin()
        example_resnet()
        
        # SAM ç¤ºä¾‹ï¼ˆéœ€è¦ transformers åº“ï¼‰
        try:
            example_sam()
        except Exception as e:
            print(f"\nâš ï¸ SAM ç¤ºä¾‹è·³è¿‡: {e}")
        
        example_custom_inject()
        example_training()
        example_fine_tuning()
        
        print("\n" + "="*70)
        print("âœ… æ‰€æœ‰ç¤ºä¾‹è¿è¡Œå®Œæˆï¼")
        print("="*70)
        print("\nğŸ’¡ æç¤º:")
        print("  - è¯¦ç»†æ–‡æ¡£è¯·æŸ¥çœ‹: src/models/like/entity_moe/README.md")
        print("  - å®é™…ä½¿ç”¨æ—¶å»ºè®®è®¾ç½® pretrained=True åŠ è½½é¢„è®­ç»ƒæƒé‡")
        print("  - æ ¹æ®ä»»åŠ¡å¤æ‚åº¦è°ƒæ•´ inject_layers å‚æ•°")
        print("="*70 + "\n")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

