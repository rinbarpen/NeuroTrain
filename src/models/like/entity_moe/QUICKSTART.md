# EntityMoE è§†è§‰æ¨¡å‹ - å¿«é€Ÿå¼€å§‹æŒ‡å—

## ğŸš€ 5åˆ†é’Ÿä¸Šæ‰‹

### å®‰è£…ä¾èµ–

```bash
# åŸºç¡€ä¾èµ–
pip install torch torchvision

# ViT, Swin, ResNet
pip install timm

# SAM
pip install transformers
```

### å¿«é€Ÿç¤ºä¾‹

#### 1ï¸âƒ£ ViT with EntityMoE

```python
from models.like.entity_moe.vit_entity_moe import vit_base_entity_moe
import torch

# åˆ›å»ºæ¨¡å‹
model = vit_base_entity_moe(pretrained=True, num_classes=1000)

# æ¨ç†
images = torch.randn(2, 3, 224, 224)
outputs = model(images)  # (2, 1000)
```

#### 2ï¸âƒ£ Swin Transformer with EntityMoE

```python
from models.like.entity_moe.vit_entity_moe import swin_tiny_entity_moe

model = swin_tiny_entity_moe(pretrained=True, num_classes=1000)
outputs = model(images)
```

#### 3ï¸âƒ£ ResNet with EntityMoE

```python
from models.like.entity_moe.vit_entity_moe import resnet50_entity_moe

model = resnet50_entity_moe(pretrained=True, num_classes=1000)
outputs = model(images)
```

#### 4ï¸âƒ£ SAM with EntityMoE

```python
from models.like.entity_moe.vit_entity_moe import sam_vit_base_entity_moe

model = sam_vit_base_entity_moe(pretrained=True)
outputs = model(pixel_values=torch.randn(1, 3, 1024, 1024))
```

## âš™ï¸ å¸¸ç”¨é…ç½®

### é€‰æ‹©æ³¨å…¥ä½ç½®

```python
# åªåœ¨æœ€åä¸€å±‚ï¼ˆæ¨èç”¨äºå¿«é€Ÿå®éªŒï¼‰
model = vit_base_entity_moe(inject_layers='last')

# åœ¨å¤šä¸ªå±‚ï¼ˆæ›´å¼ºçš„è¡¨è¾¾èƒ½åŠ›ï¼‰
model = vit_base_entity_moe(inject_layers=[9, 10, 11])

# åœ¨æ‰€æœ‰å±‚ï¼ˆæœ€å¤§å®¹é‡ï¼Œä½†è®¡ç®—å¼€é”€å¤§ï¼‰
model = vit_base_entity_moe(inject_layers='all')
```

### è°ƒæ•´ä¸“å®¶é…ç½®

```python
model = vit_base_entity_moe(
    num_experts=4,           # ä¸“å®¶æ•°é‡ï¼ˆ2-8ï¼‰
    num_experts_shared=2,    # å…±äº«ä¸“å®¶æ•°ï¼ˆ0-4ï¼‰
    expert_k=1,              # æ¿€æ´»ä¸“å®¶æ•°ï¼ˆ1-2ï¼‰
)
```

## ğŸ“ è®­ç»ƒç¤ºä¾‹

```python
import torch.nn as nn
import torch.optim as optim

# 1. åˆ›å»ºæ¨¡å‹
model = vit_base_entity_moe(pretrained=True, num_classes=10)

# 2. å®šä¹‰ä¼˜åŒ–å™¨ï¼ˆå¯é€‰ï¼šä½¿ç”¨å·®å¼‚åŒ–å­¦ä¹ ç‡ï¼‰
optimizer = optim.AdamW([
    {'params': [p for n, p in model.named_parameters() if 'entity_moe' not in n], 
     'lr': 1e-5},  # ä¸»å¹²ç½‘ç»œå°å­¦ä¹ ç‡
    {'params': [p for n, p in model.named_parameters() if 'entity_moe' in n], 
     'lr': 1e-4},  # EntityMoE å¤§å­¦ä¹ ç‡
])

criterion = nn.CrossEntropyLoss()

# 3. è®­ç»ƒå¾ªç¯
model.train()
for images, labels in train_loader:
    outputs = model(images)
    loss = criterion(outputs, labels)
    
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
```

## ğŸ’¡ å¸¸è§ç”¨æ³•

### è‡ªå®šä¹‰ timm æ¨¡å‹

```python
from models.like.entity_moe.vit_entity_moe import create_vit_entity_moe

# ä½¿ç”¨ä»»ä½• timm æ”¯æŒçš„æ¨¡å‹
model = create_vit_entity_moe(
    model_name='vit_large_patch16_384',  # ä»»ä½• timm æ¨¡å‹å
    pretrained=True,
    inject_layers='last'
)
```

### æŸ¥çœ‹æ¨¡å‹ä¿¡æ¯

```python
from models.like.entity_moe.vit_entity_moe import print_model_info

model = vit_base_entity_moe()
print_model_info(model)
```

### å†»ç»“éƒ¨åˆ†å‚æ•°

```python
# åªè®­ç»ƒ EntityMoE å’Œåˆ†ç±»å¤´
for name, param in model.named_parameters():
    if 'entity_moe' not in name and 'head' not in name:
        param.requires_grad = False
```

## ğŸ“š æ›´å¤šèµ„æº

- **è¯¦ç»†æ–‡æ¡£**: `README.md`
- **å®ç°æ€»ç»“**: `IMPLEMENTATION_SUMMARY.md`
- **å®Œæ•´ç¤ºä¾‹**: `examples/entity_moe_example.py`

## â“ å¿«é€Ÿé—®ç­”

**Q: åº”è¯¥åœ¨å¤šå°‘å±‚æ³¨å…¥ EntityMoEï¼Ÿ**
- ç®€å•ä»»åŠ¡/å¿«é€Ÿå®éªŒï¼š`inject_layers='last'`
- ä¸€èˆ¬ä»»åŠ¡ï¼š`inject_layers=[9, 10, 11]`ï¼ˆåå‡ å±‚ï¼‰
- å¤æ‚ä»»åŠ¡ï¼š`inject_layers='all'`

**Q: å¦‚ä½•å‡å°‘æ˜¾å­˜å ç”¨ï¼Ÿ**
- å‡å°‘æ³¨å…¥å±‚æ•°
- å‡å° `num_experts`
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ

**Q: é¢„è®­ç»ƒæƒé‡ä¼šè¢«ä¿ç•™å—ï¼Ÿ**
- æ˜¯çš„ï¼Œåªåœ¨æŒ‡å®šå±‚æ·»åŠ  EntityMoEï¼ŒåŸå§‹æƒé‡ä¿æŒä¸å˜

**Q: è®­ç»ƒé€Ÿåº¦ä¼šå˜æ…¢å—ï¼Ÿ**
- ä¼šæœ‰ä¸€äº›å½±å“ï¼Œä½†å¯ä»¥é€šè¿‡å‡å°‘æ³¨å…¥å±‚æ•°æ¥ä¼˜åŒ–

---

âœ… **å°±è¿™ä¹ˆç®€å•ï¼å¼€å§‹ä½¿ç”¨ EntityMoE å¢å¼ºä½ çš„è§†è§‰æ¨¡å‹å§ï¼**

