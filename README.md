# NeuroTrain

ä¸€ä¸ªä¸“ä¸šçš„æ·±åº¦å­¦ä¹ è®­ç»ƒæ¡†æ¶ï¼Œä¸“ä¸ºåŒ»å­¦å›¾åƒåˆ†å‰²ä»»åŠ¡è®¾è®¡ï¼Œæä¾›çµæ´»çš„æ•°æ®é›†ç®¡ç†ã€æ¨¡å‹è®­ç»ƒå’Œç»“æœåˆ†æåŠŸèƒ½ã€‚

## ğŸš€ ç‰¹æ€§

- **å¤šæ•°æ®é›†æ”¯æŒ**: æ”¯æŒDRIVEã€CHASEDB1ã€STAREç­‰åŒ»å­¦å›¾åƒæ•°æ®é›†ï¼Œä»¥åŠCOCOç›®æ ‡æ£€æµ‹/åˆ†å‰²æ•°æ®é›†å’ŒCIFARå›¾åƒåˆ†ç±»æ•°æ®é›†
- **Diffusionæ¨¡å‹æ”¯æŒ**: å®Œæ•´æ”¯æŒæ‰©æ•£æ¨¡å‹è®­ç»ƒï¼ŒåŒ…æ‹¬æ— æ¡ä»¶ç”Ÿæˆã€æ¡ä»¶ç”Ÿæˆå’Œæ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ ğŸ†•
- **LLMé©±åŠ¨çš„æ•°æ®åˆ†æ**: ä½¿ç”¨è‡ªç„¶è¯­è¨€æŸ¥è¯¢åˆ†æã€ç­›é€‰å’Œå¤„ç†æ•°æ®é›† ğŸ†•
- **çµæ´»çš„æ•°æ®é›†é…ç½®**: å•ä¸€æ•°æ®é›†ã€æ··åˆæ•°æ®é›†ã€å¢å¼ºç‰ˆæ··åˆæ•°æ®é›†
- **æ™ºèƒ½é‡‡æ ·ç­–ç•¥**: æƒé‡é‡‡æ ·ã€å¹³è¡¡é‡‡æ ·ã€ä¼˜å…ˆçº§é‡‡æ ·
- **ä¸°å¯Œçš„æ•°æ®å¢å¼º**: æ—‹è½¬ã€ç¿»è½¬ã€äº®åº¦è°ƒæ•´ã€å¼¹æ€§å˜æ¢ç­‰
- **æ··åˆç²¾åº¦è®­ç»ƒ**: æ”¯æŒbfloat16æ··åˆç²¾åº¦è®­ç»ƒï¼Œæå‡è®­ç»ƒæ•ˆç‡
- **æ¨¡å‹é‡åŒ–æ”¯æŒ**: æ”¯æŒåŠ¨æ€é‡åŒ–ã€é™æ€é‡åŒ–ã€QATã€GPTQã€AWQã€BitsAndBytesç­‰å¤šç§é‡åŒ–æ–¹æ³•
- **æ¨¡å—åŒ–è®¾è®¡**: æ˜“äºæ‰©å±•å’Œè‡ªå®šä¹‰
- **å®Œæ•´çš„å®éªŒç®¡ç†**: è‡ªåŠ¨ä¿å­˜è®­ç»ƒæ—¥å¿—ã€æ¨¡å‹æ£€æŸ¥ç‚¹å’Œç»“æœåˆ†æ
- **é…ç½®é©±åŠ¨**: ä½¿ç”¨ TOML é…ç½®æ–‡ä»¶ç®¡ç†å®éªŒå‚æ•°
- **æ”¯æŒè®­ç»ƒä¸­æ–­åç»§ç»­**: è®­ç»ƒè¿‡ç¨‹ä¸­å¯ä»¥ä¸­æ–­ï¼Œåç»­å¯ä»¥ä»æ£€æŸ¥ç‚¹ç»§ç»­è®­ç»ƒ
- **åˆ†å¸ƒå¼è®­ç»ƒ**: æ”¯æŒå¤šGPUè®­ç»ƒï¼ŒåŠ é€Ÿæ¨¡å‹è®­ç»ƒè¿‡ç¨‹

## ğŸ“¦ å®‰è£…

### ç¯å¢ƒè¦æ±‚
- Python 3.10â€“3.13ï¼ˆæ¨èï¼ŒCI å·²è¦†ç›–ï¼‰
- CUDA 11.8+ (å¯é€‰ï¼Œç”¨äºGPUè®­ç»ƒ)
- Conda æˆ– Miniconda

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
   ```bash
   git clone https://github.com/rinbarpen/NeuroTrain.git
   cd NeuroTrain
   ```

2. **åˆ›å»ºå¹¶æ¿€æ´»Condaç¯å¢ƒ**
   ```bash
   conda create -n ntrain python=3.10
   conda activate ntrain
   ```

3. **å®‰è£…ä¾èµ–**
   ```bash
   # ä½¿ç”¨uvå®‰è£…ä¾èµ–ï¼ˆæ¨èï¼‰
   uv pip install -e '.[cu128]'  # æ”¯æŒCUDA 12.8
   # æˆ–è€…é€‰æ‹©å…¶ä»–ç‰ˆæœ¬ï¼šcpu, cu118, cu126
   
   # æˆ–è€…ä½¿ç”¨ä¼ ç»Ÿæ–¹å¼
   pip install -e '.[cu128]'
   ```

4. **éªŒè¯å®‰è£…**
   ```bash
   python -c "import torch; print(f'PyTorchç‰ˆæœ¬: {torch.__version__}')"
   python -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')"
   ```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å‡†å¤‡æ•°æ®

å°†æ•°æ®é›†æ”¾åœ¨ `data` ç›®å½•ä¸‹ï¼Œä¾‹å¦‚ï¼š
```
data/
â”œâ”€â”€ drive/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â”œâ”€â”€ chasedb1/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â”œâ”€â”€ stare/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ masks/
â””â”€â”€ coco/                    # COCOæ•°æ®é›†ï¼ˆå¯é€‰ï¼‰
    â”œâ”€â”€ annotations/
    â”œâ”€â”€ train2017/
    â””â”€â”€ val2017/
```

**ä¸‹è½½COCOæ•°æ®é›†ï¼ˆå¯é€‰ï¼‰**ï¼š
```bash
# ä½¿ç”¨è‡ªåŠ¨ä¸‹è½½è„šæœ¬
bash scripts/download_coco.sh 2017 all

# æˆ–è€…æ‰‹åŠ¨ä¸‹è½½ï¼Œè¯¦è§ docs/COCO_DATASET_GUIDE.md
```

### 2. é…ç½®è®­ç»ƒå‚æ•°

å¤åˆ¶å¹¶ä¿®æ”¹é…ç½®æ–‡ä»¶ï¼š
```bash
cp configs/single/train.template.toml configs/my_training.toml
```

### 3. å¼€å§‹è®­ç»ƒ

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate ntrain

# æ£€æŸ¥é…ç½®
python main.py -c configs/my_training.toml --check

# å¼€å§‹è®­ç»ƒ
python main.py -c configs/my_training.toml --train

# è®­ç»ƒå¹¶æµ‹è¯•
python main.py -c configs/my_training.toml --train --test
```

## ğŸ“– è¯¦ç»†æ–‡æ¡£

æˆ‘ä»¬æä¾›äº†å®Œæ•´çš„æ–‡æ¡£æ¥å¸®åŠ©æ‚¨ä½¿ç”¨NeuroTrainæ¡†æ¶ï¼š

- **[è®­ç»ƒæŒ‡å—](docs/training_guide.md)** - è¯¦ç»†çš„æ¨¡å‹è®­ç»ƒæ•™ç¨‹
- **[æ•°æ®é›†é…ç½®æŒ‡å—](docs/dataset_configuration_guide.md)** - å¦‚ä½•é…ç½®å„ç§æ•°æ®é›†
- **[å¢å¼ºç‰ˆæ··åˆæ•°æ®é›†æŒ‡å—](docs/enhanced_hybrid_dataset_guide.md)** - é«˜çº§æ•°æ®é›†é…ç½®
- **[Diffusionæ•°æ®é›†æŒ‡å—](docs/DIFFUSION_DATASET.md)** - Diffusionæ¨¡å‹æ•°æ®é›†ä½¿ç”¨æŒ‡å— ğŸ†•
- **[LLMæ•°æ®åˆ†æå™¨æŒ‡å—](docs/LLM_DATA_ANALYZER.md)** - LLMé©±åŠ¨çš„æ•°æ®åˆ†æå’Œç­›é€‰ ğŸ†•
- **[ç»“æœåˆ†ææŒ‡å—](docs/results_analysis_guide.md)** - å¦‚ä½•åˆ†æè®­ç»ƒç»“æœ
- **[æ•…éšœæ’é™¤æŒ‡å—](docs/troubleshooting_guide.md)** - å¸¸è§é—®é¢˜è§£å†³æ–¹æ¡ˆ

## ğŸ“‚ é¡¹ç›®ç»“æ„

```
NeuroTrain/
â”œâ”€â”€ configs/              # é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ single/          # å•æ¬¡è®­ç»ƒé…ç½®
â”‚   â””â”€â”€ pipeline/        # ç®¡é“é…ç½®
â”œâ”€â”€ src/                  # æ ¸å¿ƒæºä»£ç 
â”‚   â”œâ”€â”€ dataset/         # æ•°æ®é›†æ¨¡å—
â”‚   â”œâ”€â”€ engine/          # è®­ç»ƒå¼•æ“
â”‚   â”œâ”€â”€ metrics/         # è¯„ä¼°æŒ‡æ ‡
â”‚   â””â”€â”€ utils/           # å·¥å…·å‡½æ•°
â”œâ”€â”€ data/                # æ•°æ®é›†å­˜å‚¨
â”œâ”€â”€ runs/                # è®­ç»ƒç»“æœè¾“å‡º
â”œâ”€â”€ cache/               # æ¨¡å‹ç¼“å­˜
â”œâ”€â”€ tests/               # æµ‹è¯•æ–‡ä»¶
â”œâ”€â”€ docs/                # æ–‡æ¡£
â”œâ”€â”€ tools/               # åˆ†æå·¥å…·
â”œâ”€â”€ scripts/             # è„šæœ¬æ–‡ä»¶
â””â”€â”€ examples/            # ä½¿ç”¨ç¤ºä¾‹
```

## ğŸ”§ é…ç½®ç¤ºä¾‹

### åŸºç¡€è®­ç»ƒé…ç½®

```toml
[basic]
task_name = "Retina_Vessel_Segmentation"
run_id = "experiment_001"

[model]
name = "UNet"
n_channels = 3
n_classes = 2

[dataset]
name = "drive"
root_dir = "data/drive"
is_rgb = true

[training]
epochs = 100
batch_size = 8
learning_rate = 0.001
```

### å¢å¼ºç‰ˆæ··åˆæ•°æ®é›†é…ç½®

```toml
[dataset]
name = "enhanced_hybrid"
datasets = ["drive", "chasedb1", "stare"]
sampling_strategy = "weighted"
ratios = [0.5, 0.3, 0.2]
weights = [1.0, 1.2, 0.8]

[dataset.drive]
root_dir = "data/drive"
is_rgb = true

[dataset.chasedb1]
root_dir = "data/chasedb1"
is_rgb = true

[dataset.stare]
root_dir = "data/stare"
is_rgb = true
```

## ğŸš€ ä½¿ç”¨åœºæ™¯

### 1. å•æ•°æ®é›†è®­ç»ƒ
é€‚ç”¨äºåœ¨å•ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ï¼š
```bash
python main.py -c configs/single/train-drive.toml --train
```

### 2. å¤šæ•°æ®é›†æ··åˆè®­ç»ƒ
ä½¿ç”¨å¤šä¸ªæ•°æ®é›†è¿›è¡Œè”åˆè®­ç»ƒï¼š
```bash
python main.py -c configs/single/train.enhanced.template.toml --train
```

### 3. æ¨¡å‹æµ‹è¯•å’Œè¯„ä¼°
å¯¹è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•ï¼š
```bash
python main.py -c configs/my_config.toml --test
```

### 4. æ‰¹é‡å®éªŒç®¡é“
æ‰§è¡Œä¸€ç³»åˆ—é¢„å®šä¹‰çš„å®éªŒï¼š
```bash
python main_pipeline.py -c configs/pipeline/pipeline-template.toml
```

### 5. Diffusionæ¨¡å‹è®­ç»ƒ ğŸ†•
è®­ç»ƒæ‰©æ•£æ¨¡å‹è¿›è¡Œå›¾åƒç”Ÿæˆï¼š
```bash
# è¿è¡Œç¤ºä¾‹
python examples/diffusion_dataset_example.py

# æˆ–ä½¿ç”¨é…ç½®æ–‡ä»¶
python main.py -c examples/config_diffusion_example.toml --train
```

äº†è§£æ›´å¤šï¼š[Diffusionæ•°æ®é›†æŒ‡å—](docs/DIFFUSION_DATASET.md) å’Œ [å¿«é€Ÿå¼€å§‹README](DIFFUSION_DATASET_README.md)

## ğŸ“Š ç»“æœåˆ†æ

è®­ç»ƒç»“æœä¿å­˜åœ¨ `runs/{run_id}/` ç›®å½•ä¸‹ï¼š

```
runs/
â””â”€â”€ experiment_001/
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ model_summary.txt      # æ¨¡å‹ç»“æ„æ‘˜è¦
    â”‚   â”œâ”€â”€ model_flop_count.txt   # è®¡ç®—å¤æ‚åº¦åˆ†æ
    â”‚   â””â”€â”€ training.log           # è®­ç»ƒæ—¥å¿—
    â”œâ”€â”€ test/
    â”‚   â”œâ”€â”€ metrics.json           # æµ‹è¯•æŒ‡æ ‡
    â”‚   â””â”€â”€ predictions/           # é¢„æµ‹ç»“æœ
    â””â”€â”€ checkpoints/
        â”œâ”€â”€ best.pth              # æœ€ä½³æ¨¡å‹
        â””â”€â”€ last.pth              # æœ€æ–°æ¨¡å‹
```

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
```bash
tail -f runs/{run_id}/train/training.log
```

### åˆ†ææ¨¡å‹æ€§èƒ½
```bash
python tools/analyzers/metrics_analyzer.py --run_id {run_id}
```

### å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹

## ğŸš€ æ¨¡å‹é‡åŒ–

NeuroTrainæ”¯æŒå¤šç§æ¨¡å‹é‡åŒ–æ–¹æ³•ï¼Œå¸®åŠ©å‡å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ—¶é—´ï¼š

### æ”¯æŒçš„é‡åŒ–æ–¹æ³•
- **åŠ¨æ€é‡åŒ–**: PyTorchå†…ç½®ï¼Œæ— éœ€æ ¡å‡†æ•°æ®
- **é™æ€é‡åŒ–**: PyTorchå†…ç½®ï¼Œéœ€è¦æ ¡å‡†æ•°æ®é›†
- **é‡åŒ–æ„ŸçŸ¥è®­ç»ƒ(QAT)**: è®­ç»ƒæ—¶è€ƒè™‘é‡åŒ–å½±å“
- **GPTQé‡åŒ–**: é€‚ç”¨äºå¤§è¯­è¨€æ¨¡å‹
- **AWQé‡åŒ–**: ä¿æŒæ¿€æ´»ç²¾åº¦
- **BitsAndBytesé‡åŒ–**: 4bit/8bité‡åŒ–

### å¿«é€Ÿå¼€å§‹é‡åŒ–

```python
from src.utils.quantization import QuantizationConfig, QuantizationManager

# åˆ›å»ºé‡åŒ–é…ç½®
config = QuantizationConfig(method="dynamic", dtype="qint8")

# é‡åŒ–æ¨¡å‹
manager = QuantizationManager(config)
quantized_model = manager.quantize_model(your_model)

# è·å–æ¨¡å‹ä¿¡æ¯
size_info = manager.get_model_size_info(quantized_model)
print(f"æ¨¡å‹å¤§å°: {size_info['model_size_mb']:.2f}MB")
```

### å‘½ä»¤è¡Œé‡åŒ–å·¥å…·

```bash
# é‡åŒ–æ¨¡å‹
python tools/quantization_cli.py quantize model.pt output/ --method dynamic

# åˆ†æé‡åŒ–æ•ˆæœ
python tools/quantization_cli.py analyze original.pt quantized.pt analysis/

# è¿è¡Œç¤ºä¾‹
python tools/quantization_cli.py example --method dynamic
```

### é…ç½®æ–‡ä»¶é‡åŒ–

```yaml
# config.yaml
quantization:
  enabled: true
  method: "dynamic"
  dtype: "qint8"
```

è¯¦ç»†ä½¿ç”¨è¯´æ˜è¯·å‚è€ƒ [é‡åŒ–æ¨¡å—æ–‡æ¡£](src/quantization/README.md)ã€‚

## ğŸ§ª æµ‹è¯•

è¿è¡Œæµ‹è¯•ä»¥ç¡®ä¿æ¡†æ¶æ­£å¸¸å·¥ä½œï¼š

```bash
# æ¿€æ´»ç¯å¢ƒ
conda activate ntrain

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest tests/ -v

# è¿è¡Œç‰¹å®šæµ‹è¯•
python -m pytest tests/test_dataset_creation.py -v

# æµ‹è¯•æ•°æ®é›†åˆ›å»º
python test_dataset_creation.py

# æµ‹è¯•å¢å¼ºé…ç½®
python test_enhanced_config.py
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“ æ›´æ–°æ—¥å¿—

### v1.2.0 (æœ€æ–°)
- âœ¨ æ–°å¢CIFAR-10å’ŒCIFAR-100æ•°æ®é›†æ”¯æŒï¼Œç”¨äºå›¾åƒåˆ†ç±»ä»»åŠ¡
- ğŸ“Š æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯ï¼ˆmean/stdï¼‰ä½œä¸ºé™æ€å˜é‡ï¼Œä¾¿äºè®¿é—®
- ğŸ”§ æ–°å¢metadataé™æ€æ–¹æ³•ï¼Œæä¾›ç±»åˆ«ä¿¡æ¯å’Œæ¨èmetrics
- ğŸ“š æ·»åŠ CIFARæ•°æ®é›†ä½¿ç”¨æŒ‡å—å’Œç¤ºä¾‹ä»£ç 
- âœ… æ”¯æŒè‡ªåŠ¨ä¸‹è½½CIFARæ•°æ®é›†

### v1.1.0
- âœ¨ æ–°å¢COCOæ•°æ®é›†æ”¯æŒï¼Œæ”¯æŒç›®æ ‡æ£€æµ‹ã€å®ä¾‹åˆ†å‰²ã€å…³é”®ç‚¹æ£€æµ‹å’Œå›¾åƒæè¿°ä»»åŠ¡
- ğŸ“š æ·»åŠ COCOæ•°æ®é›†ä½¿ç”¨æŒ‡å—å’Œç¤ºä¾‹ä»£ç 
- ğŸ› ï¸ æä¾›COCOæ•°æ®é›†è‡ªåŠ¨ä¸‹è½½è„šæœ¬
- âœ… æ·»åŠ COCOæ•°æ®é›†å•å…ƒæµ‹è¯•

### v1.0.0
- âœ¨ æ–°å¢å¢å¼ºç‰ˆæ··åˆæ•°æ®é›†æ”¯æŒ
- âœ¨ æ”¯æŒå¤šç§é‡‡æ ·ç­–ç•¥ï¼ˆæƒé‡ã€å¹³è¡¡ã€ä¼˜å…ˆçº§ï¼‰
- âœ¨ å®Œå–„çš„æ–‡æ¡£ç³»ç»Ÿ
- ğŸ› ä¿®å¤RGBé€šé“ä¸åŒ¹é…é—®é¢˜
- ğŸ”§ ä¼˜åŒ–é…ç½®æ–‡ä»¶ç»“æ„

### v0.9.0
- âœ¨ åŸºç¡€æ··åˆæ•°æ®é›†åŠŸèƒ½
- âœ¨ UNetæ¨¡å‹æ”¯æŒ
- âœ¨ åŸºç¡€è®­ç»ƒå’Œæµ‹è¯•æµç¨‹

## ğŸ”® è®¡åˆ’åŠŸèƒ½

- [x] é€šç”¨ç›®æ ‡æ£€æµ‹æ•°æ®é›†æ”¯æŒï¼ˆCOCOï¼‰âœ…
- [x] å›¾åƒåˆ†ç±»æ•°æ®é›†æ”¯æŒï¼ˆCIFAR-10/100ï¼‰âœ…
- [ ] æ›´å¤šæ·±åº¦å­¦ä¹ æ¨¡å‹æ”¯æŒï¼ˆResNetã€DenseNetã€Transformerç­‰ï¼‰
- [ ] è‡ªåŠ¨è¶…å‚æ•°è°ƒä¼˜
- [ ] åˆ†å¸ƒå¼è®­ç»ƒä¼˜åŒ–
- [ ] æ¨¡å‹é‡åŒ–å’Œå‰ªæ
- [ ] æ›´å¤šåŒ»å­¦å›¾åƒæ•°æ®é›†æ”¯æŒ
- [ ] Webç•Œé¢ç®¡ç†å·¥å…·

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…ã€‚

## ğŸ™ è‡´è°¢

æ„Ÿè°¢ä»¥ä¸‹å¼€æºé¡¹ç›®çš„æ”¯æŒï¼š
- [PyTorch](https://pytorch.org/) - æ·±åº¦å­¦ä¹ æ¡†æ¶
- [torchvision](https://pytorch.org/vision/) - è®¡ç®—æœºè§†è§‰å·¥å…·
- [Albumentations](https://albumentations.ai/) - å›¾åƒå¢å¼ºåº“
- [MONAI](https://monai.io/) - åŒ»å­¦å›¾åƒåˆ†æå·¥å…·

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡ä»¥ä¸‹æ–¹å¼è”ç³»ï¼š
- æäº¤ [Issue](https://github.com/rinbarpen/NeuroTrain/issues)
- å‘é€é‚®ä»¶è‡³ï¼š[your-email@example.com]
- é¡¹ç›®ä¸»é¡µï¼š[https://github.com/rinbarpen/NeuroTrain]

---

**NeuroTrain** - è®©åŒ»å­¦å›¾åƒåˆ†å‰²å˜å¾—ç®€å•é«˜æ•ˆï¼ ğŸš€
    â”‚   â”‚   â”œâ”€â”€ config[.json|.toml|.yaml]  # å®éªŒé…ç½®æ–‡ä»¶
    â”‚   â”‚   â”œâ”€â”€ [mean|std]_metric.csv  # æ‰€æœ‰ç±»åˆ«çš„å‡å€¼æŒ‡æ ‡å’Œæ ‡å‡†å·®æŒ‡æ ‡
    â”‚   â”‚   â”œâ”€â”€ mean_metrics_per_classes.png  # æ¯ä¸ªç±»åˆ«çš„å‡å€¼æŒ‡æ ‡å¯è§†åŒ–å›¾
    â”‚   â”‚   â””â”€â”€ mean_metrics.png  # æ‰€æœ‰ç±»åˆ«çš„å‡å€¼æŒ‡æ ‡å¯è§†åŒ–å›¾
    â”‚   â”œâ”€â”€ predict/          # é¢„æµ‹ç›¸å…³è¾“å‡º
    â”‚   â”‚   â”œâ”€â”€ {predicted_files}  # é¢„æµ‹è¾“å‡ºæ–‡ä»¶
    â”‚   â”‚   â””â”€â”€ config[.json|.toml|.yaml]  # å®éªŒé…ç½®æ–‡ä»¶
    â”œâ”€â”€ logs/                 # è®­ç»ƒæ—¥å¿—
    |   â””â”€â”€ [train|test|predict].log  # æ¯ä¸ªä»»åŠ¡çš„æ—¥å¿—æ–‡ä»¶
    â”‚   model_flop_count.txt  # æ¨¡å‹ FLOP ç»Ÿè®¡
    â””â”€â”€ model_summary.txt     # æ¨¡å‹å‚æ•°ç»Ÿè®¡
```

## è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä»£ç ã€æ–‡æ¡£ã€é—®é¢˜æŠ¥å‘Šå’ŒåŠŸèƒ½å»ºè®®ã€‚è¯·é€šè¿‡æäº¤ Pull Request æˆ–æ‰“å¼€ Issue æ¥å‚ä¸è´¡çŒ®ã€‚

## è®¸å¯è¯

æœ¬é¡¹ç›®åŸºäº MIT è®¸å¯è¯å¼€æºã€‚è¯¦æƒ…è¯·è§ `LICENSE` æ–‡ä»¶ã€‚