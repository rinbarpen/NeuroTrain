import gradio as gr
import subprocess
import threading
import queue
import json
import time
import os
import psutil
import GPUtil
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
# é…ç½®matplotlibæ”¯æŒä¸­æ–‡å­—ä½“
import matplotlib.font_manager as fm
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
import numpy as np
from datetime import datetime
import torch
import logging
from typing import Optional, Tuple, List
import io
import base64
from PIL import Image

class SystemMonitor:
    """ç³»ç»Ÿèµ„æºç›‘æ§å™¨"""
    
    def __init__(self):
        self.cpu_history = []
        self.memory_history = []
        self.gpu_history = []
        self.max_history = 100
        
    def get_system_info(self):
        """è·å–ç³»ç»Ÿä¿¡æ¯"""
        info = {
            'torch_version': torch.__version__,
            'cuda_available': torch.cuda.is_available(),
            'cuda_version': torch.version.cuda if torch.cuda.is_available() else 'N/A',
            'gpu_count': torch.cuda.device_count() if torch.cuda.is_available() else 0
        }
        return info
    
    def get_current_usage(self):
        """è·å–å½“å‰èµ„æºä½¿ç”¨æƒ…å†µ"""
        # CPUä½¿ç”¨ç‡
        cpu_percent = psutil.cpu_percent(interval=1)
        
        # å†…å­˜ä½¿ç”¨æƒ…å†µ
        memory = psutil.virtual_memory()
        memory_percent = memory.percent
        memory_used = memory.used / (1024**3)  # GB
        memory_total = memory.total / (1024**3)  # GB
        
        # GPUä½¿ç”¨æƒ…å†µ
        gpu_info = []
        if torch.cuda.is_available():
            try:
                gpus = GPUtil.getGPUs()
                for gpu in gpus:
                    gpu_info.append({
                        'id': gpu.id,
                        'name': gpu.name,
                        'load': gpu.load * 100,
                        'memory_used': gpu.memoryUsed,
                        'memory_total': gpu.memoryTotal,
                        'memory_percent': (gpu.memoryUsed / gpu.memoryTotal) * 100,
                        'temperature': gpu.temperature
                    })
            except:
                # å¦‚æœGPUtilå¤±è´¥ï¼Œä½¿ç”¨torchè·å–åŸºæœ¬ä¿¡æ¯
                for i in range(torch.cuda.device_count()):
                    memory_used = torch.cuda.memory_allocated(i) / (1024**3)
                    memory_total = torch.cuda.get_device_properties(i).total_memory / (1024**3)
                    gpu_info.append({
                        'id': i,
                        'name': torch.cuda.get_device_name(i),
                        'load': 0,  # torchæ— æ³•ç›´æ¥è·å–GPUä½¿ç”¨ç‡
                        'memory_used': memory_used,
                        'memory_total': memory_total,
                        'memory_percent': (memory_used / memory_total) * 100,
                        'temperature': 0
                    })
        
        # æ›´æ–°å†å²è®°å½•
        self.cpu_history.append(cpu_percent)
        self.memory_history.append(memory_percent)
        if gpu_info:
            self.gpu_history.append(gpu_info[0]['memory_percent'])
        
        # é™åˆ¶å†å²è®°å½•é•¿åº¦
        if len(self.cpu_history) > self.max_history:
            self.cpu_history.pop(0)
            self.memory_history.pop(0)
            if self.gpu_history:
                self.gpu_history.pop(0)
        
        return {
            'cpu_percent': cpu_percent,
            'memory_percent': memory_percent,
            'memory_used': memory_used,
            'memory_total': memory_total,
            'gpu_info': gpu_info,
            'cpu_history': self.cpu_history.copy(),
            'memory_history': self.memory_history.copy(),
            'gpu_history': self.gpu_history.copy()
        }

class TrainingMonitor:
    """è®­ç»ƒç›‘æ§å™¨"""
    
    def __init__(self):
        self.process = None
        self.output_dir = None
        self.is_running = False
        self.mode = 'train'  # train, test, predict
        self.stdout_lines = []
        self.stderr_lines = []
        self.max_lines = 1000
        
    def start_process(self, mode: str, config_file: str, output_dir: str, extra_args: List[str] = None) -> Tuple[bool, str]:
        """å¯åŠ¨è®­ç»ƒ/æµ‹è¯•/é¢„æµ‹è¿›ç¨‹"""
        if self.is_running:
            return False, f"{self.mode}è¿›ç¨‹æ­£åœ¨è¿è¡Œä¸­"
            
        self.mode = mode
        self.output_dir = Path(output_dir)
        self.stdout_lines = []
        self.stderr_lines = []
        
        # æ„å»ºå‘½ä»¤
        if mode == 'train':
            cmd = ["python", "main.py", "-c", config_file]
        elif mode == 'test':
            cmd = ["python", "main.py", "-c", config_file, "--test"]
        elif mode == 'predict':
            cmd = ["python", "main.py", "-c", config_file, "--predict"]
        else:
            return False, f"ä¸æ”¯æŒçš„æ¨¡å¼: {mode}"
            
        if extra_args:
            cmd.extend(extra_args)
        
        try:
            self.process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            self.is_running = True
            
            # å¯åŠ¨è¾“å‡ºç›‘æ§çº¿ç¨‹
            threading.Thread(target=self._monitor_output, daemon=True).start()
            
            return True, f"{mode}è¿›ç¨‹å¯åŠ¨æˆåŠŸ"
        except Exception as e:
            return False, f"å¯åŠ¨å¤±è´¥: {str(e)}"
    
    def stop_process(self) -> Tuple[bool, str]:
        """åœæ­¢è¿›ç¨‹"""
        if self.process and self.is_running:
            self.process.terminate()
            self.is_running = False
            return True, f"{self.mode}è¿›ç¨‹å·²åœæ­¢"
        return False, "æ²¡æœ‰è¿è¡Œä¸­çš„è¿›ç¨‹"
    
    def _monitor_output(self):
        """ç›‘æ§è¿›ç¨‹è¾“å‡º"""
        def read_stdout():
            while self.is_running and self.process:
                try:
                    line = self.process.stdout.readline()
                    if line:
                        timestamp = datetime.now().strftime("%H:%M:%S")
                        self.stdout_lines.append(f"[{timestamp}] {line.strip()}")
                        if len(self.stdout_lines) > self.max_lines:
                            self.stdout_lines.pop(0)
                    elif self.process.poll() is not None:
                        break
                except:
                    break
        
        def read_stderr():
            while self.is_running and self.process:
                try:
                    line = self.process.stderr.readline()
                    if line:
                        timestamp = datetime.now().strftime("%H:%M:%S")
                        self.stderr_lines.append(f"[{timestamp}] {line.strip()}")
                        if len(self.stderr_lines) > self.max_lines:
                            self.stderr_lines.pop(0)
                    elif self.process.poll() is not None:
                        break
                except:
                    break
        
        # å¯åŠ¨è¯»å–çº¿ç¨‹
        threading.Thread(target=read_stdout, daemon=True).start()
        threading.Thread(target=read_stderr, daemon=True).start()
        
        # ç­‰å¾…è¿›ç¨‹ç»“æŸ
        if self.process:
            self.process.wait()
            self.is_running = False
    
    def get_output_logs(self) -> Tuple[str, str]:
        """è·å–è¾“å‡ºæ—¥å¿—"""
        stdout_text = "\n".join(self.stdout_lines[-100:])  # æœ€è¿‘100è¡Œ
        stderr_text = "\n".join(self.stderr_lines[-100:])  # æœ€è¿‘100è¡Œ
        return stdout_text, stderr_text
    
    def get_training_data(self):
        """è·å–è®­ç»ƒæ•°æ®"""
        if not self.output_dir or not self.output_dir.exists():
            return None, None, None
        
        # è¯»å–æŸå¤±æ•°æ®
        loss_data = {}
        train_loss_file = self.output_dir / "train_loss.csv"
        valid_loss_file = self.output_dir / "valid_loss.csv"
        
        if train_loss_file.exists():
            try:
                df = pd.read_csv(train_loss_file)
                loss_data['train_loss'] = df['loss'].tolist()
            except:
                pass
        
        if valid_loss_file.exists():
            try:
                df = pd.read_csv(valid_loss_file)
                loss_data['valid_loss'] = df['loss'].tolist()
            except:
                pass
        
        # è¯»å–æŒ‡æ ‡æ•°æ®
        metrics_data = {}
        mean_metric_file = self.output_dir / "mean_metric.csv"
        if mean_metric_file.exists():
            try:
                df = pd.read_csv(mean_metric_file)
                if not df.empty:
                    metrics_data = df.iloc[-1].to_dict()
            except:
                pass
        
        # è¯»å–å›¾ç‰‡
        loss_image = None
        loss_image_file = self.output_dir / "train_epoch_loss.png"
        if loss_image_file.exists():
            try:
                loss_image = str(loss_image_file)
            except:
                pass
        
        return loss_data, metrics_data, loss_image

# å…¨å±€å®ä¾‹
system_monitor = SystemMonitor()
training_monitor = TrainingMonitor()

def create_system_info_display():
    """åˆ›å»ºç³»ç»Ÿä¿¡æ¯æ˜¾ç¤º"""
    info = system_monitor.get_system_info()
    
    info_text = f"""
    ğŸ”§ **ç³»ç»Ÿä¿¡æ¯**
    - PyTorchç‰ˆæœ¬: {info['torch_version']}
    - CUDAå¯ç”¨: {'æ˜¯' if info['cuda_available'] else 'å¦'}
    - CUDAç‰ˆæœ¬: {info['cuda_version']}
    - GPUæ•°é‡: {info['gpu_count']}
    """
    
    return info_text

def create_resource_monitor():
    """åˆ›å»ºèµ„æºç›‘æ§å›¾è¡¨"""
    usage = system_monitor.get_current_usage()
    
    # åˆ›å»ºå›¾è¡¨
    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(12, 8))
    fig.suptitle('ç³»ç»Ÿèµ„æºç›‘æ§', fontsize=16)
    
    # CPUä½¿ç”¨ç‡å†å²
    if usage['cpu_history']:
        ax1.plot(usage['cpu_history'], 'b-', linewidth=2)
        ax1.set_title(f'CPUä½¿ç”¨ç‡: {usage["cpu_percent"]:.1f}%')
        ax1.set_ylabel('ä½¿ç”¨ç‡ (%)')
        ax1.set_ylim(0, 100)
        ax1.grid(True, alpha=0.3)
    
    # å†…å­˜ä½¿ç”¨ç‡å†å²
    if usage['memory_history']:
        ax2.plot(usage['memory_history'], 'g-', linewidth=2)
        ax2.set_title(f'å†…å­˜ä½¿ç”¨ç‡: {usage["memory_percent"]:.1f}% ({usage["memory_used"]:.1f}/{usage["memory_total"]:.1f} GB)')
        ax2.set_ylabel('ä½¿ç”¨ç‡ (%)')
        ax2.set_ylim(0, 100)
        ax2.grid(True, alpha=0.3)
    
    # GPUä½¿ç”¨ç‡å†å²
    if usage['gpu_history']:
        ax3.plot(usage['gpu_history'], 'r-', linewidth=2)
        gpu_current = usage['gpu_info'][0]['memory_percent'] if usage['gpu_info'] else 0
        ax3.set_title(f'GPUå†…å­˜ä½¿ç”¨ç‡: {gpu_current:.1f}%')
        ax3.set_ylabel('ä½¿ç”¨ç‡ (%)')
        ax3.set_ylim(0, 100)
        ax3.grid(True, alpha=0.3)
    else:
        ax3.text(0.5, 0.5, 'GPUä¸å¯ç”¨', ha='center', va='center', transform=ax3.transAxes)
        ax3.set_title('GPUç›‘æ§')
    
    # GPUè¯¦ç»†ä¿¡æ¯
    if usage['gpu_info']:
        gpu_names = []
        gpu_loads = []
        gpu_temps = []
        
        for gpu in usage['gpu_info']:
            gpu_names.append(f"GPU{gpu['id']}")
            gpu_loads.append(gpu['memory_percent'])
            gpu_temps.append(gpu['temperature'] if gpu['temperature'] > 0 else 0)
        
        x_pos = np.arange(len(gpu_names))
        bars = ax4.bar(x_pos, gpu_loads, alpha=0.7, color='orange')
        ax4.set_title('GPUå†…å­˜ä½¿ç”¨è¯¦æƒ…')
        ax4.set_ylabel('å†…å­˜ä½¿ç”¨ç‡ (%)')
        ax4.set_xticks(x_pos)
        ax4.set_xticklabels(gpu_names)
        ax4.set_ylim(0, 100)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, (bar, load, temp) in enumerate(zip(bars, gpu_loads, gpu_temps)):
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height + 1,
                    f'{load:.1f}%\n{temp:.0f}Â°C' if temp > 0 else f'{load:.1f}%',
                    ha='center', va='bottom', fontsize=8)
    else:
        ax4.text(0.5, 0.5, 'GPUä¸å¯ç”¨', ha='center', va='center', transform=ax4.transAxes)
        ax4.set_title('GPUè¯¦ç»†ä¿¡æ¯')
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾ç‰‡åˆ°å†…å­˜
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
    buf.seek(0)
    plt.close()
    
    return buf.getvalue()

def create_loss_chart(loss_data):
    """åˆ›å»ºæŸå¤±æ›²çº¿å›¾"""
    if not loss_data:
        return None
    
    plt.figure(figsize=(10, 6))
    
    if 'train_loss' in loss_data and loss_data['train_loss']:
        epochs = range(1, len(loss_data['train_loss']) + 1)
        plt.plot(epochs, loss_data['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
    
    if 'valid_loss' in loss_data and loss_data['valid_loss']:
        epochs = range(1, len(loss_data['valid_loss']) + 1)
        plt.plot(epochs, loss_data['valid_loss'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
    
    plt.title('è®­ç»ƒæŸå¤±æ›²çº¿', fontsize=14)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # ä¿å­˜å›¾ç‰‡åˆ°å†…å­˜
    buf = io.BytesIO()
    plt.savefig(buf, format='png', dpi=100, bbox_inches='tight')
    buf.seek(0)
    plt.close()
    
    return buf.getvalue()

def format_metrics_display(metrics_data):
    """æ ¼å¼åŒ–æŒ‡æ ‡æ˜¾ç¤º"""
    if not metrics_data:
        return "æš‚æ— æŒ‡æ ‡æ•°æ®"
    
    formatted_text = "ğŸ“Š **æœ€æ–°è®­ç»ƒæŒ‡æ ‡**\n\n"
    
    for key, value in metrics_data.items():
        if key != 'Unnamed: 0' and isinstance(value, (int, float)):
            formatted_text += f"- **{key}**: {value:.4f}\n"
    
    return formatted_text

def start_training(config_file, output_dir, extra_args):
    """å¯åŠ¨è®­ç»ƒ"""
    extra_list = extra_args.split() if extra_args.strip() else []
    success, message = training_monitor.start_process('train', config_file, output_dir, extra_list)
    return message

def start_testing(config_file, output_dir, extra_args):
    """å¯åŠ¨æµ‹è¯•"""
    extra_list = extra_args.split() if extra_args.strip() else []
    success, message = training_monitor.start_process('test', config_file, output_dir, extra_list)
    return message

def start_prediction(config_file, output_dir, extra_args):
    """å¯åŠ¨é¢„æµ‹"""
    extra_list = extra_args.split() if extra_args.strip() else []
    success, message = training_monitor.start_process('predict', config_file, output_dir, extra_list)
    return message

def stop_process():
    """åœæ­¢è¿›ç¨‹"""
    success, message = training_monitor.stop_process()
    return message

def get_status():
    """è·å–çŠ¶æ€"""
    if training_monitor.is_running:
        return f"ğŸŸ¢ {training_monitor.mode}è¿›ç¨‹è¿è¡Œä¸­"
    else:
        return "ğŸ”´ è¿›ç¨‹å·²åœæ­¢"

def update_logs():
    """æ›´æ–°æ—¥å¿—æ˜¾ç¤º"""
    stdout, stderr = training_monitor.get_output_logs()
    return stdout, stderr

def update_training_data():
    """æ›´æ–°è®­ç»ƒæ•°æ®æ˜¾ç¤º"""
    loss_data, metrics_data, loss_image = training_monitor.get_training_data()
    
    # åˆ›å»ºæŸå¤±å›¾è¡¨
    loss_chart_bytes = create_loss_chart(loss_data)
    loss_chart_image = None
    if loss_chart_bytes:
        loss_chart_image = Image.open(io.BytesIO(loss_chart_bytes))
    
    # æ ¼å¼åŒ–æŒ‡æ ‡
    metrics_text = format_metrics_display(metrics_data)
    
    # åŸå§‹æŸå¤±å›¾ç‰‡
    original_loss_image = None
    if loss_image and Path(loss_image).exists():
        original_loss_image = loss_image
    
    return loss_chart_image, metrics_text, original_loss_image

def update_system_monitor():
    """æ›´æ–°ç³»ç»Ÿç›‘æ§"""
    resource_chart_bytes = create_resource_monitor()
    resource_chart_image = Image.open(io.BytesIO(resource_chart_bytes))
    
    system_info = create_system_info_display()
    
    return resource_chart_image, system_info

# åˆ›å»ºGradioç•Œé¢
with gr.Blocks(title="NeuroTrain Monitor", theme=gr.themes.Soft()) as app:
    gr.Markdown("""
    # ğŸ§  NeuroTrain Monitor
    
    å®æ—¶ç›‘æ§ç¥ç»ç½‘ç»œè®­ç»ƒã€æµ‹è¯•å’Œé¢„æµ‹è¿‡ç¨‹
    """)
    
    with gr.Tab("æ§åˆ¶é¢æ¿"):
        with gr.Row():
            with gr.Column(scale=2):
                config_file = gr.Textbox(
                    label="é…ç½®æ–‡ä»¶è·¯å¾„",
                    value="configs/single/train.template.toml",
                    placeholder="è¾“å…¥é…ç½®æ–‡ä»¶è·¯å¾„"
                )
                output_dir = gr.Textbox(
                    label="è¾“å‡ºç›®å½•",
                    value="outputs/web_training",
                    placeholder="è¾“å…¥è¾“å‡ºç›®å½•è·¯å¾„"
                )
                extra_args = gr.Textbox(
                    label="é¢å¤–å‚æ•°",
                    placeholder="è¾“å…¥é¢å¤–çš„å‘½ä»¤è¡Œå‚æ•°",
                    value=""
                )
            
            with gr.Column(scale=1):
                status_display = gr.Textbox(
                    label="çŠ¶æ€",
                    value="ğŸ”´ è¿›ç¨‹å·²åœæ­¢",
                    interactive=False
                )
                
                with gr.Row():
                    train_btn = gr.Button("ğŸš€ å¼€å§‹è®­ç»ƒ", variant="primary")
                    test_btn = gr.Button("ğŸ§ª å¼€å§‹æµ‹è¯•", variant="secondary")
                    predict_btn = gr.Button("ğŸ”® å¼€å§‹é¢„æµ‹", variant="secondary")
                    stop_btn = gr.Button("â¹ï¸ åœæ­¢", variant="stop")
                
                message_display = gr.Textbox(
                    label="æ¶ˆæ¯",
                    interactive=False,
                    lines=3
                )
    
    with gr.Tab("è¾“å‡ºæ—¥å¿—"):
        with gr.Row():
            with gr.Column():
                stdout_display = gr.Textbox(
                    label="ğŸ“¤ æ ‡å‡†è¾“å‡º (stdout)",
                    lines=20,
                    max_lines=20,
                    interactive=False,
                    show_copy_button=True
                )
            
            with gr.Column():
                stderr_display = gr.Textbox(
                    label="âŒ é”™è¯¯è¾“å‡º (stderr)",
                    lines=20,
                    max_lines=20,
                    interactive=False,
                    show_copy_button=True
                )
    
    with gr.Tab("è®­ç»ƒæ•°æ®"):
        with gr.Row():
            with gr.Column():
                loss_chart_display = gr.Image(
                    label="ğŸ“ˆ æŸå¤±æ›²çº¿",
                    type="pil"
                )
                
                original_loss_display = gr.Image(
                    label="ğŸ“Š åŸå§‹è®­ç»ƒå›¾è¡¨",
                    type="filepath"
                )
            
            with gr.Column():
                metrics_display = gr.Markdown(
                    label="ğŸ“Š è®­ç»ƒæŒ‡æ ‡",
                    value="æš‚æ— æŒ‡æ ‡æ•°æ®"
                )
    
    with gr.Tab("ç³»ç»Ÿç›‘æ§"):
        with gr.Row():
            with gr.Column():
                system_info_display = gr.Markdown(
                    value=create_system_info_display()
                )
            
            with gr.Column():
                resource_chart_display = gr.Image(
                    label="ğŸ“Š ç³»ç»Ÿèµ„æºç›‘æ§",
                    type="pil"
                )
    
    # äº‹ä»¶ç»‘å®š
    train_btn.click(
        fn=start_training,
        inputs=[config_file, output_dir, extra_args],
        outputs=[message_display]
    )
    
    test_btn.click(
        fn=start_testing,
        inputs=[config_file, output_dir, extra_args],
        outputs=[message_display]
    )
    
    predict_btn.click(
        fn=start_prediction,
        inputs=[config_file, output_dir, extra_args],
        outputs=[message_display]
    )
    
    stop_btn.click(
        fn=stop_process,
        outputs=[message_display]
    )

# å®šæ—¶æ›´æ–°å‡½æ•°
def auto_update():
    """è‡ªåŠ¨æ›´æ–°å‡½æ•°"""
    while True:
        try:
            # æ›´æ–°æ—¥å¿—
            stdout, stderr = update_logs()
            
            # æ›´æ–°çŠ¶æ€
            status = get_status()
            
            # æ›´æ–°è®­ç»ƒæ•°æ®
            loss_chart, metrics_text, original_loss = update_training_data()
            
            # æ›´æ–°ç³»ç»Ÿç›‘æ§
            resource_chart, system_info = update_system_monitor()
            
            # è¿™é‡Œå¯ä»¥é€šè¿‡å…¶ä»–æ–¹å¼æ›´æ–°ç•Œé¢ï¼Œæ¯”å¦‚ä½¿ç”¨å…¨å±€å˜é‡æˆ–é˜Ÿåˆ—
            
        except Exception as e:
            print(f"Auto update error: {e}")
        
        time.sleep(2)  # æ¯2ç§’æ›´æ–°ä¸€æ¬¡

if __name__ == "__main__":
    print("NeuroTrain Gradio Monitor starting...")
    print("ç³»ç»Ÿä¿¡æ¯:")
    print(create_system_info_display())
    
    # å¯åŠ¨è‡ªåŠ¨æ›´æ–°çº¿ç¨‹
    threading.Thread(target=auto_update, daemon=True).start()
    
    app.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
        quiet=False
    )
