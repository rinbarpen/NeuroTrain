# 增强版多数据集训练配置模板
# 支持数据集占比控制、加载顺序、权重设置等高级功能

output_dir = "./runs"
task = "Enhanced_Multi_Dataset_Training"
entity = "Lab"
run_id = "" # be Random set by program
device = "cuda"
seed = 42
classes = ["Retina"]
metrics = ['iou', 'accuracy', 'precision', 'recall', 'f1', 'dice']
postprocess = "binary_segmentation" # binary_segmentation, instance_segmentation, ...

[model]
name = "unet"
continue_checkpoint = "" # use this if encountering crash while training
continue_ext_checkpoint = "" # use this if encountering crash while training
pretrained = ""

[model.config]
n_channels = 3
n_classes = 2
input_sizes = [
    [1, 3, 512, 512]
]
dtypes = ["float32"]

[[criterion]]
type = 'dice'
weight = 1.0 # default is 1.0
config = {}

[[criterion]]
type = 'bce'
weight = 0.3
config = {}

[transform]
# (RESIZE, resize)
# (ROTATION, degree)
# (HFLIP, p)
# (VFLOP, p)
# (INVERT, p)
# (TO_TENSOR)
# (PIL_TO_TENSOR)
# (NORMALIZE, is_rgb)
RESIZE=[512, 512]
ROTATION=[15]
HFLIP=[0.5]
VFLIP=[0.5]
# INVERT=[0.1]
PIL_TO_TENSOR=[]
CONVERT_IMAGE_DTYPE=['float32']
# TO_TENSOR=[]

# 增强版数据集配置
[dataset]
# 数据集类型：支持 "single", "hybrid", "enhanced_hybrid"
type = "enhanced_hybrid"
config = {}

# 增强版混合数据集配置
[dataset.enhanced_hybrid]
# 全局设置
shuffle_order = false              # 是否在每个epoch随机打乱数据集顺序
random_seed = 42                   # 随机种子，用于可重现性
enable_dynamic_resampling = true   # 是否启用动态重采样功能

# 数据集列表配置
[[dataset.enhanced_hybrid.datasets]]
name = "drive"                     # 数据集名称
ratio = 0.5                        # 采样比例 (0.0-1.0)
priority = 1                       # 优先级 (数字越小优先级越高)
weight = 1.0                       # 数据集权重
# 数据集特定配置
root_dir = "./data/DRIVE"
class_name = "drive"               # 修正为正确的数据集名称
train_split = "training"
test_split = "test"
is_rgb = true                      # 以RGB模式加载图像，确保3通道输入

[[dataset.enhanced_hybrid.datasets]]
name = "chasedb1"
ratio = 0.3
priority = 2
weight = 1.2                       # 给予更高权重
root_dir = "./data/CHASEDB1"
class_name = "medical/chasedb1"    # 修正为正确的数据集名称
train_split = "train"
test_split = "test"
is_rgb = true                      # 以RGB模式加载图像，确保3通道输入

[[dataset.enhanced_hybrid.datasets]]
name = "stare"
ratio = 0.2
priority = 3
weight = 0.8                       # 给予较低权重
root_dir = "./data/STARE"
class_name = "medical/stare"       # 修正为正确的数据集名称
train_split = "train"
test_split = "test"
is_rgb = true                      # 以RGB模式加载图像，确保3通道输入

[dataloader]
num_workers = 4 # 0 to disable multiprocessing, or set to a positive integer for the number of worker processes
shuffle = true
pin_memory = true

[train]
batch_size = 16
epoch = 100
# if 0 < save_period < 1, then save temporary checkpoint and metrics per (num_epochs * save_period) epochs
# if save_period >= 1, then save temporary checkpoint and metrics per save_period epochs
# if save_period <= 0, then will only save the last one
save_period = 0.2 # the period of saving temporary checkpoint and metrics
# if 0 < save_recovery_period < 1, then save recovery info per (num_epochs * save_recovery_period) epochs
# if save_recovery_period >= 1, then save recovery info per save_recovery_period epochs
# if save_recovery_period <= 0, then will only save the last one
save_recovery_period = 0.2 # the period of saving recovery info
grad_accumulation_steps = 0 # <= 0 for disabled
## support info to peek in training pbar:
# loss: train_loss, valid_loss(if available)
# metric: metric value if defined
# epoch: which epoch in current time
# epoch_time_left: time left for training in current epoch
## trainer info peek
# lr: learning rate
# train_recorder = ['loss', 'auc', 'lr', 'epoch_time_left', 'epoch']

[train.optimizer]
type = 'adam' # sgd, adam, adamw
learning_rate = 0.001
weight_decay = 1e-8

# [train.lr_scheduler]
# type = 'step'
# warmup = 50
# warmup_lr = 0.03
# update_policy = 'epoch' # 'step'

[train.scaler]
compute_type = 'bfloat16'

# [train.early_stopping]
# patience = 3

[test]
batch_size = 16

[predict]
input = "data/DRIVE/test/images"

[predict.config]

[private]
wandb = false
mode = 0

[private.log]
verbose = true # info mode
debug = false # debug mode
log_file_format = '%Y-%m-%d %H_%M_%S'
log_format = '%(asctime)s %(levelname)s | %(name)s | %(message)s'