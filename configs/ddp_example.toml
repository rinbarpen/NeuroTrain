# DDP训练配置文件
# 用于PyTorch分布式数据并行训练

output_dir = "./runs"
task = "DDP_Training"
entity = "Lab"
run_id = "" # 由程序随机设置
device = "cuda"
seed = 42
classes = ["class_0", "class_1", "class_2"] # 根据实际类别修改
metrics = ['accuracy', 'precision', 'recall', 'f1', 'dice']
postprocess = "classification" # classification, binary_segmentation, instance_segmentation, ...

# DDP配置
[ddp]
enabled = true
log_level = "INFO"  # DEBUG, INFO, WARNING, ERROR

[model]
name = "resnet18"  # 模型名称，可以是torchvision、unet、custom等
continue_checkpoint = "" # 继续训练的检查点路径
continue_ext_checkpoint = "" # 继续训练的扩展检查点路径
pretrained = "" # 预训练模型路径

[model.config]
arch = "resnet18"        # 模型架构
n_channels = 3            # 输入通道数
n_classes = 3             # 类别数
input_sizes = [
    [1, 3, 224, 224]     # 输入尺寸 [batch, channels, height, width]
]
dtypes = ["float32"]     # 数据类型
pretrained = true        # 是否使用预训练权重

# 损失函数配置
[[criterion]]
type = 'cross_entropy'   # 损失函数类型
weight = 1.0            # 权重
config = {}

# 可选：添加多个损失函数
# [[criterion]]
# type = 'dice'
# weight = 0.5
# config = {}

# 数据变换配置
[transform]
RESIZE = [224, 224]      # 调整图像大小
HFLIP = [0.5]           # 水平翻转概率
VFLIP = [0.1]           # 垂直翻转概率
ROTATION = [10]         # 旋转角度范围
PIL_TO_TENSOR = []      # 转换为张量
CONVERT_IMAGE_DTYPE = ['float32']  # 转换数据类型
NORMALIZE = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]]  # ImageNet标准归一化

# 数据集配置
[dataset]
name = "CustomDataset"   # 数据集名称
root_dir = "./data"      # 数据根目录
config = {}             # 数据集特定配置
ref = "custom.yaml"     # 参考配置文件

# 数据分割配置
[dataset.split]
type = "train_valid_test_split" 
train = 0.8            # 训练集比例
valid = 0.1            # 验证集比例
test = 0.1             # 测试集比例
shuffle = true         # 是否打乱数据
random_state = 42      # 随机种子

# 数据加载器配置
[dataloader]
num_workers = 4        # 工作进程数，0表示禁用多进程
shuffle = true         # 是否打乱数据
pin_memory = true      # 是否固定内存
drop_last = true       # 是否丢弃最后一批不完整的数据

# 训练配置
[train]
batch_size = 32        # 批次大小
epoch = 100            # 训练轮数
save_period = 0.1      # 保存检查点的周期（相对于总轮数的比例）
save_recovery_period = 0.1  # 保存恢复信息的周期
grad_accumulation_steps = 1  # 梯度累积步数，0表示禁用

# 优化器配置
[train.optimizer]
type = 'adamw'         # 优化器类型：sgd, adam, adamw
learning_rate = 1e-3    # 学习率
weight_decay = 1e-4     # 权重衰减

# 学习率调度器配置（可选）
[train.lr_scheduler]
type = 'cosine'         # 调度器类型：step, cosine, linear, exponential
warmup = 10            # 预热轮数
warmup_lr = 1e-5       # 预热学习率
update_policy = 'epoch' # 更新策略：epoch, step

# 混合精度训练配置
[train.scaler]
compute_type = 'float16'  # 计算类型：float16, bfloat16, float32

# 早停配置（可选）
[train.early_stopping]
patience = 10           # 早停耐心值
min_delta = 0.001      # 最小改善阈值

# 测试配置
[test]
batch_size = 32        # 测试批次大小

# 预测配置
[predict]
input = "data/test"    # 预测输入路径

[predict.config]
output_format = "json" # 输出格式
save_images = true     # 是否保存图像

# 私有配置
[private]
wandb = false          # 是否使用wandb记录
mode = 0              # 运行模式

# 日志配置
[private.log]
verbose = true         # 详细日志模式
debug = false         # 调试模式
log_file_format = '%Y-%m-%d %H_%M_%S'  # 日志文件格式
log_format = '%(asctime)s %(levelname)s | %(name)s | %(message)s'  # 日志格式

# 输出配置
[output]
save_best = true       # 保存最佳模型
save_last = true       # 保存最后一个模型
save_interval = 10     # 保存间隔（轮数）
