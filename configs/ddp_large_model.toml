# DDP大模型训练配置文件
# 用于大型深度学习模型的分布式训练

output_dir = "./runs"
task = "DDP_Large_Model"
entity = "Lab"
run_id = "" # 由程序随机设置
device = "cuda"
seed = 42
classes = ["class_0", "class_1", "class_2", "class_3", "class_4"] # 多分类
metrics = ['accuracy', 'precision', 'recall', 'f1', 'auc']
postprocess = "classification"

# DDP配置
[ddp]
enabled = true
log_level = "INFO"

[model]
name = "torchvision"  # 使用torchvision预训练模型
continue_checkpoint = ""
continue_ext_checkpoint = ""
pretrained = ""

[model.config]
arch = "resnet50"      # 使用ResNet50
n_channels = 3         # RGB图像
n_classes = 5          # 5分类任务
input_sizes = [
    [1, 3, 224, 224]   # ImageNet标准尺寸
]
dtypes = ["float32"]
pretrained = true      # 使用ImageNet预训练权重

# 损失函数
[[criterion]]
type = 'cross_entropy'
weight = 1.0
config = {}

# 数据增强配置
[transform]
RESIZE = [256, 256]    # 先调整到256
CENTER_CROP = [224, 224] # 中心裁剪到224
HFLIP = [0.5]
VFLIP = [0.1]
ROTATION = [15]
COLOR_JITTER = [0.2, 0.2, 0.2, 0.1] # 颜色抖动
PIL_TO_TENSOR = []
CONVERT_IMAGE_DTYPE = ['float32']
NORMALIZE = [[0.485, 0.456, 0.406], [0.229, 0.224, 0.225]] # ImageNet归一化

# 数据集配置
[dataset]
name = "CustomDataset"
root_dir = "./data"
config = {}
ref = "custom.yaml"

# 数据分割
[dataset.split]
type = "train_valid_test_split"
train = 0.8
valid = 0.1
test = 0.1
shuffle = true
random_state = 42

# 数据加载器
[dataloader]
num_workers = 8        # 大模型训练使用更多工作进程
shuffle = true
pin_memory = true
drop_last = true

# 训练配置
[train]
batch_size = 64        # 大模型可以使用更大的批次
epoch = 300
save_period = 0.05     # 更频繁保存
save_recovery_period = 0.05
grad_accumulation_steps = 1

# 优化器
[train.optimizer]
type = 'adamw'
learning_rate = 1e-4   # 大模型通常使用较小的学习率
weight_decay = 1e-4

# 学习率调度
[train.lr_scheduler]
type = 'cosine'
warmup = 30            # 更长的预热期
warmup_lr = 1e-6
update_policy = 'epoch'

# 混合精度训练
[train.scaler]
compute_type = 'float16'

# 早停
[train.early_stopping]
patience = 20
min_delta = 0.001

# 测试
[test]
batch_size = 64

# 预测
[predict]
input = "data/test"

[predict.config]
output_format = "json"
save_images = false
top_k = 5

# 私有配置
[private]
wandb = true
mode = 0

[private.log]
verbose = true
debug = false
log_file_format = '%Y-%m-%d %H_%M_%S'
log_format = '%(asctime)s %(levelname)s | %(name)s | %(message)s'

# 输出配置
[output]
save_best = true
save_last = true
save_interval = 25
