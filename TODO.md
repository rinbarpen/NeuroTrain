# NeuroTrain 项目改进建议 (TODO)

## 1. 核心架构与代码质量

- **[ ] 重构 `src/dataset/dataset.py`**: 当前的数据集加载逻辑非常复杂，耦合了多种数据集的处理方式。建议将其重构为更模块化的结构：
  - 使用工厂模式或注册机制，根据配置动态选择和实例化对应的数据集类。
- **[ ] 减少代码重复**: 审查 `src/utils/` 和其他模块，将功能相似的辅助函数进行整合，避免代码冗余。
- **[ ] 增强错误处理**: 在文件加载、模型构建和数据处理等关键环节加入更健壮的错误处理逻辑（例如，使用 `try...except` 块），以应对配置错误或数据缺失等问题。

## 2. 配置管理

- **[ ] 引入 Pydantic 进行配置验证**: 当前的 `Config` 类功能强大，但缺少对配置项的严格验证。建议将 `Config` 类与 Pydantic 模型结合，为每个配置项（如 `model`, `dataset`, `optimizer`）定义类型和约束，从而在项目启动时自动校验配置文件的正确性，防止运行时因配置错误而失败。
- **[ ] 避免硬编码路径**: 全局搜索项目中的硬编码路径（如 `data/`、`runs/`），并将其替换为可以通过主配置文件 (`config.toml`) 或命令行参数指定的配置项。

## 3. 测试与持续集成

- **[ ] 建立单元测试框架**: 引入 `pytest` 等测试框架，为核心模块（特别是 `src/utils/`, `src/metrics/`, `src/models/` 中的关键函数）编写单元测试。
- **[ ] 增加集成测试**: 编写集成测试，模拟完整的训练、测试和预测流程，以确保各模块协同工作正常。
- **[ ] 设置 CI/CD 流水线**: 配置 GitHub Actions 或类似的 CI/CD 工具，实现代码提交时自动运行测试、代码风格检查 (linter) 和构建。

## 4. 文档与开发者体验

- **[ ] 完善代码内文档 (Docstrings)**: 为项目中的主要类和函数补充详细的 Docstrings，遵循统一的格式（如 Google 或 NumPy 风格），并使用类型提示 (Type Hinting)。
- **[ ] 增加开发者贡献指南**: 创建 `CONTRIBUTING.md` 文件，说明如何设置开发环境、运行测试、提交代码以及代码风格规范。

## 5. 依赖管理

- **[ ] 使用 `requirements.txt` 或 `pyproject.toml`**: 替代当前的 `.python-version` 文件，使用 `requirements.txt` 或 `pyproject.toml` (配合 Poetry 或 PDM) 来明确和锁定项目的所有依赖项及其版本。这能确保在不同环境中都能创建一致的、可复现的运行环境。

## 6. 功能与工具增强

- **[ ] 完善 `tools/analyzer.py`**:
  - 实现 `_comparative_score_table` 函数，使其能够真正生成跨模型、跨任务的性能对比表。
  - 增加将分析结果导出为 Markdown 或 PDF 报告的功能。
- **[ ] 集成 ONNX 导出流程**: 将 `tools/onnx_export.py` 的功能集成到主训练流程中。例如，在 `main.py` 中增加一个 `--export-onnx` 标志，在训练完成后自动将最佳模型导出为 ONNX 格式。
- **[ ] 增强可视化工具**:
  - 在 `tools/` 中增加更多可视化脚本，例如可视化模型注意力图、特征图或错误样本。
  - 考虑使用更交互式的可视化库（如 Plotly），以获得更好的分析体验。