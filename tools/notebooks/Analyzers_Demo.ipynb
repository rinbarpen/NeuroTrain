{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NeuroTrain Analyzers 使用示例\n",
        "\n",
        "本 Notebook 演示 `tools/analyzers` 模块的三类分析器：\n",
        "- DatasetAnalyzer（数据集分析）\n",
        "- MetricsAnalyzer（指标分析）\n",
        "- AttentionAnalyzer（注意力分析）\n",
        "\n",
        "运行前提：\n",
        "- 已安装项目依赖并可导入 `tools.analyzers`\n",
        "- 需要图形后端（Matplotlib/Seaborn），若在纯终端请使用 `%matplotlib inline` 或切换合适后端\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python: 3.10.18 (main, Jun  5 2025, 13:14:17) [GCC 11.2.0]\n",
            "PyTorch: 2.7.1+cu126\n",
            "Matplotlib backend: inline\n",
            "Project root exists: True\n",
            "Analyzers imported OK\n"
          ]
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "import sys, os\n",
        "from pathlib import Path\n",
        "\n",
        "# 将项目根目录加入 sys.path，便于在 Notebook 中导入包\n",
        "PROJECT_ROOT = Path('/home/rczx/workspace/sxy/lab/NeuroTrain')\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.insert(0, str(PROJECT_ROOT))\n",
        "\n",
        "# 基础依赖与环境检测\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print('Python:', sys.version)\n",
        "print('PyTorch:', torch.__version__)\n",
        "print('Matplotlib backend:', matplotlib.get_backend())\n",
        "print('Project root exists:', PROJECT_ROOT.exists())\n",
        "\n",
        "# 导入 analyzers 统一接口\n",
        "from tools.analyzers import (\n",
        "    DatasetAnalyzer, MetricsAnalyzer, AttentionAnalyzer,\n",
        "    analyze_dataset, analyze_model_metrics, analyze_model_attention,\n",
        "    UnifiedAnalyzer, create_unified_analyzer, run_comprehensive_analysis\n",
        ")\n",
        "\n",
        "print('Analyzers imported OK')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DatasetAnalyzer 示例\n",
        "\n",
        "演示两种方式：\n",
        "1) 直接使用项目内置数据集加载（若可用）\n",
        "2) 传入自定义 `TensorDataset`（总能运行）\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-12 16:55:52,860 - DatasetAnalyzer.CIFAR10 - INFO - Starting full dataset analysis...\n",
            "INFO:DatasetAnalyzer.CIFAR10:Starting full dataset analysis...\n",
            "2025-10-12 16:55:52,861 - DatasetAnalyzer.CIFAR10 - INFO - Loading datasets: CIFAR10\n",
            "INFO:DatasetAnalyzer.CIFAR10:Loading datasets: CIFAR10\n",
            "2025-10-12 16:55:52,862 - DatasetAnalyzer.CIFAR10 - WARNING -   Cannot load train dataset: get_train_dataset() missing 1 required positional argument: 'root_dir'\n",
            "WARNING:DatasetAnalyzer.CIFAR10:  Cannot load train dataset: get_train_dataset() missing 1 required positional argument: 'root_dir'\n",
            "2025-10-12 16:55:52,862 - DatasetAnalyzer.CIFAR10 - WARNING -   Cannot load test dataset: get_test_dataset() missing 1 required positional argument: 'root_dir'\n",
            "WARNING:DatasetAnalyzer.CIFAR10:  Cannot load test dataset: get_test_dataset() missing 1 required positional argument: 'root_dir'\n",
            "2025-10-12 16:55:52,863 - DatasetAnalyzer.CIFAR10 - INFO - Analyzing class distribution...\n",
            "INFO:DatasetAnalyzer.CIFAR10:Analyzing class distribution...\n",
            "2025-10-12 16:55:52,863 - DatasetAnalyzer.CIFAR10 - INFO - Analyzing data quality...\n",
            "INFO:DatasetAnalyzer.CIFAR10:Analyzing data quality...\n",
            "2025-10-12 16:55:52,864 - DatasetAnalyzer.CIFAR10 - INFO - Analyzing dataset balance...\n",
            "INFO:DatasetAnalyzer.CIFAR10:Analyzing dataset balance...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-12 16:55:53,707 - DatasetAnalyzer.CIFAR10 - INFO - Report saved to: output/analysis/CIFAR10/CIFAR10_20251012_165552_1dd293bc/dataset_analysis_report.txt\n",
            "INFO:DatasetAnalyzer.CIFAR10:Report saved to: output/analysis/CIFAR10/CIFAR10_20251012_165552_1dd293bc/dataset_analysis_report.txt\n",
            "2025-10-12 16:55:53,708 - DatasetAnalyzer.CIFAR10 - INFO - Results exported to: output/analysis/CIFAR10/CIFAR10_20251012_165552_1dd293bc/analysis_results.json\n",
            "INFO:DatasetAnalyzer.CIFAR10:Results exported to: output/analysis/CIFAR10/CIFAR10_20251012_165552_1dd293bc/analysis_results.json\n",
            "2025-10-12 16:55:53,708 - DatasetAnalyzer.CIFAR10 - INFO - Analysis completed. Results saved to: output/analysis/CIFAR10/CIFAR10_20251012_165552_1dd293bc\n",
            "INFO:DatasetAnalyzer.CIFAR10:Analysis completed. Results saved to: output/analysis/CIFAR10/CIFAR10_20251012_165552_1dd293bc\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "内置数据集分析完成，输出目录: output/analysis/CIFAR10/CIFAR10_20251012_165552_1dd293bc\n"
          ]
        }
      ],
      "source": [
        "# 方式A：使用内置数据集（如 CIFAR10），若项目 `src.dataset` 可用\n",
        "from tools.analyzers import analyze_dataset\n",
        "\n",
        "try:\n",
        "    dataset_config = {\n",
        "        \"dataset_name\": \"CIFAR10\",\n",
        "        \"data_dir\": str(PROJECT_ROOT / \"data\"),\n",
        "        \"batch_size\": 32,\n",
        "    }\n",
        "    ds_results = analyze_dataset(\n",
        "        dataset_name=\"CIFAR10\", dataset_config=dataset_config, splits=[\"train\", \"test\"]\n",
        "    )\n",
        "    print(\"内置数据集分析完成，输出目录:\", ds_results[\"output_directory\"])\n",
        "except Exception as e:\n",
        "    print(\"内置数据集方式失败，原因：\", e)\n",
        "    print(\"将使用自定义 TensorDataset 方式继续演示。\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-12 16:55:53,721 - DatasetAnalyzer.CustomDataset - INFO - Loaded custom dataset 'custom': 500 samples\n",
            "INFO:DatasetAnalyzer.CustomDataset:Loaded custom dataset 'custom': 500 samples\n",
            "2025-10-12 16:55:53,722 - DatasetAnalyzer.CustomDataset - INFO - Starting full dataset analysis...\n",
            "INFO:DatasetAnalyzer.CustomDataset:Starting full dataset analysis...\n",
            "2025-10-12 16:55:53,723 - DatasetAnalyzer.CustomDataset - INFO - Loading datasets: CustomDataset\n",
            "INFO:DatasetAnalyzer.CustomDataset:Loading datasets: CustomDataset\n",
            "2025-10-12 16:55:53,724 - DatasetAnalyzer.CustomDataset - WARNING -   Cannot load custom dataset: get_dataset() got an unexpected keyword argument 'split'\n",
            "WARNING:DatasetAnalyzer.CustomDataset:  Cannot load custom dataset: get_dataset() got an unexpected keyword argument 'split'\n",
            "2025-10-12 16:55:53,724 - DatasetAnalyzer.CustomDataset - INFO - Analyzing class distribution...\n",
            "INFO:DatasetAnalyzer.CustomDataset:Analyzing class distribution...\n",
            "2025-10-12 16:55:53,725 - DatasetAnalyzer.CustomDataset - INFO -   Analyzing custom dataset...\n",
            "INFO:DatasetAnalyzer.CustomDataset:  Analyzing custom dataset...\n",
            "2025-10-12 16:55:53,726 - DatasetAnalyzer.CustomDataset - INFO -     Found 10 unique classes\n",
            "INFO:DatasetAnalyzer.CustomDataset:    Found 10 unique classes\n",
            "2025-10-12 16:55:53,727 - DatasetAnalyzer.CustomDataset - INFO - Analyzing data quality...\n",
            "INFO:DatasetAnalyzer.CustomDataset:Analyzing data quality...\n",
            "2025-10-12 16:55:53,727 - DatasetAnalyzer.CustomDataset - INFO -   Analyzing custom dataset quality...\n",
            "INFO:DatasetAnalyzer.CustomDataset:  Analyzing custom dataset quality...\n",
            "2025-10-12 16:55:53,750 - DatasetAnalyzer.CustomDataset - INFO -     Quality score: 100.00%\n",
            "INFO:DatasetAnalyzer.CustomDataset:    Quality score: 100.00%\n",
            "2025-10-12 16:55:53,751 - DatasetAnalyzer.CustomDataset - INFO - Analyzing dataset balance...\n",
            "INFO:DatasetAnalyzer.CustomDataset:Analyzing dataset balance...\n",
            "2025-10-12 16:55:54,933 - DatasetAnalyzer.CustomDataset - INFO - Report saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/CustomDataset_20251012_165553_a656d26c/dataset_analysis_report.txt\n",
            "INFO:DatasetAnalyzer.CustomDataset:Report saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/CustomDataset_20251012_165553_a656d26c/dataset_analysis_report.txt\n",
            "2025-10-12 16:55:54,935 - DatasetAnalyzer.CustomDataset - INFO - Results exported to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/CustomDataset_20251012_165553_a656d26c/analysis_results.json\n",
            "INFO:DatasetAnalyzer.CustomDataset:Results exported to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/CustomDataset_20251012_165553_a656d26c/analysis_results.json\n",
            "2025-10-12 16:55:54,936 - DatasetAnalyzer.CustomDataset - INFO - Analysis completed. Results saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/CustomDataset_20251012_165553_a656d26c\n",
            "INFO:DatasetAnalyzer.CustomDataset:Analysis completed. Results saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/CustomDataset_20251012_165553_a656d26c\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "自定义数据集分析完成，输出目录: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/CustomDataset_20251012_165553_a656d26c\n"
          ]
        }
      ],
      "source": [
        "# 方式B：自定义 TensorDataset（保证可运行）\n",
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "X = torch.randn(500, 3, 32, 32)\n",
        "y = torch.randint(0, 10, (500,))\n",
        "custom_dataset = TensorDataset(X, y)\n",
        "\n",
        "from tools.analyzers import DatasetAnalyzer\n",
        "\n",
        "custom_da = DatasetAnalyzer(\n",
        "    dataset_name=\"CustomDataset\",\n",
        "    dataset_config=None,\n",
        "    output_dir=str(PROJECT_ROOT / \"output/analysis\"),\n",
        ")\n",
        "\n",
        "# 使用兼容方法：传入 dataset 后直接 run_full_analysis\n",
        "custom_da.load_custom_dataset(custom_dataset, \"custom\")\n",
        "custom_results = custom_da.run_full_analysis(\n",
        "    splits=[\"custom\"], save_plots=True, max_samples=200\n",
        ")\n",
        "print(\"自定义数据集分析完成，输出目录:\", custom_results[\"output_directory\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MetricsAnalyzer 示例\n",
        "\n",
        "我们构造一个“每类指标”字典，演示统计、可视化与报告导出。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "指标分析完成，输出目录: output/analysis/metrics_analysis_20251012_165554\n",
            "生成的可视化图数量: 5\n"
          ]
        }
      ],
      "source": [
        "from tools.analyzers import analyze_model_metrics\n",
        "\n",
        "# 构造假设的“每类指标”数据\n",
        "rng = np.random.default_rng(42)\n",
        "class_names = [f\"class_{i}\" for i in range(1, 11)]\n",
        "metrics_per_class = {\n",
        "    name: {\n",
        "        \"accuracy\": float(rng.uniform(0.80, 0.99)),\n",
        "        \"precision\": float(rng.uniform(0.75, 0.98)),\n",
        "        \"recall\": float(rng.uniform(0.70, 0.98)),\n",
        "        \"f1\": float(rng.uniform(0.72, 0.98)),\n",
        "    }\n",
        "    for name in class_names\n",
        "}\n",
        "\n",
        "metrics_results = analyze_model_metrics(metrics_per_class, task_type=\"classification\")\n",
        "print(\"指标分析完成，输出目录:\", metrics_results[\"output_directory\"])\n",
        "print(\"生成的可视化图数量:\", len(metrics_results[\"generated_plots\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AttentionAnalyzer 示例\n",
        "\n",
        "使用一个最小的 TransformerEncoder 生成伪造输入，演示注意力权重提取与可视化。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-12 16:55:57,174 - AttentionAnalyzer - INFO - 开始对模型 'MiniTransformer' 进行完整注意力分析\n",
            "INFO:AttentionAnalyzer:开始对模型 'MiniTransformer' 进行完整注意力分析\n",
            "2025-10-12 16:55:57,174 - AttentionAnalyzer - INFO - 开始提取注意力权重...\n",
            "INFO:AttentionAnalyzer:开始提取注意力权重...\n",
            "2025-10-12 16:55:57,176 - AttentionAnalyzer - ERROR - ❌ 注意力分析过程中出现错误: 'NoneType' object has no attribute 'detach'\n",
            "ERROR:AttentionAnalyzer:❌ 注意力分析过程中出现错误: 'NoneType' object has no attribute 'detach'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "注意力分析遇到问题： 'NoneType' object has no attribute 'detach'\n",
            "你可以将自定义注意力模块的权重以 (num_heads, seq_len, seq_len) 形式传入可视化函数。\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from tools.analyzers import AttentionAnalyzer\n",
        "\n",
        "# 最小 TransformerEncoder\n",
        "embed_dim = 32\n",
        "num_heads = 4\n",
        "num_layers = 2\n",
        "seq_len = 12\n",
        "batch_size = 1\n",
        "\n",
        "encoder_layer = nn.TransformerEncoderLayer(\n",
        "    d_model=embed_dim, nhead=num_heads, batch_first=True\n",
        ")\n",
        "model = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "# 构造随机 token 向量\n",
        "x = torch.randn(batch_size, seq_len, embed_dim)\n",
        "\n",
        "# 注意：AttentionAnalyzer 的 extract_attention_weights 通过 forward hook 寻找注意力权重。\n",
        "# 对于原生 nn.TransformerEncoderLayer，通常在输出元组或子模块上可获取（实现里做了兜底）。\n",
        "\n",
        "analyzer = AttentionAnalyzer(output_dir=str(PROJECT_ROOT / \"output/analysis\"))\n",
        "\n",
        "# 由于原生模块未暴露 attention_weights 属性，这里采用 run_full_analysis 的兜底路径；\n",
        "# 若你的模型自定义了注意力层并暴露权重，该分析器将会收集更多层的权重。\n",
        "try:\n",
        "    report = analyzer.run_full_analysis(\n",
        "        model=model,\n",
        "        input_tensor=x,\n",
        "        tokens=[f\"T{i}\" for i in range(seq_len)],\n",
        "        model_name=\"MiniTransformer\",\n",
        "    )\n",
        "    print(\"注意力分析完成，报告已导出。\")\n",
        "except Exception as e:\n",
        "    print(\"注意力分析遇到问题：\", e)\n",
        "    print(\n",
        "        \"你可以将自定义注意力模块的权重以 (num_heads, seq_len, seq_len) 形式传入可视化函数。\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 修复说明\n",
        "\n",
        "刚才发现 `analysis_results.json` 中有很多空数组 `[]` 的问题：\n",
        "\n",
        "**问题原因：**\n",
        "- `TensorDataset` 的标签是标量（形状为 `()`）\n",
        "- 在记录 `label_shapes` 时，标量的 `shape` 是空元组 `()`\n",
        "- JSON 序列化时空元组变成空数组 `[]`\n",
        "\n",
        "**已修复：**\n",
        "- 修改了 `DatasetAnalyzer` 中的标签形状记录逻辑\n",
        "- 标量标签现在记录为 `(1,)` 而不是 `()`\n",
        "\n",
        "让我们重新运行一个简单的测试来验证修复效果：\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-10-12 16:55:57,187 - DatasetAnalyzer.FixedTestDataset - INFO - Loaded custom dataset 'test': 50 samples\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Loaded custom dataset 'test': 50 samples\n",
            "2025-10-12 16:55:57,188 - DatasetAnalyzer.FixedTestDataset - INFO - Starting full dataset analysis...\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Starting full dataset analysis...\n",
            "2025-10-12 16:55:57,189 - DatasetAnalyzer.FixedTestDataset - INFO - Loading datasets: FixedTestDataset\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Loading datasets: FixedTestDataset\n",
            "2025-10-12 16:55:57,190 - DatasetAnalyzer.FixedTestDataset - WARNING -   Cannot load test dataset: get_test_dataset() missing 2 required positional arguments: 'dataset_name' and 'root_dir'\n",
            "WARNING:DatasetAnalyzer.FixedTestDataset:  Cannot load test dataset: get_test_dataset() missing 2 required positional arguments: 'dataset_name' and 'root_dir'\n",
            "2025-10-12 16:55:57,191 - DatasetAnalyzer.FixedTestDataset - INFO - Analyzing class distribution...\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Analyzing class distribution...\n",
            "2025-10-12 16:55:57,192 - DatasetAnalyzer.FixedTestDataset - INFO -   Analyzing test dataset...\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:  Analyzing test dataset...\n",
            "2025-10-12 16:55:57,193 - DatasetAnalyzer.FixedTestDataset - INFO -     Found 5 unique classes\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:    Found 5 unique classes\n",
            "2025-10-12 16:55:57,194 - DatasetAnalyzer.FixedTestDataset - INFO - Analyzing data quality...\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Analyzing data quality...\n",
            "2025-10-12 16:55:57,195 - DatasetAnalyzer.FixedTestDataset - INFO -   Analyzing test dataset quality...\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:  Analyzing test dataset quality...\n",
            "2025-10-12 16:55:57,200 - DatasetAnalyzer.FixedTestDataset - INFO -     Quality score: 100.00%\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:    Quality score: 100.00%\n",
            "2025-10-12 16:55:57,201 - DatasetAnalyzer.FixedTestDataset - INFO - Analyzing dataset balance...\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Analyzing dataset balance...\n",
            "2025-10-12 16:55:57,203 - DatasetAnalyzer.FixedTestDataset - INFO - Report saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/FixedTestDataset_20251012_165557_538ce237/dataset_analysis_report.txt\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Report saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/FixedTestDataset_20251012_165557_538ce237/dataset_analysis_report.txt\n",
            "2025-10-12 16:55:57,204 - DatasetAnalyzer.FixedTestDataset - INFO - Results exported to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/FixedTestDataset_20251012_165557_538ce237/analysis_results.json\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Results exported to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/FixedTestDataset_20251012_165557_538ce237/analysis_results.json\n",
            "2025-10-12 16:55:57,204 - DatasetAnalyzer.FixedTestDataset - INFO - Analysis completed. Results saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/FixedTestDataset_20251012_165557_538ce237\n",
            "INFO:DatasetAnalyzer.FixedTestDataset:Analysis completed. Results saved to: /home/rczx/workspace/sxy/lab/NeuroTrain/output/analysis/FixedTestDataset_20251012_165557_538ce237\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "标签形状列表（前10个）: [(), (), (), (), (), (), (), (), (), ()]\n",
            "是否还有空数组: True\n",
            "最常见的形状: ((), 50)\n"
          ]
        }
      ],
      "source": [
        "# 验证修复效果：重新运行 DatasetAnalyzer\n",
        "from torch.utils.data import TensorDataset\n",
        "from tools.analyzers import DatasetAnalyzer\n",
        "\n",
        "# 创建新的测试数据\n",
        "X_test = torch.randn(50, 3, 32, 32)\n",
        "y_test = torch.randint(0, 5, (50,))\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "\n",
        "# 创建新的分析器实例（使用修复后的代码）\n",
        "test_analyzer = DatasetAnalyzer(\n",
        "    dataset_name=\"FixedTestDataset\", output_dir=str(PROJECT_ROOT / \"output/analysis\")\n",
        ")\n",
        "\n",
        "# 运行分析\n",
        "test_analyzer.load_custom_dataset(test_dataset, \"test\")\n",
        "test_results = test_analyzer.run_full_analysis(\n",
        "    splits=[\"test\"], save_plots=False, max_samples=50\n",
        ")\n",
        "\n",
        "# 检查结果\n",
        "label_shapes = test_results[\"analysis_results\"][\"class_distribution\"][\"test\"][\n",
        "    \"label_shapes\"\n",
        "]\n",
        "print(f\"标签形状列表（前10个）: {label_shapes[:10]}\")\n",
        "print(f\"是否还有空数组: {any(len(shape) == 0 for shape in label_shapes)}\")\n",
        "print(\n",
        "    f\"最常见的形状: {test_results['analysis_results']['class_distribution']['test']['most_common_shape']}\"\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ntrain",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
