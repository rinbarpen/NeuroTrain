# Analyzer Module

è¿™æ˜¯ä¸€ä¸ªç»¼åˆçš„æ¨¡å‹åˆ†æå·¥å…·æ¨¡å—ï¼Œæä¾›å¤šç§åˆ†æåŠŸèƒ½æ¥å¸®åŠ©ç†è§£å’Œä¼˜åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚

## æ¨¡å—ç»“æ„

```
tools/analyzers/
â”œâ”€â”€ __init__.py              # ç»Ÿä¸€æ¥å£å’Œä¾¿æ·å‡½æ•°
â”œâ”€â”€ attention_analyzer.py    # æ³¨æ„åŠ›æœºåˆ¶åˆ†æå™¨ï¼ˆæ”¯æŒSEæ¨¡å—ç­‰ï¼‰
â”œâ”€â”€ data_analyzer.py         # è®­ç»ƒæ•°æ®å’ŒæŒ‡æ ‡åˆ†æå™¨
â”œâ”€â”€ dataset_analyzer.py      # æ•°æ®é›†è´¨é‡åˆ†æå™¨
â”œâ”€â”€ mask_analyzer.py         # Maskä¿¡æ¯åˆ†æå™¨ï¼ˆå›¾åƒå’Œæ–‡æœ¬ï¼‰
â”œâ”€â”€ relation_analyzer.py     # è·¨æ¨¡æ€å…³ç³»åˆ†æå™¨ï¼ˆç±»ä¼¼CLIPï¼‰
â””â”€â”€ README.md               # æœ¬æ–‡æ¡£
```

## ğŸ”§ æ ¸å¿ƒåˆ†æå™¨

### 1. AttentionAnalyzer - æ³¨æ„åŠ›åˆ†æå™¨

ä¸“é—¨ç”¨äºåˆ†æå’Œå¯è§†åŒ–æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸­çš„æ³¨æ„åŠ›æœºåˆ¶ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**
- æ³¨æ„åŠ›æƒé‡æå–å’Œåˆ†æ
- å¤šå¤´æ³¨æ„åŠ›å¯è§†åŒ–
- æ³¨æ„åŠ›æ¨¡å¼åˆ†æ
- æ³¨æ„åŠ›æµå¯è§†åŒ–
- æ³¨æ„åŠ›çƒ­å›¾ç”Ÿæˆ

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
from tools.analyzers import AttentionAnalyzer

# åˆ›å»ºåˆ†æå™¨
analyzer = AttentionAnalyzer(model=your_model)

# åˆ†ææ³¨æ„åŠ›æ¨¡å¼
results = analyzer.analyze_attention_patterns(input_data)

# ç”Ÿæˆå¯è§†åŒ–
analyzer.visualize_attention_weights(input_data, layer_name='attention')
```

### 2. MetricsAnalyzer - æ•°æ®æŒ‡æ ‡åˆ†æå™¨

æä¾›å…¨é¢çš„æ¨¡å‹æ€§èƒ½æŒ‡æ ‡è®¡ç®—å’Œåˆ†æåŠŸèƒ½ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**
- åˆ†ç±»ä»»åŠ¡æŒ‡æ ‡ï¼ˆå‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1ç­‰ï¼‰
- åˆ†å‰²ä»»åŠ¡æŒ‡æ ‡ï¼ˆIoUã€Diceç³»æ•°ç­‰ï¼‰
- æ£€æµ‹ä»»åŠ¡æŒ‡æ ‡ï¼ˆmAPã€ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ç­‰ï¼‰
- å›å½’ä»»åŠ¡æŒ‡æ ‡ï¼ˆMSEã€MAEã€RÂ²ç­‰ï¼‰
- å¤šç±»åˆ«æŒ‡æ ‡åˆ†æå’Œå¯è§†åŒ–
- æ¨¡å‹æ€§èƒ½æ¯”è¾ƒ

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
from tools.analyzers import MetricsAnalyzer

# åˆ›å»ºåˆ†æå™¨
analyzer = MetricsAnalyzer()

# åˆ†æåˆ†ç±»ä»»åŠ¡
results = analyzer.analyze_predictions(
    y_true=true_labels, 
    y_pred=predictions, 
    task_type='classification'
)

# ç”Ÿæˆæ··æ·†çŸ©é˜µ
analyzer.plot_confusion_matrix(y_true, y_pred)
```

### 3. DatasetAnalyzer - æ•°æ®é›†åˆ†æå™¨

ç”¨äºæ•°æ®é›†ç‰¹å¾åˆ†æã€è´¨é‡æ£€æŸ¥å’Œç»Ÿè®¡ä¿¡æ¯ç”Ÿæˆã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**
- æ•°æ®é›†ç±»åˆ«åˆ†å¸ƒåˆ†æ
- æ•°æ®è´¨é‡æ£€æŸ¥ä¸ç»Ÿè®¡
- æ•°æ®é›†ç‰¹å¾åˆ†æ
- æ•°æ®å¹³è¡¡æ€§è¯„ä¼°
- å¯è§†åŒ–ä¸æŠ¥å‘Šç”Ÿæˆ

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
from tools.analyzers import DatasetAnalyzer

# åˆ›å»ºåˆ†æå™¨
analyzer = DatasetAnalyzer(
    dataset_name='CIFAR10',
    dataset_config={'data_dir': './data'}
)

# è¿è¡Œå®Œæ•´åˆ†æ
results = analyzer.run_full_analysis(splits=['train', 'test'])
```

## ğŸš€ ç»Ÿä¸€æ¥å£

### UnifiedAnalyzer - ç»Ÿä¸€åˆ†æå™¨

æ•´åˆä¸‰ä¸ªæ ¸å¿ƒåˆ†æå™¨ï¼Œæä¾›ä¸€ç«™å¼åˆ†ææœåŠ¡ã€‚

**ä½¿ç”¨ç¤ºä¾‹ï¼š**
```python
from tools.analyzers import UnifiedAnalyzer

# åˆ›å»ºç»Ÿä¸€åˆ†æå™¨
analyzer = UnifiedAnalyzer(
    model=your_model,
    dataset_name='CIFAR10',
    dataset_config={'data_dir': './data'}
)

# è¿è¡Œç»¼åˆåˆ†æ
results = analyzer.run_comprehensive_analysis(
    input_data=sample_data,
    y_true=true_labels,
    y_pred=predictions,
    task_type='classification'
)
```

### ä¾¿æ·å‡½æ•°

æ¨¡å—è¿˜æä¾›äº†ä¾¿æ·çš„å‡½æ•°æ¥å£ï¼š

```python
from tools.analyzers import (
    analyze_model_attention,
    analyze_model_metrics,
    analyze_dataset,
    run_comprehensive_analysis
)

# å¿«é€Ÿæ³¨æ„åŠ›åˆ†æ
attention_results = analyze_model_attention(
    model=your_model,
    input_data=sample_data
)

# å¿«é€ŸæŒ‡æ ‡åˆ†æ
metrics_results = analyze_model_metrics(
    y_true=true_labels,
    y_pred=predictions,
    task_type='classification'
)

# å¿«é€Ÿæ•°æ®é›†åˆ†æ
dataset_results = analyze_dataset(
    dataset_name='CIFAR10',
    dataset_config={'data_dir': './data'}
)

# ç»¼åˆåˆ†æ
comprehensive_results = run_comprehensive_analysis(
    model=your_model,
    dataset_name='CIFAR10',
    input_data=sample_data,
    y_true=true_labels,
    y_pred=predictions
)
```

## ğŸ“Š è¾“å‡ºç»“æœ

æ‰€æœ‰åˆ†æå™¨éƒ½ä¼šåœ¨æŒ‡å®šçš„è¾“å‡ºç›®å½•ä¸­ç”Ÿæˆä»¥ä¸‹å†…å®¹ï¼š

### æ–‡ä»¶ç»“æ„
```
runs/analysis_output/
â”œâ”€â”€ attention/              # æ³¨æ„åŠ›åˆ†æç»“æœ
â”‚   â”œâ”€â”€ attention_weights.png
â”‚   â”œâ”€â”€ attention_patterns.json
â”‚   â””â”€â”€ attention_report.txt
â”œâ”€â”€ metrics/                # æŒ‡æ ‡åˆ†æç»“æœ
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â”œâ”€â”€ metrics_summary.json
â”‚   â””â”€â”€ performance_report.txt
â”œâ”€â”€ dataset/                # æ•°æ®é›†åˆ†æç»“æœ
â”‚   â”œâ”€â”€ class_distribution.png
â”‚   â”œâ”€â”€ data_quality.png
â”‚   â””â”€â”€ dataset_report.txt
â”œâ”€â”€ comprehensive_analysis.json  # ç»¼åˆåˆ†æç»“æœ
â””â”€â”€ comprehensive_report.txt     # ç»¼åˆåˆ†ææŠ¥å‘Š
```

### æŠ¥å‘Šå†…å®¹
- **JSONæ ¼å¼**ï¼šç»“æ„åŒ–çš„åˆ†æç»“æœï¼Œä¾¿äºç¨‹åºå¤„ç†
- **æ–‡æœ¬æŠ¥å‘Š**ï¼šäººç±»å¯è¯»çš„åˆ†ææ‘˜è¦å’Œå»ºè®®
- **å¯è§†åŒ–å›¾è¡¨**ï¼šç›´è§‚çš„å›¾è¡¨å’Œå›¾åƒ
- **ç»Ÿè®¡æ•°æ®**ï¼šè¯¦ç»†çš„æ•°å€¼ç»Ÿè®¡ä¿¡æ¯

## âš™ï¸ é…ç½®é€‰é¡¹

### é€šç”¨é…ç½®
```python
# è¾“å‡ºç›®å½•é…ç½®
output_dir = "runs/my_analysis"

# æ—¥å¿—çº§åˆ«é…ç½®
import logging
logger = logging.getLogger()
logger.setLevel(logging.INFO)
```

### åˆ†æå™¨ç‰¹å®šé…ç½®

**AttentionAnalyzeré…ç½®ï¼š**
```python
analyzer = AttentionAnalyzer(
    model=model,
    device='cuda',
    layer_names=['attention.0', 'attention.1'],
    head_fusion='mean',  # 'mean', 'max', 'min'
    output_dir='runs/attention_analysis'
)
```

**MetricsAnalyzeré…ç½®ï¼š**
```python
analyzer = MetricsAnalyzer(
    class_names=['cat', 'dog', 'bird'],
    average='weighted',  # 'micro', 'macro', 'weighted'
    output_dir='runs/metrics_analysis'
)
```

**DatasetAnalyzeré…ç½®ï¼š**
```python
analyzer = DatasetAnalyzer(
    dataset_name='CustomDataset',
    dataset_config={'batch_size': 32},
    label_extractor=custom_label_function,
    image_extractor=custom_image_function,
    output_dir='runs/dataset_analysis'
)
```

## ğŸ”§ è‡ªå®šä¹‰æ‰©å±•

### è‡ªå®šä¹‰æ ‡ç­¾æå–å™¨
```python
def custom_label_extractor(sample):
    """è‡ªå®šä¹‰æ ‡ç­¾æå–å‡½æ•°"""
    # å®ç°ä½ çš„æ ‡ç­¾æå–é€»è¾‘
    return extracted_label

analyzer = DatasetAnalyzer(
    dataset_name='MyDataset',
    label_extractor=custom_label_extractor
)
```

### è‡ªå®šä¹‰æŒ‡æ ‡è®¡ç®—
```python
def custom_metric(y_true, y_pred):
    """è‡ªå®šä¹‰æŒ‡æ ‡è®¡ç®—å‡½æ•°"""
    # å®ç°ä½ çš„æŒ‡æ ‡è®¡ç®—é€»è¾‘
    return metric_value

analyzer = MetricsAnalyzer()
analyzer.add_custom_metric('my_metric', custom_metric)
```

## ğŸ“‹ ä¾èµ–è¦æ±‚

```python
# æ ¸å¿ƒä¾èµ–
torch>=1.8.0
numpy>=1.19.0
matplotlib>=3.3.0
seaborn>=0.11.0
pandas>=1.2.0
scikit-learn>=0.24.0

# NeuroTrainæ¨¡å—
src.dataset
src.metrics
src.utils
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **å†…å­˜ä½¿ç”¨**ï¼šå¤§å‹æ•°æ®é›†åˆ†æå¯èƒ½æ¶ˆè€—å¤§é‡å†…å­˜ï¼Œå»ºè®®è®¾ç½®åˆé€‚çš„é‡‡æ ·å‚æ•°
2. **GPUæ”¯æŒ**ï¼šæ³¨æ„åŠ›åˆ†æå™¨æ”¯æŒGPUåŠ é€Ÿï¼Œç¡®ä¿CUDAç¯å¢ƒæ­£ç¡®é…ç½®
3. **æ–‡ä»¶æƒé™**ï¼šç¡®ä¿è¾“å‡ºç›®å½•å…·æœ‰å†™å…¥æƒé™
4. **æ•°æ®æ ¼å¼**ï¼šç¡®ä¿è¾“å…¥æ•°æ®æ ¼å¼ä¸åˆ†æå™¨æœŸæœ›çš„æ ¼å¼ä¸€è‡´

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

**Q: å¯¼å…¥æ¨¡å—å¤±è´¥**
```python
# ç¡®ä¿NeuroTrainé¡¹ç›®æ ¹ç›®å½•åœ¨Pythonè·¯å¾„ä¸­
import sys
sys.path.append('/path/to/NeuroTrain')
```

**Q: æ³¨æ„åŠ›åˆ†æå¤±è´¥**
```python
# æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŒ…å«æ³¨æ„åŠ›å±‚
print([name for name, module in model.named_modules() if 'attention' in name.lower()])
```

**Q: æ•°æ®é›†åŠ è½½å¤±è´¥**
```python
# æ£€æŸ¥æ•°æ®é›†é…ç½®
try:
    from src.dataset import get_dataset
    dataset = get_dataset(**your_config)
    print(f"Dataset loaded successfully: {len(dataset)} samples")
except Exception as e:
    print(f"Dataset loading failed: {e}")
```

## ğŸ“š æ›´å¤šç¤ºä¾‹

æŸ¥çœ‹ `examples/` ç›®å½•è·å–æ›´å¤šè¯¦ç»†çš„ä½¿ç”¨ç¤ºä¾‹å’Œæœ€ä½³å®è·µã€‚

## ğŸ¤ è´¡çŒ®æŒ‡å—

æ¬¢è¿è´¡çŒ®ä»£ç å’Œæ”¹è¿›å»ºè®®ï¼è¯·éµå¾ªä»¥ä¸‹æ­¥éª¤ï¼š

1. Fork é¡¹ç›®
2. åˆ›å»ºåŠŸèƒ½åˆ†æ”¯
3. æäº¤æ›´æ”¹
4. åˆ›å»º Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬æ¨¡å—éµå¾ª NeuroTrain é¡¹ç›®çš„è®¸å¯è¯åè®®ã€‚